<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>LXiHa`Notes</title>
  
  <subtitle>The House Belong to Love and Freedom.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://liujunjie11.github.io/"/>
  <updated>2018-10-23T13:50:33.947Z</updated>
  <id>https://liujunjie11.github.io/</id>
  
  <author>
    <name>刘俊</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>关于在Mac下的python文字转语音库pyttsx3</title>
    <link href="https://liujunjie11.github.io/2018/10/23/%E5%85%B3%E4%BA%8E%E5%9C%A8Mac%E4%B8%8B%E7%9A%84python%E6%96%87%E5%AD%97%E8%BD%AC%E8%AF%AD%E9%9F%B3%E5%BA%93pyttsx3/"/>
    <id>https://liujunjie11.github.io/2018/10/23/关于在Mac下的python文字转语音库pyttsx3/</id>
    <published>2018-10-23T13:29:17.000Z</published>
    <updated>2018-10-23T13:50:33.947Z</updated>
    
    <content type="html"><![CDATA[<p>最近写python机器学习教程有点累了..就玩一些其他的东西，就包括了这个文字转语音的python3库<em>pyttsx3</em>。</p><p>其中也遇到了一些问题，在此记录一下。</p><a id="more"></a><h1 id="关于下载运行的问题"><a href="#关于下载运行的问题" class="headerlink" title="关于下载运行的问题"></a>关于下载运行的问题</h1><p>在使用命令行<code>pip install pyttsx3</code>下载之后，我在终端写下了如下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pyttsx3</div><div class="line">engine = pyttsx3.init()</div></pre></td></tr></table></figure><p>结果出现了<code>No module named &#39;Foundation&#39;</code>的错误问题。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>下载模块<code>pyobjc</code>.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install pyobjc</div></pre></td></tr></table></figure><p>估计是跟调用系统一些模块有关，毕竟这个库是跟macOS关系还是挺深的…自行了解，没想到这个库可以调用Objective-C的库来进行macOS上的应用程序开发…</p><p>以下是WiKi的解释：</p><blockquote><p>PyObjC是Python和Objective-C编程语言之间的双向桥梁，允许程序员使用Python扩展现有的Objective-C库，例如Apple的Cocoa框架。 PyObjC用于在纯Python中开发macOS应用程序。 对GNUstep的支持也很有限，GNUstep是Cocoa的开源，跨平台实现。</p></blockquote><p>下载完成这个库之后，再运行上面的代码就没有出错了。</p><ul><li>参考链接：<a href="https://blog.csdn.net/noway5456/article/details/78905275" target="_blank" rel="external">https://blog.csdn.net/noway5456/article/details/78905275</a></li></ul><h1 id="关于pyttsx3读中文字的问题"><a href="#关于pyttsx3读中文字的问题" class="headerlink" title="关于pyttsx3读中文字的问题"></a>关于pyttsx3读中文字的问题</h1><p>这个问题其实是跟系统的语音设置相关的，看下图吧。</p><p>我在系统默认的语音类型(在图中两者之间切换)：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-23%20%E4%B8%8B%E5%8D%889.24.59.png" alt=""></p><p>然后又用代码查看<em>pyttsx3</em>的对应默认声音：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-23%20%E4%B8%8B%E5%8D%889.24.30.png" alt=""></p><p>发现了其实pyttsx3的语音是根据本地语音相关的，这又一步说明为何要安装<code>pyobjc</code>这个铺助模块的意义。</p><p>在读取英文或中文时，设置一下本地的默认语音即可。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近写python机器学习教程有点累了..就玩一些其他的东西，就包括了这个文字转语音的python3库&lt;em&gt;pyttsx3&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;其中也遇到了一些问题，在此记录一下。&lt;/p&gt;
    
    </summary>
    
      <category term="python" scheme="https://liujunjie11.github.io/categories/python/"/>
    
    
      <category term="python" scheme="https://liujunjie11.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>python机器学习系列：支持向量机(SVM)的应用以及实现</title>
    <link href="https://liujunjie11.github.io/2018/10/23/python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%9A%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA-SVM-%E7%9A%84%E5%BA%94%E7%94%A8%E4%BB%A5%E5%8F%8A%E5%AE%9E%E7%8E%B0/"/>
    <id>https://liujunjie11.github.io/2018/10/23/python机器学习系列：支持向量机-SVM-的应用以及实现/</id>
    <published>2018-10-23T01:44:10.000Z</published>
    <updated>2018-10-26T12:47:13.253Z</updated>
    
    <content type="html"><![CDATA[<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/HHUqhVzctQE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe><p>我记录下的这些东西，如果是有哪些不懂得地方，我强烈建议参考我在<a href="http://liujunworld.com/2018/09/16/%E5%88%9D%E5%AD%A6%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8D%97/" target="_blank" rel="external">这里的书籍</a>。另外还有<a href="https://github.com/apachecn/AiLearning" target="_blank" rel="external">《机器学习实战》</a>，<a href="https://github.com/exacity/deeplearningbook-chinese" target="_blank" rel="external">《深度学习》</a>这本花书等，利用好搜索引擎也是一大好利器。</p><p>关于这篇文章，我还是和以前记录相关的机器学习知识之类篇章一样的风格。</p><p>不懂可进入<a href="https://pythonprogramming.net/support-vector-machine-intro-machine-learning-tutorial/?completed=/final-thoughts-knn-machine-learning-tutorial/" target="_blank" rel="external">这里的对应的教程</a>，看不懂可借助翻译插件/软件(实际上借助这些看起来轻松多了，看英文头疼的厉害，如果是对于初学者)。</p><a id="more"></a><h1 id="SVM的实现"><a href="#SVM的实现" class="headerlink" title="SVM的实现"></a>SVM的实现</h1><p>SVM算法是有一点难理解的，但是坚持看一些文章和上面说的那些书籍之后就会发现其实也就那么回事。</p><p>关于SVM的实现(仅作通俗说明，以二维为例)：由于这个算法是根据支持向量得出两个函数，而我们取的是这两条线性函数的距离的中间值，从而得到了决策边界函数，这样任务也就完成了。但是由于参数的不同，取这个决策边界是可以有多个甚至是无穷个的，那么取得最优的参数是可以利用梯度下降算法的(符合凸二次规划)。得到了最优的参数就可以得出决策边界的函数了。</p><blockquote><p>涉及到不少的数学知识…我想我大概是说对了吧，哈哈…</p></blockquote><p>为了实现这个算法，必须要提前了解这算法相关的知识，不然真的是寸步难行啊。</p><p>下面是铺助理解链接，不懂还要翻书看吴恩达老师的教程：</p><ul><li><p><a href="https://zh.wikipedia.org/wiki/二次规划" target="_blank" rel="external">二次规划</a></p></li><li><p><a href="http://www.sohu.com/a/206572358_160850" target="_blank" rel="external">干货 | 从超平面到SVM（一）</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/26514613" target="_blank" rel="external">浅谈最优化问题的KKT条件</a></p></li></ul><p>以下就是完整的实现代码了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Support_Vector_Machine</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, visualization=True)</span>:</span></div><div class="line">        self.visualization = visualization</div><div class="line">        self.colors = &#123;<span class="number">1</span>:<span class="string">'r'</span>, <span class="number">-1</span>:<span class="string">'b'</span>&#125;</div><div class="line">        <span class="keyword">if</span> self.visualization:</div><div class="line">            self.fig = plt.figure()</div><div class="line">            self.ax = self.fig.add_subplot(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>)</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, data)</span>:</span></div><div class="line">        self.data = data</div><div class="line">        opt_dict = &#123;&#125;</div><div class="line">        </div><div class="line">        transforms = [[<span class="number">1</span>,<span class="number">1</span>],</div><div class="line">                      [<span class="number">-1</span>,<span class="number">1</span>],</div><div class="line">                      [<span class="number">-1</span>,<span class="number">-1</span>],</div><div class="line">                      [<span class="number">1</span>,<span class="number">-1</span>]]</div><div class="line">        </div><div class="line">        all_data = []</div><div class="line">        <span class="keyword">for</span> yi <span class="keyword">in</span> self.data:</div><div class="line">            <span class="keyword">for</span> featureset <span class="keyword">in</span> self.data[yi]:</div><div class="line">                <span class="keyword">for</span> feature <span class="keyword">in</span> featureset:</div><div class="line">                    all_data.append(feature)</div><div class="line">        </div><div class="line">        self.max_feature_value = max(all_data)</div><div class="line">        self.min_feature_value = min(all_data)</div><div class="line">        all_data = <span class="keyword">None</span></div><div class="line">        </div><div class="line">        <span class="comment">#指定梯度下降的步子大小</span></div><div class="line">        step_sizes = [self.max_feature_value * <span class="number">0.1</span>,</div><div class="line">                      self.max_feature_value * <span class="number">0.01</span>,</div><div class="line">                      self.max_feature_value * <span class="number">0.001</span>,]</div><div class="line">        </div><div class="line">        <span class="comment">#b的假设大小，最为重要的是参数w，而不是参数b </span></div><div class="line">        b_range_multiple = <span class="number">2</span></div><div class="line">        b_multiple =<span class="number">5</span></div><div class="line">        latest_optimum = self.max_feature_value*<span class="number">10</span> <span class="comment">#最大的步子</span></div><div class="line">        </div><div class="line">        <span class="keyword">for</span> step <span class="keyword">in</span> step_sizes:</div><div class="line">            w = np.array([latest_optimum, latest_optimum])</div><div class="line">            optimized = <span class="keyword">False</span></div><div class="line">            <span class="keyword">while</span> <span class="keyword">not</span> optimized:</div><div class="line">                <span class="keyword">for</span> b <span class="keyword">in</span> np.arange(<span class="number">-1</span>*(self.max_feature_value * b_range_multiple),</div><div class="line">                                   self.max_feature_value * b_range_multiple,</div><div class="line">                                   step * b_multiple):</div><div class="line">                    <span class="keyword">for</span> transformation <span class="keyword">in</span> transforms:</div><div class="line">                        w_t = w*transformation</div><div class="line">                        found_option = <span class="keyword">True</span></div><div class="line">                        </div><div class="line">                        <span class="keyword">for</span> i <span class="keyword">in</span> self.data:</div><div class="line">                            <span class="keyword">for</span> xi <span class="keyword">in</span> self.data[i]:</div><div class="line">                                yi = i</div><div class="line">                                <span class="keyword">if</span> <span class="keyword">not</span> yi*(np.dot(w_t, xi)+b) &gt;= <span class="number">1</span>:</div><div class="line">                                    found_option = <span class="keyword">False</span></div><div class="line">                        </div><div class="line">                        <span class="comment">#如果约束优化条件成立</span></div><div class="line">                        <span class="keyword">if</span> found_option:</div><div class="line">                            opt_dict[np.linalg.norm(w_t)] = [w_t, b]</div><div class="line">                </div><div class="line">                <span class="comment">#若是值为负数则停止进一步的优化步子</span></div><div class="line">                <span class="keyword">if</span> w[<span class="number">0</span>] &lt;<span class="number">0</span>:</div><div class="line">                    optimized = <span class="keyword">True</span></div><div class="line">                    print(<span class="string">'Optimized a step.'</span>)</div><div class="line">                <span class="keyword">else</span>:</div><div class="line">                    w = w - step</div><div class="line">            norms = sorted([n <span class="keyword">for</span> n <span class="keyword">in</span> opt_dict])</div><div class="line">            </div><div class="line">            opt_choice = opt_dict[norms[<span class="number">0</span>]]</div><div class="line">            self.w = opt_choice[<span class="number">0</span>]</div><div class="line">            self.b = opt_choice[<span class="number">1</span>]</div><div class="line">            latest_optimum = opt_choice[<span class="number">0</span>][<span class="number">0</span>]+step*<span class="number">2</span></div><div class="line">            </div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> self.data:</div><div class="line">            <span class="keyword">for</span> xi <span class="keyword">in</span> self.data[i]:</div><div class="line">                yi = i</div><div class="line">                print(xi, <span class="string">':'</span>, yi*(np.dot(self.w, xi)+self.b))</div><div class="line">            </div><div class="line">    <span class="comment">#预测部分</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, features)</span>:</span></div><div class="line">        classification = np.sign(np.dot(np.array(features), self.w)+self.b)</div><div class="line">        <span class="keyword">if</span> classification != <span class="number">0</span> <span class="keyword">and</span> self.visualization:</div><div class="line">            self.ax.scatter(features[<span class="number">0</span>], features[<span class="number">1</span>], s=<span class="number">200</span>, marker=<span class="string">'*'</span>, c=self.colors[classification])</div><div class="line">        </div><div class="line">        <span class="keyword">return</span> classification</div><div class="line">    </div><div class="line">    <span class="comment">#可视化部分</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">visualize</span><span class="params">(self)</span>:</span></div><div class="line">        [[self.ax.scatter(x[<span class="number">0</span>], x[<span class="number">1</span>], s=<span class="number">100</span>, color=self.colors[i]) <span class="keyword">for</span> x <span class="keyword">in</span> data_dict[i]] <span class="keyword">for</span> i <span class="keyword">in</span> data_dict]</div><div class="line">        </div><div class="line">        <span class="function"><span class="keyword">def</span> <span class="title">hyperplane</span><span class="params">(x, w, b, v)</span>:</span></div><div class="line">            <span class="keyword">return</span> (-w[<span class="number">0</span>]*x-b+v) / w[<span class="number">1</span>]</div><div class="line">        </div><div class="line">        datarange = (self.min_feature_value*<span class="number">0.9</span>, self.max_feature_value*<span class="number">1.1</span>)</div><div class="line">        hyp_x_min = datarange[<span class="number">0</span>]</div><div class="line">        hyp_x_max = datarange[<span class="number">1</span>]</div><div class="line">        </div><div class="line">        psv1 = hyperplane(hyp_x_min, self.w, self.b, <span class="number">1</span>)</div><div class="line">        psv2 = hyperplane(hyp_x_max, self.w, self.b, <span class="number">1</span>)</div><div class="line">        self.ax.plot([hyp_x_min, hyp_x_max], [psv1,psv2], <span class="string">'k'</span>)</div><div class="line">        </div><div class="line">        nsv1 = hyperplane(hyp_x_min, self.w, self.b, <span class="number">-1</span>)</div><div class="line">        nsv2 = hyperplane(hyp_x_max, self.w, self.b, <span class="number">-1</span>)</div><div class="line">        self.ax.plot([hyp_x_min, hyp_x_max], [nsv1,nsv2], <span class="string">'k'</span>)</div><div class="line">        </div><div class="line">        db1 = hyperplane(hyp_x_min, self.w, self.b, <span class="number">0</span>)</div><div class="line">        db2 = hyperplane(hyp_x_max, self.w, self.b, <span class="number">0</span>)</div><div class="line">        self.ax.plot([hyp_x_min, hyp_x_max], [db1, db2], <span class="string">'y--'</span>)</div><div class="line">        </div><div class="line">        plt.show()</div></pre></td></tr></table></figure><p>铺助理解链接：</p><ul><li><p><a href="https://blog.csdn.net/qianwenhong/article/details/41414809" target="_blank" rel="external">Python 中的range(),arange()函数</a></p></li><li><p><a href="https://www.cnblogs.com/hezhiyao/p/8649231.html" target="_blank" rel="external">python中np.multiply（）、np.dot（）和星号（*）三种乘法运算的区别（转）</a></p></li></ul><h2 id="简要数据集预测以及结果可视化"><a href="#简要数据集预测以及结果可视化" class="headerlink" title="简要数据集预测以及结果可视化"></a>简要数据集预测以及结果可视化</h2><p>以下是完整代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Support_Vector_Machine</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, visualization=True)</span>:</span></div><div class="line">        self.visualization = visualization</div><div class="line">        self.colors = &#123;<span class="number">1</span>:<span class="string">'r'</span>, <span class="number">-1</span>:<span class="string">'b'</span>&#125;</div><div class="line">        <span class="keyword">if</span> self.visualization:</div><div class="line">            self.fig = plt.figure()</div><div class="line">            self.ax = self.fig.add_subplot(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>)</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, data)</span>:</span></div><div class="line">        self.data = data</div><div class="line">        opt_dict = &#123;&#125;</div><div class="line">        </div><div class="line">        transforms = [[<span class="number">1</span>,<span class="number">1</span>],</div><div class="line">                      [<span class="number">-1</span>,<span class="number">1</span>],</div><div class="line">                      [<span class="number">-1</span>,<span class="number">-1</span>],</div><div class="line">                      [<span class="number">1</span>,<span class="number">-1</span>]]</div><div class="line">        </div><div class="line">        all_data = []</div><div class="line">        <span class="keyword">for</span> yi <span class="keyword">in</span> self.data:</div><div class="line">            <span class="keyword">for</span> featureset <span class="keyword">in</span> self.data[yi]:</div><div class="line">                <span class="keyword">for</span> feature <span class="keyword">in</span> featureset:</div><div class="line">                    all_data.append(feature)</div><div class="line">        </div><div class="line">        self.max_feature_value = max(all_data)</div><div class="line">        self.min_feature_value = min(all_data)</div><div class="line">        all_data = <span class="keyword">None</span></div><div class="line">        </div><div class="line">        <span class="comment">#指定梯度下降的步子大小</span></div><div class="line">        step_sizes = [self.max_feature_value * <span class="number">0.1</span>,</div><div class="line">                      self.max_feature_value * <span class="number">0.01</span>,</div><div class="line">                      self.max_feature_value * <span class="number">0.001</span>,]</div><div class="line">        </div><div class="line">        <span class="comment">#b的假设大小，最为重要的是参数w，而不是参数b </span></div><div class="line">        b_range_multiple = <span class="number">2</span></div><div class="line">        b_multiple =<span class="number">5</span></div><div class="line">        latest_optimum = self.max_feature_value*<span class="number">10</span> <span class="comment">#最大的步子</span></div><div class="line">        </div><div class="line">        <span class="keyword">for</span> step <span class="keyword">in</span> step_sizes:</div><div class="line">            w = np.array([latest_optimum, latest_optimum])</div><div class="line">            optimized = <span class="keyword">False</span></div><div class="line">            <span class="keyword">while</span> <span class="keyword">not</span> optimized:</div><div class="line">                <span class="keyword">for</span> b <span class="keyword">in</span> np.arange(<span class="number">-1</span>*(self.max_feature_value * b_range_multiple),</div><div class="line">                                   self.max_feature_value * b_range_multiple,</div><div class="line">                                   step * b_multiple):</div><div class="line">                    <span class="keyword">for</span> transformation <span class="keyword">in</span> transforms:</div><div class="line">                        w_t = w*transformation</div><div class="line">                        found_option = <span class="keyword">True</span></div><div class="line">                        </div><div class="line">                        <span class="keyword">for</span> i <span class="keyword">in</span> self.data:</div><div class="line">                            <span class="keyword">for</span> xi <span class="keyword">in</span> self.data[i]:</div><div class="line">                                yi = i</div><div class="line">                                <span class="keyword">if</span> <span class="keyword">not</span> yi*(np.dot(w_t, xi)+b) &gt;= <span class="number">1</span>:</div><div class="line">                                    found_option = <span class="keyword">False</span></div><div class="line">                        </div><div class="line">                        <span class="comment">#如果约束优化条件成立</span></div><div class="line">                        <span class="keyword">if</span> found_option:</div><div class="line">                            opt_dict[np.linalg.norm(w_t)] = [w_t, b]</div><div class="line">                </div><div class="line">                <span class="comment">#若是值为负数则停止进一步的优化步子</span></div><div class="line">                <span class="keyword">if</span> w[<span class="number">0</span>] &lt;<span class="number">0</span>:</div><div class="line">                    optimized = <span class="keyword">True</span></div><div class="line">                    print(<span class="string">'Optimized a step.'</span>)</div><div class="line">                <span class="keyword">else</span>:</div><div class="line">                    w = w - step</div><div class="line">            norms = sorted([n <span class="keyword">for</span> n <span class="keyword">in</span> opt_dict])</div><div class="line">            </div><div class="line">            opt_choice = opt_dict[norms[<span class="number">0</span>]]</div><div class="line">            self.w = opt_choice[<span class="number">0</span>]</div><div class="line">            self.b = opt_choice[<span class="number">1</span>]</div><div class="line">            latest_optimum = opt_choice[<span class="number">0</span>][<span class="number">0</span>]+step*<span class="number">2</span></div><div class="line">            </div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> self.data:</div><div class="line">            <span class="keyword">for</span> xi <span class="keyword">in</span> self.data[i]:</div><div class="line">                yi = i</div><div class="line">                print(xi, <span class="string">':'</span>, yi*(np.dot(self.w, xi)+self.b))</div><div class="line">            </div><div class="line">    <span class="comment">#预测部分</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, features)</span>:</span></div><div class="line">        classification = np.sign(np.dot(np.array(features), self.w)+self.b)</div><div class="line">        <span class="keyword">if</span> classification != <span class="number">0</span> <span class="keyword">and</span> self.visualization:</div><div class="line">            self.ax.scatter(features[<span class="number">0</span>], features[<span class="number">1</span>], s=<span class="number">200</span>, marker=<span class="string">'*'</span>, c=self.colors[classification])</div><div class="line">        </div><div class="line">        <span class="keyword">return</span> classification</div><div class="line">    </div><div class="line">    <span class="comment">#可视化部分</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">visualize</span><span class="params">(self)</span>:</span></div><div class="line">        [[self.ax.scatter(x[<span class="number">0</span>], x[<span class="number">1</span>], s=<span class="number">100</span>, color=self.colors[i]) <span class="keyword">for</span> x <span class="keyword">in</span> data_dict[i]] <span class="keyword">for</span> i <span class="keyword">in</span> data_dict]</div><div class="line">        </div><div class="line">        <span class="function"><span class="keyword">def</span> <span class="title">hyperplane</span><span class="params">(x, w, b, v)</span>:</span></div><div class="line">            <span class="keyword">return</span> (-w[<span class="number">0</span>]*x-b+v) / w[<span class="number">1</span>]</div><div class="line">        </div><div class="line">        datarange = (self.min_feature_value*<span class="number">0.9</span>, self.max_feature_value*<span class="number">1.1</span>)</div><div class="line">        hyp_x_min = datarange[<span class="number">0</span>]</div><div class="line">        hyp_x_max = datarange[<span class="number">1</span>]</div><div class="line">        </div><div class="line">        psv1 = hyperplane(hyp_x_min, self.w, self.b, <span class="number">1</span>)</div><div class="line">        psv2 = hyperplane(hyp_x_max, self.w, self.b, <span class="number">1</span>)</div><div class="line">        self.ax.plot([hyp_x_min, hyp_x_max], [psv1,psv2], <span class="string">'k'</span>)</div><div class="line">        </div><div class="line">        nsv1 = hyperplane(hyp_x_min, self.w, self.b, <span class="number">-1</span>)</div><div class="line">        nsv2 = hyperplane(hyp_x_max, self.w, self.b, <span class="number">-1</span>)</div><div class="line">        self.ax.plot([hyp_x_min, hyp_x_max], [nsv1,nsv2], <span class="string">'k'</span>)</div><div class="line">        </div><div class="line">        db1 = hyperplane(hyp_x_min, self.w, self.b, <span class="number">0</span>)</div><div class="line">        db2 = hyperplane(hyp_x_max, self.w, self.b, <span class="number">0</span>)</div><div class="line">        self.ax.plot([hyp_x_min, hyp_x_max], [db1, db2], <span class="string">'y--'</span>)</div><div class="line">        </div><div class="line">        plt.show()</div><div class="line"></div><div class="line"><span class="comment">#训练数据集</span></div><div class="line">data_dict = &#123;<span class="number">-1</span>:np.array([[<span class="number">1</span>,<span class="number">7</span>],</div><div class="line">                          [<span class="number">2</span>,<span class="number">8</span>],</div><div class="line">                          [<span class="number">3</span>,<span class="number">8</span>],]),</div><div class="line">             </div><div class="line">             <span class="number">1</span>:np.array([[<span class="number">5</span>,<span class="number">1</span>],</div><div class="line">                         [<span class="number">6</span>,<span class="number">-1</span>],</div><div class="line">                         [<span class="number">7</span>,<span class="number">3</span>],])&#125;</div><div class="line"></div><div class="line">svm = Support_Vector_Machine()</div><div class="line">svm.fit(data=data_dict)</div><div class="line"></div><div class="line"><span class="comment">#预测数据集</span></div><div class="line">predict_us = [[<span class="number">0</span>,<span class="number">10</span>],</div><div class="line">              [<span class="number">1</span>,<span class="number">3</span>],</div><div class="line">              [<span class="number">3</span>,<span class="number">4</span>],</div><div class="line">              [<span class="number">3</span>,<span class="number">5</span>],</div><div class="line">              [<span class="number">5</span>,<span class="number">5</span>],</div><div class="line">              [<span class="number">5</span>,<span class="number">6</span>],</div><div class="line">              [<span class="number">6</span>,<span class="number">-5</span>],</div><div class="line">              [<span class="number">5</span>,<span class="number">8</span>]]</div><div class="line"></div><div class="line"><span class="keyword">for</span> p <span class="keyword">in</span> predict_us:</div><div class="line">    svm.predict(p)</div><div class="line"></div><div class="line">svm.visualize()</div></pre></td></tr></table></figure><p>这样一来就完成了算法的实现了，可视化的图表如下：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-26%20%E4%B8%8B%E5%8D%887.49.15.png" alt=""></p><blockquote><p>实际上这只是算法的简单实现，许多的细节并没有照顾到。而且这个算法的基础必须要牢固，不然很难理解上面的代码。</p></blockquote><h1 id="SVM进阶"><a href="#SVM进阶" class="headerlink" title="SVM进阶"></a>SVM进阶</h1><p>相关到<code>核函数</code>，<code>硬间隔最大化</code>，<code>软间隔最大化</code>等知识，其中的<code>核函数</code>，<code>软间隔最大化</code>针对于非线性数据(即线性不可分)，<code>硬间隔最大化</code>针对于线性可分数据类型，这需要自行去了解、理解。在上面说的书籍中可以找到相关的知识。</p><p>以下是关于<code>核函数</code>，<code>软间隔最大化</code>的针对于非线性数据python代码的实现，可以理解为SVM的底层实现的一部分，可以更好的理解内部实现的于原理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div><div class="line">251</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Mathieu Blondel, September 2010</span></div><div class="line"><span class="comment"># License: BSD 3 clause</span></div><div class="line"><span class="comment"># http://www.mblondel.org/journal/2010/09/19/support-vector-machines-in-python/</span></div><div class="line"></div><div class="line"><span class="comment"># visualizing what translating to another dimension does</span></div><div class="line"><span class="comment"># and bringing back to 2D:</span></div><div class="line"><span class="comment"># https://www.youtube.com/watch?v=3liCbRZPrZA</span></div><div class="line"></div><div class="line"><span class="comment"># Docs: http://cvxopt.org/userguide/coneprog.html#quadratic-programming</span></div><div class="line"><span class="comment"># Docs qp example: http://cvxopt.org/examples/tutorial/qp.html</span></div><div class="line"></div><div class="line"><span class="comment"># Nice tutorial:</span></div><div class="line"><span class="comment"># https://courses.csail.mit.edu/6.867/wiki/images/a/a7/Qp-cvxopt.pdf</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> linalg</div><div class="line"><span class="keyword">import</span> cvxopt</div><div class="line"><span class="keyword">import</span> cvxopt.solvers</div><div class="line">             </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_kernel</span><span class="params">(x1, x2)</span>:</span></div><div class="line">    <span class="keyword">return</span> np.dot(x1, x2)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">polynomial_kernel</span><span class="params">(x, y, p=<span class="number">3</span>)</span>:</span></div><div class="line">    <span class="keyword">return</span> (<span class="number">1</span> + np.dot(x, y)) ** p</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">gaussian_kernel</span><span class="params">(x, y, sigma=<span class="number">5.0</span>)</span>:</span></div><div class="line">    <span class="keyword">return</span> np.exp(-linalg.norm(x-y)**<span class="number">2</span> / (<span class="number">2</span> * (sigma ** <span class="number">2</span>)))</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">SVM</span><span class="params">(object)</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, kernel=linear_kernel, C=None)</span>:</span></div><div class="line">        self.kernel = kernel</div><div class="line">        self.C = C</div><div class="line">        <span class="keyword">if</span> self.C <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>: self.C = float(self.C)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y)</span>:</span></div><div class="line">        n_samples, n_features = X.shape</div><div class="line"></div><div class="line">        <span class="comment"># Gram matrix</span></div><div class="line">        K = np.zeros((n_samples, n_samples))</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(n_samples):</div><div class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(n_samples):</div><div class="line">                K[i,j] = self.kernel(X[i], X[j])</div><div class="line"></div><div class="line">        P = cvxopt.matrix(np.outer(y,y) * K)</div><div class="line">        q = cvxopt.matrix(np.ones(n_samples) * <span class="number">-1</span>)</div><div class="line">        A = cvxopt.matrix(y, (<span class="number">1</span>,n_samples))</div><div class="line">        b = cvxopt.matrix(<span class="number">0.0</span>)</div><div class="line"></div><div class="line">        <span class="keyword">if</span> self.C <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            G = cvxopt.matrix(np.diag(np.ones(n_samples) * <span class="number">-1</span>))</div><div class="line">            h = cvxopt.matrix(np.zeros(n_samples))</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            tmp1 = np.diag(np.ones(n_samples) * <span class="number">-1</span>)</div><div class="line">            tmp2 = np.identity(n_samples)</div><div class="line">            G = cvxopt.matrix(np.vstack((tmp1, tmp2)))</div><div class="line">            tmp1 = np.zeros(n_samples)</div><div class="line">            tmp2 = np.ones(n_samples) * self.C</div><div class="line">            h = cvxopt.matrix(np.hstack((tmp1, tmp2)))</div><div class="line"></div><div class="line">        <span class="comment"># solve QP problem</span></div><div class="line">        solution = cvxopt.solvers.qp(P, q, G, h, A, b)</div><div class="line"></div><div class="line">        <span class="comment"># Lagrange multipliers</span></div><div class="line">        a = np.ravel(solution[<span class="string">'x'</span>])</div><div class="line"></div><div class="line">        <span class="comment"># Support vectors have non zero lagrange multipliers</span></div><div class="line">        sv = a &gt; <span class="number">1e-5</span></div><div class="line">        ind = np.arange(len(a))[sv]</div><div class="line">        self.a = a[sv]</div><div class="line">        self.sv = X[sv]</div><div class="line">        self.sv_y = y[sv]</div><div class="line">        print(<span class="string">"%d support vectors out of %d points"</span> % (len(self.a), n_samples))</div><div class="line"></div><div class="line">        <span class="comment"># Intercept</span></div><div class="line">        self.b = <span class="number">0</span></div><div class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> range(len(self.a)):</div><div class="line">            self.b += self.sv_y[n]</div><div class="line">            self.b -= np.sum(self.a * self.sv_y * K[ind[n],sv])</div><div class="line">        self.b /= len(self.a)</div><div class="line"></div><div class="line">        <span class="comment"># Weight vector</span></div><div class="line">        <span class="keyword">if</span> self.kernel == linear_kernel:</div><div class="line">            self.w = np.zeros(n_features)</div><div class="line">            <span class="keyword">for</span> n <span class="keyword">in</span> range(len(self.a)):</div><div class="line">                self.w += self.a[n] * self.sv_y[n] * self.sv[n]</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            self.w = <span class="keyword">None</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">project</span><span class="params">(self, X)</span>:</span></div><div class="line">        <span class="keyword">if</span> self.w <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">            <span class="keyword">return</span> np.dot(X, self.w) + self.b</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            y_predict = np.zeros(len(X))</div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(X)):</div><div class="line">                s = <span class="number">0</span></div><div class="line">                <span class="keyword">for</span> a, sv_y, sv <span class="keyword">in</span> zip(self.a, self.sv_y, self.sv):</div><div class="line">                    s += a * sv_y * self.kernel(X[i], sv)</div><div class="line">                y_predict[i] = s</div><div class="line">            <span class="keyword">return</span> y_predict + self.b</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X)</span>:</span></div><div class="line">        <span class="keyword">return</span> np.sign(self.project(X))</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">    <span class="keyword">import</span> pylab <span class="keyword">as</span> pl</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gen_lin_separable_data</span><span class="params">()</span>:</span></div><div class="line">        <span class="comment"># generate training data in the 2-d case</span></div><div class="line">        mean1 = np.array([<span class="number">0</span>, <span class="number">2</span>])</div><div class="line">        mean2 = np.array([<span class="number">2</span>, <span class="number">0</span>])</div><div class="line">        cov = np.array([[<span class="number">0.8</span>, <span class="number">0.6</span>], [<span class="number">0.6</span>, <span class="number">0.8</span>]])</div><div class="line">        X1 = np.random.multivariate_normal(mean1, cov, <span class="number">100</span>)</div><div class="line">        y1 = np.ones(len(X1))</div><div class="line">        X2 = np.random.multivariate_normal(mean2, cov, <span class="number">100</span>)</div><div class="line">        y2 = np.ones(len(X2)) * <span class="number">-1</span></div><div class="line">        <span class="keyword">return</span> X1, y1, X2, y2</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gen_non_lin_separable_data</span><span class="params">()</span>:</span></div><div class="line">        mean1 = [<span class="number">-1</span>, <span class="number">2</span>]</div><div class="line">        mean2 = [<span class="number">1</span>, <span class="number">-1</span>]</div><div class="line">        mean3 = [<span class="number">4</span>, <span class="number">-4</span>]</div><div class="line">        mean4 = [<span class="number">-4</span>, <span class="number">4</span>]</div><div class="line">        cov = [[<span class="number">1.0</span>,<span class="number">0.8</span>], [<span class="number">0.8</span>, <span class="number">1.0</span>]]</div><div class="line">        X1 = np.random.multivariate_normal(mean1, cov, <span class="number">50</span>)</div><div class="line">        X1 = np.vstack((X1, np.random.multivariate_normal(mean3, cov, <span class="number">50</span>)))</div><div class="line">        y1 = np.ones(len(X1))</div><div class="line">        X2 = np.random.multivariate_normal(mean2, cov, <span class="number">50</span>)</div><div class="line">        X2 = np.vstack((X2, np.random.multivariate_normal(mean4, cov, <span class="number">50</span>)))</div><div class="line">        y2 = np.ones(len(X2)) * <span class="number">-1</span></div><div class="line">        <span class="keyword">return</span> X1, y1, X2, y2</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gen_lin_separable_overlap_data</span><span class="params">()</span>:</span></div><div class="line">        <span class="comment"># generate training data in the 2-d case</span></div><div class="line">        mean1 = np.array([<span class="number">0</span>, <span class="number">2</span>])</div><div class="line">        mean2 = np.array([<span class="number">2</span>, <span class="number">0</span>])</div><div class="line">        cov = np.array([[<span class="number">1.5</span>, <span class="number">1.0</span>], [<span class="number">1.0</span>, <span class="number">1.5</span>]])</div><div class="line">        X1 = np.random.multivariate_normal(mean1, cov, <span class="number">100</span>)</div><div class="line">        y1 = np.ones(len(X1))</div><div class="line">        X2 = np.random.multivariate_normal(mean2, cov, <span class="number">100</span>)</div><div class="line">        y2 = np.ones(len(X2)) * <span class="number">-1</span></div><div class="line">        <span class="keyword">return</span> X1, y1, X2, y2</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">split_train</span><span class="params">(X1, y1, X2, y2)</span>:</span></div><div class="line">        X1_train = X1[:<span class="number">90</span>]</div><div class="line">        y1_train = y1[:<span class="number">90</span>]</div><div class="line">        X2_train = X2[:<span class="number">90</span>]</div><div class="line">        y2_train = y2[:<span class="number">90</span>]</div><div class="line">        X_train = np.vstack((X1_train, X2_train))</div><div class="line">        y_train = np.hstack((y1_train, y2_train))</div><div class="line">        <span class="keyword">return</span> X_train, y_train</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">split_test</span><span class="params">(X1, y1, X2, y2)</span>:</span></div><div class="line">        X1_test = X1[<span class="number">90</span>:]</div><div class="line">        y1_test = y1[<span class="number">90</span>:]</div><div class="line">        X2_test = X2[<span class="number">90</span>:]</div><div class="line">        y2_test = y2[<span class="number">90</span>:]</div><div class="line">        X_test = np.vstack((X1_test, X2_test))</div><div class="line">        y_test = np.hstack((y1_test, y2_test))</div><div class="line">        <span class="keyword">return</span> X_test, y_test</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">plot_margin</span><span class="params">(X1_train, X2_train, clf)</span>:</span></div><div class="line">        <span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(x, w, b, c=<span class="number">0</span>)</span>:</span></div><div class="line">            <span class="comment"># given x, return y such that [x,y] in on the line</span></div><div class="line">            <span class="comment"># w.x + b = c</span></div><div class="line">            <span class="keyword">return</span> (-w[<span class="number">0</span>] * x - b + c) / w[<span class="number">1</span>]</div><div class="line"></div><div class="line">        pl.plot(X1_train[:,<span class="number">0</span>], X1_train[:,<span class="number">1</span>], <span class="string">"ro"</span>)</div><div class="line">        pl.plot(X2_train[:,<span class="number">0</span>], X2_train[:,<span class="number">1</span>], <span class="string">"bo"</span>)</div><div class="line">        pl.scatter(clf.sv[:,<span class="number">0</span>], clf.sv[:,<span class="number">1</span>], s=<span class="number">100</span>, c=<span class="string">"g"</span>)</div><div class="line"></div><div class="line">        <span class="comment"># w.x + b = 0</span></div><div class="line">        a0 = <span class="number">-4</span>; a1 = f(a0, clf.w, clf.b)</div><div class="line">        b0 = <span class="number">4</span>; b1 = f(b0, clf.w, clf.b)</div><div class="line">        pl.plot([a0,b0], [a1,b1], <span class="string">"k"</span>)</div><div class="line"></div><div class="line">        <span class="comment"># w.x + b = 1</span></div><div class="line">        a0 = <span class="number">-4</span>; a1 = f(a0, clf.w, clf.b, <span class="number">1</span>)</div><div class="line">        b0 = <span class="number">4</span>; b1 = f(b0, clf.w, clf.b, <span class="number">1</span>)</div><div class="line">        pl.plot([a0,b0], [a1,b1], <span class="string">"k--"</span>)</div><div class="line"></div><div class="line">        <span class="comment"># w.x + b = -1</span></div><div class="line">        a0 = <span class="number">-4</span>; a1 = f(a0, clf.w, clf.b, <span class="number">-1</span>)</div><div class="line">        b0 = <span class="number">4</span>; b1 = f(b0, clf.w, clf.b, <span class="number">-1</span>)</div><div class="line">        pl.plot([a0,b0], [a1,b1], <span class="string">"k--"</span>)</div><div class="line"></div><div class="line">        pl.axis(<span class="string">"tight"</span>)</div><div class="line">        pl.show()</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">plot_contour</span><span class="params">(X1_train, X2_train, clf)</span>:</span></div><div class="line">        pl.plot(X1_train[:,<span class="number">0</span>], X1_train[:,<span class="number">1</span>], <span class="string">"ro"</span>)</div><div class="line">        pl.plot(X2_train[:,<span class="number">0</span>], X2_train[:,<span class="number">1</span>], <span class="string">"bo"</span>)</div><div class="line">        pl.scatter(clf.sv[:,<span class="number">0</span>], clf.sv[:,<span class="number">1</span>], s=<span class="number">100</span>, c=<span class="string">"g"</span>)</div><div class="line"></div><div class="line">        X1, X2 = np.meshgrid(np.linspace(<span class="number">-6</span>,<span class="number">6</span>,<span class="number">50</span>), np.linspace(<span class="number">-6</span>,<span class="number">6</span>,<span class="number">50</span>))</div><div class="line">        X = np.array([[x1, x2] <span class="keyword">for</span> x1, x2 <span class="keyword">in</span> zip(np.ravel(X1), np.ravel(X2))])</div><div class="line">        Z = clf.project(X).reshape(X1.shape)</div><div class="line">        pl.contour(X1, X2, Z, [<span class="number">0.0</span>], colors=<span class="string">'k'</span>, linewidths=<span class="number">1</span>, origin=<span class="string">'lower'</span>)</div><div class="line">        pl.contour(X1, X2, Z + <span class="number">1</span>, [<span class="number">0.0</span>], colors=<span class="string">'grey'</span>, linewidths=<span class="number">1</span>, origin=<span class="string">'lower'</span>)</div><div class="line">        pl.contour(X1, X2, Z - <span class="number">1</span>, [<span class="number">0.0</span>], colors=<span class="string">'grey'</span>, linewidths=<span class="number">1</span>, origin=<span class="string">'lower'</span>)</div><div class="line"></div><div class="line">        pl.axis(<span class="string">"tight"</span>)</div><div class="line">        pl.show()</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_linear</span><span class="params">()</span>:</span></div><div class="line">        X1, y1, X2, y2 = gen_lin_separable_data()</div><div class="line">        X_train, y_train = split_train(X1, y1, X2, y2)</div><div class="line">        X_test, y_test = split_test(X1, y1, X2, y2)</div><div class="line"></div><div class="line">        clf = SVM()</div><div class="line">        clf.fit(X_train, y_train)</div><div class="line"></div><div class="line">        y_predict = clf.predict(X_test)</div><div class="line">        correct = np.sum(y_predict == y_test)</div><div class="line">        print(<span class="string">"%d out of %d predictions correct"</span> % (correct, len(y_predict)))</div><div class="line"></div><div class="line">        plot_margin(X_train[y_train==<span class="number">1</span>], X_train[y_train==<span class="number">-1</span>], clf)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_non_linear</span><span class="params">()</span>:</span></div><div class="line">        X1, y1, X2, y2 = gen_non_lin_separable_data()</div><div class="line">        X_train, y_train = split_train(X1, y1, X2, y2)</div><div class="line">        X_test, y_test = split_test(X1, y1, X2, y2)</div><div class="line"></div><div class="line">        clf = SVM(polynomial_kernel)</div><div class="line">        clf.fit(X_train, y_train)</div><div class="line"></div><div class="line">        y_predict = clf.predict(X_test)</div><div class="line">        correct = np.sum(y_predict == y_test)</div><div class="line">        print(<span class="string">"%d out of %d predictions correct"</span> % (correct, len(y_predict)))</div><div class="line"></div><div class="line">        plot_contour(X_train[y_train==<span class="number">1</span>], X_train[y_train==<span class="number">-1</span>], clf)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_soft</span><span class="params">()</span>:</span></div><div class="line">        X1, y1, X2, y2 = gen_lin_separable_overlap_data()</div><div class="line">        X_train, y_train = split_train(X1, y1, X2, y2)</div><div class="line">        X_test, y_test = split_test(X1, y1, X2, y2)</div><div class="line"></div><div class="line">        clf = SVM(C=<span class="number">1000.1</span>)</div><div class="line">        clf.fit(X_train, y_train)</div><div class="line"></div><div class="line">        y_predict = clf.predict(X_test)</div><div class="line">        correct = np.sum(y_predict == y_test)</div><div class="line">        print(<span class="string">"%d out of %d predictions correct"</span> % (correct, len(y_predict)))</div><div class="line"></div><div class="line">        plot_contour(X_train[y_train==<span class="number">1</span>], X_train[y_train==<span class="number">-1</span>], clf)</div><div class="line"></div><div class="line">        </div><div class="line">    <span class="comment">#test_linear()</span></div><div class="line">    <span class="comment">#test_non_linear()</span></div><div class="line">    test_soft()</div></pre></td></tr></table></figure><blockquote><p><strong>具体相关说明可见<a href="https://pythonprogramming.net/soft-margin-kernel-cvxopt-svm-machine-learning-tutorial/?completed=/soft-margin-svm-machine-learning-tutorial/" target="_blank" rel="external">对应的课程地址</a>。</strong></p></blockquote><p>更多的铺助链接：</p><ul><li><p><a href="https://cvxopt.org/userguide/intro.html" target="_blank" rel="external">pythonC最优化模块库：VXOPT二次编程文档</a></p></li><li><p><a href="https://courses.csail.mit.edu/6.867/wiki/images/a/a7/Qp-cvxopt.pdf" target="_blank" rel="external">CVXOPT进行二次编程的更深入的示例</a></p></li><li><p><a href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/" target="_blank" rel="external">用于支持向量机优化的库</a></p></li></ul><h1 id="SVM的应用"><a href="#SVM的应用" class="headerlink" title="SVM的应用"></a>SVM的应用</h1><p>还是利用了在上个文章<a href="http://liujunworld.com/2018/10/21/python机器学习系列：K近邻算法(KNN" target="_blank" rel="external">python机器学习系列：K近邻算法(KNN)的实现及应用</a>的实现及应用/)的实际数据集。只是将<code>sklearn</code>模块中的现成的拿来用了。</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing, neighbors, svm</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"></div><div class="line">df = pd.read_csv(<span class="string">'breast-cancer-wisconsin.data'</span>)</div><div class="line"></div><div class="line">df.replace(<span class="string">'?'</span>,<span class="number">-99999</span>,inplace=<span class="keyword">True</span>) <span class="comment">#替换异常值为-99999，inplace=True表示文件中也将进行同步更改</span></div><div class="line"></div><div class="line"><span class="comment">#去除不相关的特征列</span></div><div class="line">df.drop([<span class="string">'Id'</span>], <span class="number">1</span>, inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">X = np.array(df.drop([<span class="string">'Class'</span>], <span class="number">1</span>)) <span class="comment">#去除标签列，自制数据集</span></div><div class="line">y = np.array(df[<span class="string">'Class'</span>])</div><div class="line"></div><div class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</div><div class="line"></div><div class="line">clf = svm.SVC() <span class="comment">#分类SVM</span></div><div class="line">clf.fit(X_train, y_train)</div><div class="line"></div><div class="line">accuracy = clf.score(X_test, y_test) <span class="comment">#得出准确值</span></div><div class="line">print(accuracy)</div><div class="line"></div><div class="line"><span class="comment">#创建数据集来进行简单的预测</span></div><div class="line">example_maasurse = np.array([[<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>],[<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>]])</div><div class="line"></div><div class="line">example_maasurse = example_maasurse.reshape(len(example_maasurse),<span class="number">-1</span>) <span class="comment">#重朔,其中的-1可理解为，只想输出2行的情况下，后面的列我写上-1由numpy自行得出对应相符的数组，有点抽象...其实也就那么回事</span></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">prediction = clf.predict(example_maasurse)</div><div class="line">print(prediction)</div></pre></td></tr></table></figure><p>结果跟上篇介绍的用<code>KNN</code>的结果几乎一样，就不展示了。</p><p>关于现成算法的参数的使用可移步：</p><ul><li><a href="http://sklearn.apachecn.org/cn/stable/index.html" target="_blank" rel="external">sklearn中文主页</a></li></ul><p>这样这篇文章基本上就这样了，需要更新的话再来补充。</p>]]></content>
    
    <summary type="html">
    
      &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/HHUqhVzctQE&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; encrypted-media&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;我记录下的这些东西，如果是有哪些不懂得地方，我强烈建议参考我在&lt;a href=&quot;http://liujunworld.com/2018/09/16/%E5%88%9D%E5%AD%A6%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8D%97/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;这里的书籍&lt;/a&gt;。另外还有&lt;a href=&quot;https://github.com/apachecn/AiLearning&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;《机器学习实战》&lt;/a&gt;，&lt;a href=&quot;https://github.com/exacity/deeplearningbook-chinese&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;《深度学习》&lt;/a&gt;这本花书等，利用好搜索引擎也是一大好利器。&lt;/p&gt;
&lt;p&gt;关于这篇文章，我还是和以前记录相关的机器学习知识之类篇章一样的风格。&lt;/p&gt;
&lt;p&gt;不懂可进入&lt;a href=&quot;https://pythonprogramming.net/support-vector-machine-intro-machine-learning-tutorial/?completed=/final-thoughts-knn-machine-learning-tutorial/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;这里的对应的教程&lt;/a&gt;，看不懂可借助翻译插件/软件(实际上借助这些看起来轻松多了，看英文头疼的厉害，如果是对于初学者)。&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>解决eclipse中运行Django时出现错误Django not found</title>
    <link href="https://liujunjie11.github.io/2018/10/21/%E8%A7%A3%E5%86%B3eclipse%E4%B8%AD%E8%BF%90%E8%A1%8CDjango%E6%97%B6%E5%87%BA%E7%8E%B0%E9%94%99%E8%AF%AFDjango-not-found/"/>
    <id>https://liujunjie11.github.io/2018/10/21/解决eclipse中运行Django时出现错误Django-not-found/</id>
    <published>2018-10-21T12:07:13.000Z</published>
    <updated>2018-10-21T12:50:55.045Z</updated>
    
    <content type="html"><![CDATA[<p>打算在<em>eclipse</em>中运行<em>Django</em>项目，结果发现出现了错误Django not found，如下图(网上找的一张，忘记截图了..)：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/20151111171637700.png" alt=""></p><blockquote><p>图片来源：<a href="https://blog.csdn.net/wlsyn/article/details/49784263?utm_source=blogxgwz2" target="_blank" rel="external">https://blog.csdn.net/wlsyn/article/details/49784263?utm_source=blogxgwz2</a></p></blockquote><p>试了一些网上所谓的重新嵌入解释器目录的方法，还有重装<em>Django</em>的方法，都没有什么用。</p><a id="more"></a><p>但是我真的不想放弃啊，eclipse那么好用，而且在其中运行Django是那么的方便…</p><h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><h2 id="git下载GitHub上的Django"><a href="#git下载GitHub上的Django" class="headerlink" title="git下载GitHub上的Django"></a>git下载GitHub上的Django</h2><p>使用命令行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git <span class="built_in">clone</span> https://github.com/django/django.git</div></pre></td></tr></table></figure><blockquote><p>参考：<a href="https://www.djangoproject.com/download/" target="_blank" rel="external">https://www.djangoproject.com/download/</a></p></blockquote><h2 id="移动安装包"><a href="#移动安装包" class="headerlink" title="移动安装包"></a>移动安装包</h2><p>之后将下载好的移动到要用到的python版本中的<code>site-packages</code>中，如我的目录<code>/anaconda3/lib/python3.6/site-packages/</code>。</p><h2 id="eclipse配置"><a href="#eclipse配置" class="headerlink" title="eclipse配置"></a>eclipse配置</h2><p>之后打开eclipse配置界面，看图吧，一图胜千言。</p><p><img src="http://owudg3xs2.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-21%20%E4%B8%8B%E5%8D%888.16.27.png" alt=""></p><p>之后应用、关闭。</p><p>然后再建立Django项目时就不会再出现错误Django not found了。</p><p>测试和建立项目过程不妨可以参考以下链接：</p><blockquote><p><a href="http://www.cnblogs.com/lanxuezaipiao/p/3283932.html" target="_blank" rel="external">http://www.cnblogs.com/lanxuezaipiao/p/3283932.html</a></p></blockquote><p>我就不重复制造轮子了。</p><p>测试成功之后：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-21%20%E4%B8%8B%E5%8D%888.04.02.png" alt=""></p><p>Yes,it`s successful!</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;打算在&lt;em&gt;eclipse&lt;/em&gt;中运行&lt;em&gt;Django&lt;/em&gt;项目，结果发现出现了错误Django not found，如下图(网上找的一张，忘记截图了..)：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://owudg3xs2.bkt.clouddn.com/20151111171637700.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;图片来源：&lt;a href=&quot;https://blog.csdn.net/wlsyn/article/details/49784263?utm_source=blogxgwz2&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://blog.csdn.net/wlsyn/article/details/49784263?utm_source=blogxgwz2&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;试了一些网上所谓的重新嵌入解释器目录的方法，还有重装&lt;em&gt;Django&lt;/em&gt;的方法，都没有什么用。&lt;/p&gt;
    
    </summary>
    
      <category term="错误解决" scheme="https://liujunjie11.github.io/categories/%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3/"/>
    
    
      <category term="错误解决" scheme="https://liujunjie11.github.io/tags/%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3/"/>
    
  </entry>
  
  <entry>
    <title>python机器学习系列：K近邻算法(KNN)的实现及应用</title>
    <link href="https://liujunjie11.github.io/2018/10/21/python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%9AK%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95(KNN)%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%BA%94%E7%94%A8/"/>
    <id>https://liujunjie11.github.io/2018/10/21/python机器学习系列：K近邻算法(KNN)的实现及应用/</id>
    <published>2018-10-21T05:43:00.000Z</published>
    <updated>2018-10-26T08:39:07.164Z</updated>
    
    <content type="html"><![CDATA[<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/r_D5TTV9-2c" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe><p>还是老样子，这篇文章不适合纯粹的小白，仅仅注重实践，基础知识说的比较浅，基本上一笔带过。</p><p>我在作者的原代码和数据上进行了一点修改以符合当今的实际情况。</p><p>此篇文章将实现K近邻算法的基本原理，以及实现K邻近算法并且应用到实际数据集之中，之后会有一个实战项目。<br><a id="more"></a></p><h1 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h1><h2 id="欧几里得原理以及代码实现"><a href="#欧几里得原理以及代码实现" class="headerlink" title="欧几里得原理以及代码实现"></a>欧几里得原理以及代码实现</h2><p>欧几里得公式：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/euclidean-distance.png" alt=""></p><blockquote><p>实际上很简单，想想求解两点值之间的距离的问题吧…</p></blockquote><p>代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt</div><div class="line"></div><div class="line"><span class="comment">#数据自制</span></div><div class="line">feature_1 = [<span class="number">1</span>,<span class="number">3</span>]</div><div class="line">feature_2 = [<span class="number">2</span>,<span class="number">6</span>]</div><div class="line"></div><div class="line">euclidean_distance = sqrt((variable_2[<span class="number">0</span>]-variable_1[<span class="number">0</span>])**<span class="number">2</span> + (variable_2[<span class="number">1</span>]-variable_1[<span class="number">1</span>])**<span class="number">2</span>)</div><div class="line">print(euclidean_distance)</div></pre></td></tr></table></figure><blockquote><p>这里是中文相关一节的地址：<a href="https://www.yxgapp.com/video/c8426884-2b56-494f-a274-0aa3105503f1.html" target="_blank" rel="external">https://www.yxgapp.com/video/c8426884-2b56-494f-a274-0aa3105503f1.html</a></p></blockquote><h2 id="实现KNN"><a href="#实现KNN" class="headerlink" title="实现KNN"></a>实现KNN</h2><p>KNN的工作机制(来自志华哥的《机器学习》)：</p><blockquote><p>给定测试样本，基于某种距离度量找出训练集中与其最近的k个训练样本，然后基于这k个“邻居”的信息来进行预测，通常，在分类任务中可使用“投票法”(在本文当中明显就是分类问题)，即选择这k个样本中出现最多的类别标记作为预测结果；在回归任务中可使用“平均法”，即将这k个样本的实值输出标记的平均值作为预测结果；还可基于距离远近进行加权平均或加权投票，距离越近的样本权重越大。</p></blockquote><p>这样就能好理解之后写的算法了，这毕竟不是给纯粹的小白写的。</p><p>简单说说下面写的代码的原理：通过原有的数值与新的数值代入欧几里得原理得出各点与新数值的距离，然后对这些数值进行从小到大排序并且选取前面K个数值(即所谓的K近邻)作为选择值，之后选择第一个最近的(距离最小的)作为新数据的标签。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> warnings</div><div class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</div><div class="line"></div><div class="line"><span class="comment">#自制数据集</span></div><div class="line">dataset = &#123;<span class="string">'k'</span>:[[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">3</span>],[<span class="number">3</span>,<span class="number">1</span>]], <span class="string">'r'</span>:[[<span class="number">6</span>,<span class="number">5</span>],[<span class="number">7</span>,<span class="number">7</span>],[<span class="number">8</span>,<span class="number">6</span>]]&#125; <span class="comment">#这个字典的key值为何这样命名看到下面就知道了，作为color参数的输入</span></div><div class="line">new_features = [<span class="number">5</span>,<span class="number">7</span>]</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">k_nearest_neighbors</span><span class="params">(data, predict_feature, k=<span class="number">3</span>)</span>:</span> <span class="comment">#特别说明：k值在sklearn中的模型默认为5</span></div><div class="line">    <span class="keyword">if</span> len(data) &gt;= k:</div><div class="line">        warnings.warn(<span class="string">'你这样就没有意义了...笨猪！'</span>)</div><div class="line">    distances = []</div><div class="line">    <span class="keyword">for</span> group <span class="keyword">in</span> data:</div><div class="line">        <span class="keyword">for</span> features <span class="keyword">in</span> data[group]: <span class="comment">#这两段代码与for group, features in dateset.items():意义一致</span></div><div class="line">            euclidean_distance = np.linalg.norm(np.array(features)-np.array(predict_feature)) <span class="comment">#使用numpy的相关的模块会显得更加的快速以及更加的高级</span></div><div class="line">            distances.append([euclidean_distance, group])</div><div class="line">            </div><div class="line">    votes = [i[<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> sorted(distances)[:k]] <span class="comment">#从小到大的排序，选择出现在前面的K个样本作为投票得出的结果</span></div><div class="line">    vote_result = Counter(votes).most_common(<span class="number">1</span>)[<span class="number">0</span>][<span class="number">0</span>]</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> vote_result</div><div class="line"></div><div class="line">result = k_nearest_neighbors(dataset, new_features, k=<span class="number">3</span>)</div><div class="line">print(result)</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line"><span class="comment">#可通过图表展示出结果信息</span></div><div class="line">[[plt.scatter(ii[<span class="number">0</span>],ii[<span class="number">1</span>], s=<span class="number">20</span>, color=i) <span class="keyword">for</span> ii <span class="keyword">in</span> dateset[i]] <span class="keyword">for</span> i <span class="keyword">in</span> dateset] <span class="comment">#color输出为'r'，可见上面作者命名的含义</span></div><div class="line"></div><div class="line">result = k_nearest_neighbors(dataset, new_features)</div><div class="line">plt.scatter(new_features[<span class="number">0</span>], new_features[<span class="number">1</span>], s=<span class="number">20</span>, color = result) <span class="comment">#color输出为'r'，可见上面作者命名的含义</span></div><div class="line">plt.show()</div></pre></td></tr></table></figure><p>可帮助理解的链接：</p><ul><li><p><a href="http://www.pythoner.com/205.html" target="_blank" rel="external">Python标准库——collections模块的Counter类</a></p></li><li><p><a href="https://blog.csdn.net/hqh131360239/article/details/79061535" target="_blank" rel="external">np.linalg.norm(求范数)</a></p></li></ul><blockquote><p>看完并且理解了上面的代码之后，你就会发现<strong>KNN算法为何对于异常值不敏感了吧，因为异常值太大，得出的距离也很大，所以一般在投票选择排序时就被out了。</strong></p></blockquote><h2 id="展示图表以及运行结果"><a href="#展示图表以及运行结果" class="headerlink" title="展示图表以及运行结果"></a>展示图表以及运行结果</h2><p>如图：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-22%20%E4%B8%8B%E5%8D%885.55.39.png" alt=""></p><p>这样就一目了然了。</p><h1 id="项目实践"><a href="#项目实践" class="headerlink" title="项目实践"></a>项目实践</h1><ul><li>数据来源：<a href="https://archive.ics.uci.edu/ml/datasets.html" target="_blank" rel="external">https://archive.ics.uci.edu/ml/datasets.html</a>﻿</li></ul><p>这是加州大学的一个用于机器学习数据的仓库，基本上是开放数据给我们使用的。</p><ul><li><p>项目使用的数据下载页面：<a href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic" target="_blank" rel="external">https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic</a>)</p></li><li><p>项目使用的数据下载链接：<a href="https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/" target="_blank" rel="external">https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/</a></p></li></ul><p>下载其中的<code>breast-cancer-wisconsin.data</code>，查看特征系数情况查看<code>breast-cancer-wisconsin.names</code>。</p><p>因为需要对数据进行一些特征增加的修改，所以我贴上修改后的数据在下，也可查看上面的作者的YouTube教程来进行修改。</p><ul><li>修改后的数据集：<a href="https://pan.baidu.com/s/1J-G6ESB-JXFfBk8yTl8lmw" target="_blank" rel="external">https://pan.baidu.com/s/1J-G6ESB-JXFfBk8yTl8lmw</a></li></ul><blockquote><p>也就是添加了特征名而已。</p></blockquote><p>这是一个关于乳腺癌判断的数据集。从<code>breast-cancer-wisconsin.names</code>中可得知缺失的数据由<code>&#39;?&#39;</code>来表示。</p><blockquote><ol><li><p>Missing attribute values: 16</p><p>There are 16 instances in Groups 1 to 6 that contain a single missing (i.e., unavailable) attribute value, now denoted by “?”.  </p></li></ol></blockquote><p>这样一来就能开始整个项目了。</p><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>数据集中的特征意喻：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">Attribute Information: (class attribute has been moved to last column)</div><div class="line"></div><div class="line">   <span class="comment">#  Attribute                     Domain</span></div><div class="line">   -- -----------------------------------------</div><div class="line">   1. Sample code number            id number</div><div class="line">   2. Clump Thickness               1 - 10</div><div class="line">   3. Uniformity of Cell Size       1 - 10</div><div class="line">   4. Uniformity of Cell Shape      1 - 10</div><div class="line">   5. Marginal Adhesion             1 - 10</div><div class="line">   6. Single Epithelial Cell Size   1 - 10</div><div class="line">   7. Bare Nuclei                   1 - 10</div><div class="line">   8. Bland Chromatin               1 - 10</div><div class="line">   9. Normal Nucleoli               1 - 10</div><div class="line">  10. Mitoses                       1 - 10</div><div class="line">  11. Class:                        (2 <span class="keyword">for</span> benign(良性), 4 <span class="keyword">for</span> malignant(恶性))</div></pre></td></tr></table></figure><p>因为缺失的数据并不多，并且在我修改了那几个缺失值测试了好几次用于训练之后发现差距基本上可以忽略，所以这里的关于缺失值改为异常值来处理，因为基本上对于模型训练基本上没有什么影响。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"></div><div class="line">df = pd.read_csv(<span class="string">'breast-cancer-wisconsin.data'</span>)</div><div class="line"></div><div class="line">df.replace(<span class="string">'?'</span>,<span class="number">-99999</span>,inplace=<span class="keyword">True</span>) <span class="comment">#替换异常值为-99999，inplace=True表示文件中也将进行同步更改</span></div><div class="line"><span class="comment">#去除不相关的特征列</span></div><div class="line">df.drop([<span class="string">'Id'</span>], <span class="number">1</span>, inplace=<span class="keyword">True</span>)</div></pre></td></tr></table></figure><p>数据量本身也就是那么点…所以数据预处理也就这样了…<strong>KNN算法对于异常值不敏感。</strong></p><h2 id="模型训练及预测"><a href="#模型训练及预测" class="headerlink" title="模型训练及预测"></a>模型训练及预测</h2><p>分割数据集，进行训练，并且制作简易数据集来进行预测。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing,neighbors</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"></div><div class="line">X = np.array(df.drop([<span class="string">'Class'</span>], <span class="number">1</span>)) <span class="comment">#去除标签列，自制数据集</span></div><div class="line">y = np.array(df[<span class="string">'Class'</span>])</div><div class="line"></div><div class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</div><div class="line"></div><div class="line">clf = neighbors.KNeighborsClassifier()</div><div class="line">clf.fit(X_train, y_train)</div><div class="line"></div><div class="line">accuracy = clf.score(X_test, y_test) <span class="comment">#得出准确值</span></div><div class="line">print(accuracy)</div><div class="line"></div><div class="line"><span class="comment">#创建数据集来进行简单的预测</span></div><div class="line">example_maasurse = np.array([[<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>],[<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>]])</div><div class="line">example_maasurse = example_maasurse.reshape(len(example_maasurse),<span class="number">-1</span>) <span class="comment">#重朔,其中的-1可理解为，只想输出2行的情况下，后面的列我写上-1由numpy自行得出对应相符的数组，有点抽象...其实也就那么回事</span></div><div class="line"></div><div class="line"></div><div class="line">prediction = clf.predict(example_maasurse)</div><div class="line">print(prediction)</div></pre></td></tr></table></figure><p>输出如下：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-21%20%E4%B8%8B%E5%8D%884.10.36.png" alt=""></p><p>如果还是对于这条代码<code>example_maasurse.reshape(len(example_maasurse),-1)</code>中的<code>-1</code>还是不理解，可参考如下链接或者是官网：</p><ul><li><p><a href="https://www.zhihu.com/question/52684594" target="_blank" rel="external">Python中reshape函数参数-1的意思？</a></p></li><li><p><a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html#numpy-reshape" target="_blank" rel="external">numpy.reshape</a></p></li><li><p><a href="">Python Numpy中reshape函数参数-1的含义</a></p></li></ul><p>其实也就那么回事…</p><h2 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing,neighbors</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"></div><div class="line">df = pd.read_csv(<span class="string">'breast-cancer-wisconsin.data'</span>)</div><div class="line"></div><div class="line">df.replace(<span class="string">'?'</span>,<span class="number">-99999</span>,inplace=<span class="keyword">True</span>) </div><div class="line">df.drop([<span class="string">'Id'</span>], <span class="number">1</span>, inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">X = np.array(df.drop([<span class="string">'Class'</span>], <span class="number">1</span>)) </div><div class="line">y = np.array(df[<span class="string">'Class'</span>])</div><div class="line"></div><div class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</div><div class="line"></div><div class="line">clf = neighbors.KNeighborsClassifier()</div><div class="line">clf.fit(X_train, y_train)</div><div class="line"></div><div class="line">accuracy = clf.score(X_test, y_test) </div><div class="line">print(accuracy)</div><div class="line"></div><div class="line">example_maasurse = np.array([[<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>],[<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>]])</div><div class="line">example_maasurse = example_maasurse.reshape(len(example_maasurse),<span class="number">-1</span>)</div><div class="line"></div><div class="line">prediction = clf.predict(example_maasurse)</div><div class="line">print(prediction)</div></pre></td></tr></table></figure><h2 id="用手动实现的KNN训练此数据集"><a href="#用手动实现的KNN训练此数据集" class="headerlink" title="用手动实现的KNN训练此数据集"></a>用手动实现的KNN训练此数据集</h2><p>代入以上的实际数据，转换数据类型打乱整体(俗称“洗牌”)的数据集并且分割对应标签制作成可代入上面写的算法中的数据集形式，然后根据计算出的距离结合<code>K</code>的取值得出最终的测试数据集的整体预测标签(计算在训练数据集与测试数据集之间进行)，然后将预测得出的标签与实际的结果进行比较，最终即可得出整体的算法准确性(Accuracy)。</p><p>下面是实现的整体代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> warnings</div><div class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">k_nearest_neighbors</span><span class="params">(data, predict_feature, k=<span class="number">3</span>)</span>:</span> <span class="comment">#特别说明：k值在sklearn中的模型默认为5</span></div><div class="line">    <span class="keyword">if</span> len(data) &gt;= k:</div><div class="line">        warnings.warn(<span class="string">'你这样就没有意义了...笨猪！'</span>)</div><div class="line">    distances = []</div><div class="line">    <span class="keyword">for</span> group <span class="keyword">in</span> data:</div><div class="line">        <span class="keyword">for</span> features <span class="keyword">in</span> data[group]: <span class="comment">#这两段代码与for group, features in dateset.items():意义一致</span></div><div class="line">            euclidean_distance = np.linalg.norm(np.array(features)-np.array(predict_feature)) <span class="comment">#使用numpy的相关的模块会显得更加的快速以及更加的高级</span></div><div class="line">            distances.append([euclidean_distance, group])</div><div class="line">            </div><div class="line">    votes = [i[<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> sorted(distances)[:k]] <span class="comment">#从小到大的排序，选择出现在前面的K个样本作为投票得出的结果</span></div><div class="line">    vote_result = Counter(votes).most_common(<span class="number">1</span>)[<span class="number">0</span>][<span class="number">0</span>]</div><div class="line">    confidence = Counter(votes).most_common(<span class="number">1</span>)[<span class="number">0</span>][<span class="number">1</span>] / k <span class="comment">#在预测的样本中正确预测的比例，但是数据量小，一般不靠谱，所以不采用，当然可写入代码中以便学习</span></div><div class="line"></div><div class="line"></div><div class="line">    <span class="keyword">return</span> vote_result, confidence</div><div class="line"></div><div class="line">df = pd.read_csv(<span class="string">'breast-cancer-wisconsin.data'</span>)</div><div class="line">df.replace(<span class="string">'?'</span>, <span class="number">-99999</span>, inplace=<span class="keyword">True</span>)</div><div class="line">df.drop([<span class="string">'Id'</span>], <span class="number">1</span>, inplace=<span class="keyword">True</span>)</div><div class="line">full_data = df.astype(float).values.tolist() <span class="comment">#转化为float、列表类型以便下面的随机打乱</span></div><div class="line"></div><div class="line">random.shuffle(full_data) <span class="comment">#随机打乱所有数据,洗牌函数</span></div><div class="line">test_size = <span class="number">0.2</span></div><div class="line">train_set = &#123;<span class="number">2</span>:[], <span class="number">4</span>:[]&#125;</div><div class="line">test_set = &#123;<span class="number">2</span>:[], <span class="number">4</span>:[]&#125;</div><div class="line"><span class="comment">#取训练数据集比例0.8:0.2</span></div><div class="line">train_data = full_data[:-int(test_size*len(full_data))]</div><div class="line">test_data = full_data[-int(test_size*len(full_data)):]</div><div class="line"></div><div class="line"><span class="comment">#数据分割对应</span></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> train_data:</div><div class="line">    train_set[i[<span class="number">-1</span>]].append(i[:<span class="number">-1</span>]) <span class="comment">#模版套入对应数据即可</span></div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> test_data:</div><div class="line">    test_set[i[<span class="number">-1</span>]].append(i[:<span class="number">-1</span>])</div><div class="line">    </div><div class="line">correct = <span class="number">0</span></div><div class="line">total = <span class="number">0</span></div><div class="line"></div><div class="line"><span class="keyword">for</span> group <span class="keyword">in</span> test_set:</div><div class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> test_set[group]: <span class="comment">#亦可理解为for group, data in test_set.items():</span></div><div class="line">        vote, confidence = k_nearest_neighbors(train_set, data, k=<span class="number">5</span>) </div><div class="line">        <span class="keyword">if</span> group == vote:</div><div class="line">            correct += <span class="number">1</span> <span class="comment">#若是准确预测了则加1</span></div><div class="line">        total += <span class="number">1</span></div><div class="line">print(<span class="string">'Accuracy:'</span>, correct/total)</div></pre></td></tr></table></figure><blockquote><p>铺助理解：<a href="http://www.runoob.com/python3/python3-func-number-shuffle.html" target="_blank" rel="external">Python3 shuffle() 函数</a></p></blockquote><p>运行可得预测准确性：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-22%20%E4%B8%8B%E5%8D%886.51.22.png" alt=""></p><p>其中有必要说明一下：<code>Accuracy</code>与<code>confidence</code>的关系，就相当于<code>查准率(Precision)</code>(<strong>预测正确的样本数与总体使用样本数的比例</strong>)和<code>查全率(Recall)</code>(<strong>预测正确样本数与全部使用数据数量的比例</strong>)的关系。另外补充一点关于平常常用的<code>score</code>参数的计算公式：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-22%20%E4%B8%8B%E5%8D%887.27.46.png" alt=""></p><blockquote><p>这些知识都是基础知识，可在网友整理的吴恩达老师的<a href="http://www.ai-start.com/ml2014/html/week6.html#header-n168" target="_blank" rel="external">机器学习笔记</a>中找到，也可完整的学习相关的知识，吴恩达老师的必看啊。</p></blockquote><h1 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h1><p>以上的算法没有完全的实现，仅仅是实现基础的构想，还需要改进的地方有很多，比如数据量大了一点之后，需要用到的多线程等。</p><p>另外，KNN算法的优缺点值得去了解，上面我也说过一点，比如数据量大了之后它的效率会受到影响，但是它对于异常值处理的都很好，基本上不受异常值之类的影响等，自行翻书了解去吧。</p>]]></content>
    
    <summary type="html">
    
      &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/r_D5TTV9-2c&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; encrypted-media&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;还是老样子，这篇文章不适合纯粹的小白，仅仅注重实践，基础知识说的比较浅，基本上一笔带过。&lt;/p&gt;
&lt;p&gt;我在作者的原代码和数据上进行了一点修改以符合当今的实际情况。&lt;/p&gt;
&lt;p&gt;此篇文章将实现K近邻算法的基本原理，以及实现K邻近算法并且应用到实际数据集之中，之后会有一个实战项目。&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>python机器学习系列：线性回归算法的实现</title>
    <link href="https://liujunjie11.github.io/2018/10/19/python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%9A%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B0/"/>
    <id>https://liujunjie11.github.io/2018/10/19/python机器学习系列：线性回归算法的实现/</id>
    <published>2018-10-19T03:08:43.000Z</published>
    <updated>2018-10-24T13:47:46.144Z</updated>
    
    <content type="html"><![CDATA[<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/V59bYfIomVk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe><p>本来不想写太多关于这方面的基础知识的，但是为了加强理解，我想不妨直接写博文记录也是一个好的选择，也可以顺便帮助需要的人，何乐而不为呢？</p><p>那么开始吧。我在原课程的基础上进行那么一点点修改。</p><blockquote><p>这是我学习的相应的课程地址：<a href="https://pythonprogramming.net/how-to-program-best-fit-line-machine-learning-tutorial/?completed=/how-to-program-best-fit-line-slope-machine-learning-tutorial/" target="_blank" rel="external">https://pythonprogramming.net/how-to-program-best-fit-line-machine-learning-tutorial/?completed=/how-to-program-best-fit-line-slope-machine-learning-tutorial/</a></p></blockquote><p>这不是一个小白教程，需要自行取了解一些基础知识，基础知识我仅仅是一笔带过。</p><a id="more"></a><h1 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h1><p>众所周知，线性回归算法是以一条直线来将一些散点进行分类的算法，而这条直线通常可理解为<code>y(x)=mx+b</code>/<code>y=mx+b</code>这样的函数(这是最简单的线性回归算法实例)，其中<code>m</code>为直线的斜率，而<code>y</code>为直线的截距，而<code>x</code>为直线的自变量。</p><p>如下图，我们要将图1的散点，通过图2一条直线进行适当良好的分类开来：</p><ul><li>图1</li></ul><p><img src="http://owudg3xs2.bkt.clouddn.com/linear-regression-tutorial.png" alt=""></p><ul><li>图2</li></ul><p><img src="http://owudg3xs2.bkt.clouddn.com/linear-regression-python-tutorial.png" alt=""></p><h2 id="求解m"><a href="#求解m" class="headerlink" title="求解m:"></a>求解<code>m</code>:</h2><p>如图：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/best-fit-slope.png" alt=""></p><h2 id="求解b"><a href="#求解b" class="headerlink" title="求解b:"></a>求解<code>b</code>:</h2><p>如图：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/best-fit-y-intercept.png" alt=""></p><p>实际上这与所谓的<code>感知机</code>是一样的原理(相关的知识可见李航老师的书籍《统计需诶下方法》)。再者，经过python实现编写对应的公式再进行可视化验证即可完成任务了。</p><h2 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h2><p>因为仅仅是为了说明算法的实现，所以数值就随便取的来用了。</p><h3 id="数值取值："><a href="#数值取值：" class="headerlink" title="数值取值："></a>数值取值：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line">xs = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],dtype=np.float64)</div><div class="line">ys = np.array([<span class="number">5</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>],dtype=np.float64)</div></pre></td></tr></table></figure><h3 id="代码实现公式原理"><a href="#代码实现公式原理" class="headerlink" title="代码实现公式原理"></a>代码实现公式原理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> statistics <span class="keyword">import</span> mean</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">best_fit_slope_and_intercept</span><span class="params">(xs,ys)</span>:</span></div><div class="line">    </div><div class="line">    <span class="comment">#实现m参数，两种实现方法</span></div><div class="line"><span class="comment">#m = (mean(xs)*mean(ys) - mean(xs*ys)) / (mean(xs)*mean(xs) - mean(xs*xs))</span></div><div class="line">    m = (mean(xs)*mean(ys) - mean(xs*ys)) / (mean(xs)**<span class="number">2</span> - mean(xs**<span class="number">2</span>))</div><div class="line">    <span class="comment">#实现b参数</span></div><div class="line">    b = mean(ys)-m*mean(xs)</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> m,b</div></pre></td></tr></table></figure><h3 id="画图预测展示"><a href="#画图预测展示" class="headerlink" title="画图预测展示"></a>画图预测展示</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line">m,b = best_fit_slope_and_intercept(xs,ys)</div><div class="line"></div><div class="line">regression_line = [(m*x)+b <span class="keyword">for</span> x <span class="keyword">in</span> xs] <span class="comment">#y(x)的实现</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">#趋势直线点向</span></div><div class="line">predict_x = <span class="number">9</span></div><div class="line">predict_y = (m*predict_x)+b</div><div class="line"></div><div class="line"><span class="comment">#散点图</span></div><div class="line">plt.scatter(xs,ys)</div><div class="line">plt.scatter(predict_x,predict_y)</div><div class="line">plt.plot(xs,regression_line) <span class="comment">#直线描绘</span></div><div class="line">plt.show()</div></pre></td></tr></table></figure><p>如图：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/Figure_1.png" alt=""></p><p>这样就完成任务了。</p><h2 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> statistics <span class="keyword">import</span> mean</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line">xs = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],dtype=np.float64)</div><div class="line">ys = np.array([<span class="number">5</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>],dtype=np.float64)</div><div class="line"><span class="comment"># print(xs,ys)</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">best_fit_slope_and_intercept</span><span class="params">(xs,ys)</span>:</span></div><div class="line">    </div><div class="line"></div><div class="line"><span class="comment">#m = (mean(xs)*mean(ys) - mean(xs*ys)) / (mean(xs)*mean(xs) - mean(xs*xs))</span></div><div class="line">    m = (mean(xs)*mean(ys) - mean(xs*ys)) / (mean(xs)**<span class="number">2</span> - mean(xs**<span class="number">2</span>))</div><div class="line">    b = mean(ys)-m*mean(xs)</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> m,b</div><div class="line"></div><div class="line">m,b = best_fit_slope_and_intercept(xs,ys)</div><div class="line"></div><div class="line">regression_line = [(m*x)+b <span class="keyword">for</span> x <span class="keyword">in</span> xs] <span class="comment">#y(x)的实现</span></div><div class="line"></div><div class="line">predict_x = <span class="number">9</span></div><div class="line">predict_y = (m*predict_x)+b</div><div class="line"></div><div class="line"></div><div class="line">plt.scatter(xs,ys)</div><div class="line">plt.scatter(predict_x,predict_y)</div><div class="line">plt.plot(xs,regression_line) <span class="comment">#直线描绘</span></div><div class="line">plt.show()</div></pre></td></tr></table></figure><h2 id="铺助理解链接"><a href="#铺助理解链接" class="headerlink" title="铺助理解链接"></a>铺助理解链接</h2><ul><li><p><a href="http://www.runoob.com/python/python-operators.html" target="_blank" rel="external">Python 运算符</a></p></li><li><p><a href="https://pythoncaff.com/docs/pymotw/statistics-statistical-calculations/106" target="_blank" rel="external">statistics — 统计学计算</a></p></li></ul><h1 id="补充R平方理论以及检验假设"><a href="#补充R平方理论以及检验假设" class="headerlink" title="补充R平方理论以及检验假设"></a>补充R平方理论以及检验假设</h1><p>强烈建议查看书籍学习了解相关的统计知识：</p><blockquote><p>商务与经济统计：<a href="https://pan.baidu.com/s/1O9G7l4QbeqOPsPs_90lFGA" target="_blank" rel="external">https://pan.baidu.com/s/1O9G7l4QbeqOPsPs_90lFGA</a></p></blockquote><p>这是一本好书。</p><h2 id="关于R平方理论"><a href="#关于R平方理论" class="headerlink" title="关于R平方理论"></a>关于R平方理论</h2><p>又称<em>决定系数/判定系数</em>。这是检验一个线性回归中<code>y</code>变量的变差与<code>x</code>变量的变差比例的系数，比例越大说明这个线性方程的拟合效果越好(可简单的理解为，它就是衡量一个线性回归算法的拟合精确度的)。它与相关系数也是有关系的。</p><blockquote><p><a href="https://wenku.baidu.com/view/2cad65f24afe04a1b171de05.html" target="_blank" rel="external">可查看百度文库的解释</a></p></blockquote><p>就不再多说了，这篇文章不是给小白看的教程，只注重实践部分。</p><h3 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h3><p>图一：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/coefficient-of-determination-r-squared.png" alt=""></p><p>这个公式还可变换为：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/v2-254f5004fb3ceaf68a6366ec593c1a63_hd.jpg" alt=""></p><p><img src="http://owudg3xs2.bkt.clouddn.com/v2-dd32ad2965e1bdeeefa3431c96c89357_hd.jpg" alt=""></p><p>其中<code>r^2 = SSR/SST = 1 - SSE/SST</code>亦成立，所以这里的<code>r^2 = SSR/SST = 1 - SSE/SST</code>公式即对应着图一的公式，这样就好理解下面写的代码了。</p><p>目的是检验上方的<code>ys</code>取值(即测试数据点的坐标y轴线的取值点)与训练得出的<code>y(x)</code>(即上方程序中的<code>regression_line</code>)的拟合效果如何(会有一个量化值出现)。</p><blockquote><p>可参考：</p><p><a href="https://zhuanlan.zhihu.com/p/32335608" target="_blank" rel="external">线性回归中的相关度和决定系数</a></p><p><a href="https://ww2.mathworks.cn/help/stats/coefficient-of-determination-r-squared.html" target="_blank" rel="external">Coefficient of Determination (R-Squared)</a></p></blockquote><h3 id="代码实现演示"><a href="#代码实现演示" class="headerlink" title="代码实现演示"></a>代码实现演示</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#平方误差函数</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">squared_error</span><span class="params">(ys_orig, ys_line)</span>:</span></div><div class="line">    <span class="keyword">return</span> sum((ys_line-ys_orig)**<span class="number">2</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">coefficient_of_determination</span><span class="params">(ys_orig, ys_line)</span>:</span></div><div class="line">    y_mean_line = [mean(ys_orig) <span class="keyword">for</span> y <span class="keyword">in</span> ys_orig]</div><div class="line">    squared_error_regr = squared_error(ys_orig, ys_line) <span class="comment">#SSE</span></div><div class="line">    squared_error_y_mean = squared_error(y_mean_line, ys_orig) <span class="comment">#SST</span></div><div class="line">    <span class="keyword">return</span> <span class="number">1</span> - (squared_error_regr / squared_error_y_mean)</div><div class="line">    print(y_mean_line)</div><div class="line"></div><div class="line">r_squared = coefficient_of_determination(ys, regression_line)</div><div class="line">print(r_squared)</div></pre></td></tr></table></figure><p>代入以上完整代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> statistics <span class="keyword">import</span> mean</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line">xs = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],dtype=np.float64)</div><div class="line">ys = np.array([<span class="number">5</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>],dtype=np.float64)</div><div class="line"><span class="comment"># print(xs,ys)</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">best_fit_slope_and_intercept</span><span class="params">(xs,ys)</span>:</span></div><div class="line">    </div><div class="line"></div><div class="line"><span class="comment">#m = (mean(xs)*mean(ys) - mean(xs*ys)) / (mean(xs)*mean(xs) - mean(xs*xs))</span></div><div class="line">    m = (mean(xs)*mean(ys) - mean(xs*ys)) / (mean(xs)**<span class="number">2</span> - mean(xs**<span class="number">2</span>))</div><div class="line">    b = mean(ys)-m*mean(xs)</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> m,b</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">squared_error</span><span class="params">(ys_orig, ys_line)</span>:</span></div><div class="line">    <span class="keyword">return</span> sum((ys_line-ys_orig)**<span class="number">2</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">coefficient_of_determination</span><span class="params">(ys_orig, ys_line)</span>:</span></div><div class="line">    y_mean_line = [mean(ys_orig) <span class="keyword">for</span> y <span class="keyword">in</span> ys_orig]</div><div class="line">    squared_error_regr = squared_error(ys_orig, ys_line) <span class="comment">#SSE</span></div><div class="line">    squared_error_y_mean = squared_error(y_mean_line, ys_orig) <span class="comment">#SST</span></div><div class="line">    <span class="keyword">return</span> <span class="number">1</span> - (squared_error_regr / squared_error_y_mean)</div><div class="line">    print(y_mean_line)</div><div class="line"></div><div class="line">m,b = best_fit_slope_and_intercept(xs,ys)</div><div class="line"></div><div class="line">regression_line = [(m*x)+b <span class="keyword">for</span> x <span class="keyword">in</span> xs] <span class="comment">#y(x)的实现</span></div><div class="line"></div><div class="line">r_squared = coefficient_of_determination(ys, regression_line)</div><div class="line">print(r_squared)</div><div class="line"></div><div class="line"><span class="comment">#predict_x = 9</span></div><div class="line"><span class="comment">#predict_y = (m*predict_x)+b</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">#plt.scatter(xs,ys)</span></div><div class="line"><span class="comment">#plt.scatter(predict_x,predict_y)</span></div><div class="line"><span class="comment">#plt.plot(xs,regression_line) #直线描绘</span></div><div class="line"><span class="comment">#plt.show()</span></div></pre></td></tr></table></figure><blockquote><p>将会输出一个<code>R</code>的平方值，用以衡量拟合效果如何。</p></blockquote><h2 id="关于检验假设"><a href="#关于检验假设" class="headerlink" title="关于检验假设"></a>关于检验假设</h2><p>关于检验假设，这是一个可检验数据是否符合相关算法的一个验证，也可理解为先假设，然后去验证对不对(验证假设对不对)。这可与关于R平方理论(输出效果量化值)结合，从而可得出算法对于多类不同数据的拟合效果如何。</p><p>在此之后将通过伪随机生成器(可理解只要是计算机生成的随机数都是伪随机数)来进行一段实例演示。</p><blockquote><p><a href="https://blog.csdn.net/czc1997/article/details/78167705" target="_blank" rel="external">随机数：真随机数和伪随机数</a></p></blockquote><h3 id="代码实现演示-1"><a href="#代码实现演示-1" class="headerlink" title="代码实现演示"></a>代码实现演示</h3><p>这里既是一个简单的随机数据生成器，与相关性、方差有关，为其中的参数选择。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> random</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">#数据量的多少，方差，平均每个点步骤(与相关性的取值有关)，相关性设定,默认无相关性</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dataset</span><span class="params">(hm, variance, step=<span class="number">2</span>, correlation=False)</span>:</span></div><div class="line">    val = <span class="number">1</span> <span class="comment">#初始值</span></div><div class="line">    ys = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(hm):</div><div class="line">        y = val + random.randrange(-variance,variance)</div><div class="line">        ys.append(y)</div><div class="line">        <span class="comment">#若为正相关</span></div><div class="line">        <span class="keyword">if</span> correlation <span class="keyword">and</span> correlation == <span class="string">'pos'</span>:</div><div class="line">            val += step</div><div class="line">        <span class="keyword">elif</span> correlation <span class="keyword">and</span> correlation ==<span class="string">'neg'</span>:</div><div class="line">            val -= step</div><div class="line">    xs = [i <span class="keyword">for</span> i <span class="keyword">in</span> range(len(ys))] <span class="comment">#xs为平常的顺序取值数</span></div><div class="line">    </div><div class="line">    <span class="keyword">return</span> np.array(xs, dtype=np.float64), np.array(ys, dtype=np.float64)</div><div class="line"></div><div class="line">xs, ys = create_dataset(<span class="number">40</span>, <span class="number">40</span>, <span class="number">2</span>, correlation=<span class="string">'pos'</span>)</div></pre></td></tr></table></figure><h2 id="完整代码-1"><a href="#完整代码-1" class="headerlink" title="完整代码"></a>完整代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> statistics <span class="keyword">import</span> mean</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> random</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line"><span class="comment"># xs = np.array([1,2,3,4,5,6],dtype=np.float64)</span></div><div class="line"><span class="comment"># ys = np.array([5,4,6,5,6,7],dtype=np.float64)</span></div><div class="line"></div><div class="line"><span class="comment">#数据量的多少，方差，平均每个点步骤(与相关性的取值有关)，相关性设定,默认无相关性</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dataset</span><span class="params">(hm, variance, step=<span class="number">2</span>, correlation=False)</span>:</span></div><div class="line">    val = <span class="number">1</span> <span class="comment">#初始值</span></div><div class="line">    ys = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(hm):</div><div class="line">        y = val + random.randrange(-variance,variance)</div><div class="line">        ys.append(y)</div><div class="line">        <span class="comment">#若为正相关</span></div><div class="line">        <span class="keyword">if</span> correlation <span class="keyword">and</span> correlation == <span class="string">'pos'</span>:</div><div class="line">            val += step</div><div class="line">        <span class="keyword">elif</span> correlation <span class="keyword">and</span> correlation ==<span class="string">'neg'</span>:</div><div class="line">            val -= step</div><div class="line">    xs = [i <span class="keyword">for</span> i <span class="keyword">in</span> range(len(ys))] <span class="comment">#xs为平常的顺序取值数</span></div><div class="line">    </div><div class="line">    <span class="keyword">return</span> np.array(xs, dtype=np.float64), np.array(ys, dtype=np.float64)</div><div class="line">            </div><div class="line">    </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">best_fit_slope_and_intercept</span><span class="params">(xs,ys)</span>:</span></div><div class="line">    </div><div class="line">    <span class="comment">#实现m参数</span></div><div class="line">    <span class="comment">#m = (mean(xs)*mean(ys) - mean(xs*ys)) / (mean(xs)*mean(xs) - mean(xs*xs))</span></div><div class="line">    m = (mean(xs)*mean(ys) - mean(xs*ys)) / (mean(xs)**<span class="number">2</span> - mean(xs**<span class="number">2</span>))</div><div class="line">    <span class="comment">#实现b参数</span></div><div class="line">    b = mean(ys)-m*mean(xs)</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> m,b</div><div class="line"></div><div class="line"><span class="comment">#平方误差函数</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">squared_error</span><span class="params">(ys_orig, ys_line)</span>:</span></div><div class="line">    <span class="keyword">return</span> sum((ys_line-ys_orig)**<span class="number">2</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">coefficient_of_determination</span><span class="params">(ys_orig, ys_line)</span>:</span></div><div class="line">    y_mean_line = [mean(ys_orig) <span class="keyword">for</span> y <span class="keyword">in</span> ys_orig]</div><div class="line">    squared_error_regr = squared_error(ys_orig, ys_line) <span class="comment">#SSE</span></div><div class="line">    squared_error_y_mean = squared_error(y_mean_line, ys_orig) <span class="comment">#SST</span></div><div class="line">    <span class="keyword">return</span> <span class="number">1</span> - (squared_error_regr / squared_error_y_mean)</div><div class="line">    print(y_mean_line)</div><div class="line"></div><div class="line">xs, ys = create_dataset(<span class="number">40</span>, <span class="number">40</span>, <span class="number">2</span>, correlation=<span class="string">'pos'</span>)</div><div class="line">    </div><div class="line">m,b = best_fit_slope_and_intercept(xs,ys)</div><div class="line"></div><div class="line">regression_line = [(m*x)+b <span class="keyword">for</span> x <span class="keyword">in</span> xs] <span class="comment">#y(x)的实现</span></div><div class="line"></div><div class="line">r_squared = coefficient_of_determination(ys, regression_line)</div><div class="line">print(r_squared)</div><div class="line"></div><div class="line"><span class="comment">#趋势点向</span></div><div class="line">predict_x = <span class="number">9</span></div><div class="line">predict_y = (m*predict_x)+b</div><div class="line"></div><div class="line"><span class="comment">#散点图</span></div><div class="line">plt.scatter(xs,ys)</div><div class="line">plt.scatter(predict_x,predict_y)</div><div class="line">plt.plot(xs,regression_line) <span class="comment">#直线描绘</span></div><div class="line">plt.show()</div></pre></td></tr></table></figure><blockquote><p><a href="http://www.runoob.com/python/func-number-randrange.html" target="_blank" rel="external">Python randrange() 函数</a></p></blockquote><h2 id="结果展示"><a href="#结果展示" class="headerlink" title="结果展示"></a>结果展示</h2><p>会输出一个<code>R</code>平方值和一张由于随机数据为基础的训练图表。</p><p><img src="http://owudg3xs2.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-20%20%E4%B8%8B%E5%8D%8810.03.18.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/V59bYfIomVk&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; encrypted-media&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;本来不想写太多关于这方面的基础知识的，但是为了加强理解，我想不妨直接写博文记录也是一个好的选择，也可以顺便帮助需要的人，何乐而不为呢？&lt;/p&gt;
&lt;p&gt;那么开始吧。我在原课程的基础上进行那么一点点修改。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这是我学习的相应的课程地址：&lt;a href=&quot;https://pythonprogramming.net/how-to-program-best-fit-line-machine-learning-tutorial/?completed=/how-to-program-best-fit-line-slope-machine-learning-tutorial/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://pythonprogramming.net/how-to-program-best-fit-line-machine-learning-tutorial/?completed=/how-to-program-best-fit-line-slope-machine-learning-tutorial/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这不是一个小白教程，需要自行取了解一些基础知识，基础知识我仅仅是一笔带过。&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>python机器学习系列：预测房价并且可视化</title>
    <link href="https://liujunjie11.github.io/2018/10/18/python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%9A%E9%A2%84%E6%B5%8B%E6%88%BF%E4%BB%B7%E5%B9%B6%E4%B8%94%E5%8F%AF%E8%A7%86%E5%8C%96/"/>
    <id>https://liujunjie11.github.io/2018/10/18/python机器学习系列：预测房价并且可视化/</id>
    <published>2018-10-18T10:38:51.000Z</published>
    <updated>2018-10-21T12:41:07.828Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章不是给纯粹的小白看的，需要一定的基础，需要小白补充一定的基础知识，在我的博客有<a href="http://liujunworld.com/2018/09/16/%E5%88%9D%E5%AD%A6%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8D%97/" target="_blank" rel="external">相关的资源</a>介绍。</p><p>在这里记录下这篇文章时因为很实用，并且也希望以此帮助需要的人。</p><p>这是我在<em>YouTube</em>上学习到的。</p><iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/QLVMqwpOLPk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe><ul><li>中文地址(不全)：<a href="https://www.yxgapp.com/channel/349.html" target="_blank" rel="external">https://www.yxgapp.com/channel/349.html</a></li></ul><blockquote><p>对应的网页课程地址在此：<a href="https://pythonprogramming.net/forecasting-predicting-machine-learning-tutorial/" target="_blank" rel="external">https://pythonprogramming.net/forecasting-predicting-machine-learning-tutorial/</a></p></blockquote><p>在作者的基础上进行了一点点的改动。说明一下：<strong>相关的库自行安装，就不一一废话了。</strong></p><a id="more"></a><h1 id="项目开始"><a href="#项目开始" class="headerlink" title="项目开始"></a>项目开始</h1><p><strong>项目过程：从开放的数据接口拿到数据，并且做简单的数据处理，自行做好数据标签用于算法训练，之后在利用相关的模块做好预测得到的数值与相应的时间值的对接，得出数据的图表(包括预测部分)，项目完成。</strong></p><h2 id="获取数据以及简单数据处理"><a href="#获取数据以及简单数据处理" class="headerlink" title="获取数据以及简单数据处理"></a>获取数据以及简单数据处理</h2><p>代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> quandl,math</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</div><div class="line"></div><div class="line"><span class="comment">#获取公共数据接口</span></div><div class="line">df = quandl.get(<span class="string">"WIKI/GOOGL"</span>)</div><div class="line"></div><div class="line"><span class="comment">#简单的数据特征处理、整理，目的是得出“标签”特征列（因为仅仅是做到实践的效果，所以就不多说了，看代码便知）。</span></div><div class="line">df = df[[<span class="string">'Adj. Open'</span>, <span class="string">'Adj. High'</span>, <span class="string">'Adj. Low'</span>, <span class="string">'Adj. Close'</span>, <span class="string">'Adj. Volume'</span>]]  <span class="comment">#取用时需要用大括号</span></div><div class="line">df[<span class="string">'HL_PCT'</span>] = (df[<span class="string">'Adj. High'</span>] - df[<span class="string">'Adj. Close'</span>]) / df[<span class="string">'Adj. Close'</span>] * <span class="number">100.0</span></div><div class="line">df[<span class="string">'PCT_change'</span>] = (df[<span class="string">'Adj. Close'</span>] - df[<span class="string">'Adj. Open'</span>]) /df[<span class="string">'Adj. Open'</span>] * <span class="number">100.0</span></div><div class="line"></div><div class="line">df = df[[<span class="string">'Adj. Close'</span>, <span class="string">'Adj. Volume'</span>,<span class="string">'HL_PCT'</span>,<span class="string">'PCT_change'</span>]]</div><div class="line"></div><div class="line">forecast_col = <span class="string">'Adj. Close'</span></div><div class="line">df.fillna(value=<span class="number">-99999</span>, inplace=<span class="keyword">True</span>)</div><div class="line">forecast_out = int(math.ceil(<span class="number">0.01</span> * len(df)))</div><div class="line"><span class="comment">#得出标签特征列，以便直接用于训练</span></div><div class="line">df[<span class="string">'label'</span>] = df[forecast_col].shift(-forecast_out)</div></pre></td></tr></table></figure><blockquote><p>关于<a href="https://www.quandl.com" target="_blank" rel="external">quandl</a>,是个公开的数据网站，有免费的，也有收费的，它有很好的支持python的数据接口。可用<code>pip install quandl</code>下载相关的支持模块。<strong>如果有时获取数据出错了，重新运行直到没错误出现为止。</strong></p></blockquote><h2 id="算法预测"><a href="#算法预测" class="headerlink" title="算法预测"></a>算法预测</h2><p>代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">X = np.array(df.drop([<span class="string">'label'</span>], <span class="number">1</span>))</div><div class="line">X = preprocessing.scale(X)</div><div class="line"></div><div class="line"><span class="comment">#这里是取数据的后面一小部分用于预测得出的数值使用</span></div><div class="line">X_lately = X[-forecast_out:]</div><div class="line">X = X[:-forecast_out]</div><div class="line"></div><div class="line">df.dropna(inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">y = np.array(df[<span class="string">'label'</span>])</div><div class="line"></div><div class="line"><span class="comment">#数据分割</span></div><div class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</div><div class="line">clf = LinearRegression(n_jobs=<span class="number">-1</span>)</div><div class="line">clf.fit(X_train, y_train)</div><div class="line"><span class="comment">#预测准确性</span></div><div class="line">confidence = clf.score(X_test, y_test)</div><div class="line"></div><div class="line"><span class="comment">#最后预测的数值部分</span></div><div class="line">forecast_set = clf.predict(X_lately)</div></pre></td></tr></table></figure><blockquote><p>这里是简单的预测部分了，其中有一些简单的数据处理部分。</p></blockquote><h2 id="时间与预测值的对应以及图表的描绘"><a href="#时间与预测值的对应以及图表的描绘" class="headerlink" title="时间与预测值的对应以及图表的描绘"></a>时间与预测值的对应以及图表的描绘</h2><p>代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> datetime</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line"><span class="comment">#matplotlib的美化图表风格</span></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line"><span class="comment">#预测标签</span></div><div class="line">df[<span class="string">'Forecast'</span>] = np.nan</div><div class="line"></div><div class="line"><span class="comment">#获取源数据最后一天日期</span></div><div class="line">last_date = df.iloc[<span class="number">-1</span>].name</div><div class="line">last_unix = last_date.timestamp()</div><div class="line">one_day = <span class="number">86400</span> <span class="comment">#一天的时间戳</span></div><div class="line">next_unix = last_unix + one_day</div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> forecast_set:</div><div class="line">    next_date = datetime.datetime.fromtimestamp(next_unix)</div><div class="line">    next_unix += <span class="number">86400</span></div><div class="line">    <span class="comment">#将此日期对应的前面五列不相干的均设为nan，而仅仅加上预测的数值，即仅仅有相应的时间对应相应的预测数值</span></div><div class="line">    df.loc[next_date] = [np.nan <span class="keyword">for</span> _ <span class="keyword">in</span> range(len(df.columns)<span class="number">-1</span>)]+[i] <span class="comment">#如果这里不理解的话，可以查看df的head和tail部分试试，就能一目了然了</span></div><div class="line"></div><div class="line"><span class="comment">#图表描绘</span></div><div class="line">df[<span class="string">'Adj. Close'</span>].plot()</div><div class="line">df[<span class="string">'Forecast'</span>].plot()</div><div class="line">plt.legend(loc=<span class="number">4</span>)</div><div class="line">plt.xlabel(<span class="string">'Date'</span>)</div><div class="line">plt.ylabel(<span class="string">'Price'</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><blockquote><p>这里有些难理解，但是其实很好理解，只是一些代码根本没见到过，所以导致阅读障碍。</p></blockquote><p>估计有人不理解这段<code>df.loc[next_date] = [np.nan for _ in range(len(df.columns)-1)]+[i]</code>代码，我来简单说明一下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> forecast_set:</div><div class="line">    next_date = datetime.datetime.fromtimestamp(next_unix)</div><div class="line">    next_unix += <span class="number">86400</span></div><div class="line">    df.loc[next_date] = [np.nan <span class="keyword">for</span> _ <span class="keyword">in</span> range(len(df.columns)<span class="number">-1</span>)]+[i]</div><div class="line"></div><div class="line">print(df.head())   </div><div class="line"></div><div class="line">输出：</div><div class="line"></div><div class="line">         Adj. Close  Adj. Volume   HL_PCT  PCT_change   label      Forecast</div><div class="line">Date                                                                          </div><div class="line"><span class="number">2004</span><span class="number">-08</span><span class="number">-19</span>   <span class="number">50.322842</span>   <span class="number">44659000.0</span>  <span class="number">3.712563</span>    <span class="number">0.324968</span>  <span class="number">69.078238</span>       NaN</div><div class="line"><span class="number">2004</span><span class="number">-08</span><span class="number">-20</span>   <span class="number">54.322689</span>   <span class="number">22834300.0</span>  <span class="number">0.710922</span>    <span class="number">7.227007</span>  <span class="number">67.839414</span>       NaN</div><div class="line"><span class="number">2004</span><span class="number">-08</span><span class="number">-23</span>   <span class="number">54.869377</span>   <span class="number">18256100.0</span>  <span class="number">3.729433</span>   <span class="number">-1.227880</span>  <span class="number">68.912727</span>       NaN</div><div class="line"><span class="number">2004</span><span class="number">-08</span><span class="number">-24</span>   <span class="number">52.597363</span>   <span class="number">15247300.0</span>  <span class="number">6.417469</span>   <span class="number">-5.726357</span>  <span class="number">70.668146</span>       NaN</div><div class="line"><span class="number">2004</span><span class="number">-08</span><span class="number">-25</span>   <span class="number">53.164113</span>    <span class="number">9188600.0</span>  <span class="number">1.886792</span>    <span class="number">1.183658</span>  <span class="number">71.219849</span>       NaN </div><div class="line"></div><div class="line"></div><div class="line">print(df.tail())</div><div class="line"></div><div class="line">输出：</div><div class="line"></div><div class="line">                     Adj. Close  Adj. Volume  HL_PCT  PCT_change  label  \</div><div class="line">Date                                                                      </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-08</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>         NaN          NaN     NaN         NaN    NaN   </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-09</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>         NaN          NaN     NaN         NaN    NaN   </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-10</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>         NaN          NaN     NaN         NaN    NaN   </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-11</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>         NaN          NaN     NaN         NaN    NaN   </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-12</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>         NaN          NaN     NaN         NaN    NaN   </div><div class="line"></div><div class="line">                        Forecast  </div><div class="line">Date                              </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-08</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>  <span class="number">1113.922012</span>  </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-09</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>  <span class="number">1071.104993</span>  </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-10</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>  <span class="number">1043.810593</span>  </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-11</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>  <span class="number">1073.778780</span>  </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-12</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>  <span class="number">1022.639186</span></div></pre></td></tr></table></figure><blockquote><p>就是这样，已经很明了了，就是仅仅为了让预测的时间对应预测的房价数值而已。</p></blockquote><h3 id="什么是时间戳"><a href="#什么是时间戳" class="headerlink" title="什么是时间戳?"></a>什么是时间戳?</h3><p>简单说说：时间戳是自1970年1月1日（00:00:00 UTC/GMT）以来的秒数。它也被称为Unix时间戳（Unix Timestam、Unix epoch、POSIX time、Unix timestamp）是从1970年1月1日（UTC/GMT的午夜）开始所经过的秒数，不考虑闰秒。</p><p>  UNIX时间戳的0按照ISO 8601规范为：1970-01-01T00:00:00Z</p><p>  一个小时表示为UNIX时间戳格式为：3600秒；一天表示为UNIX时间戳为86400秒，闰秒不计算。</p><blockquote><p>来自：<a href="http://www.htmer.com/article/420.htm" target="_blank" rel="external">http://www.htmer.com/article/420.htm</a></p></blockquote><h2 id="完整代码："><a href="#完整代码：" class="headerlink" title="完整代码："></a>完整代码：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> quandl,math,datetime</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing,svm</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line">df = quandl.get(<span class="string">"WIKI/GOOGL"</span>)</div><div class="line"></div><div class="line">df = df[[<span class="string">'Adj. Open'</span>, <span class="string">'Adj. High'</span>, <span class="string">'Adj. Low'</span>, <span class="string">'Adj. Close'</span>, <span class="string">'Adj. Volume'</span>]] <span class="comment">#取用时需要用大括号</span></div><div class="line">df[<span class="string">'HL_PCT'</span>] = (df[<span class="string">'Adj. High'</span>] - df[<span class="string">'Adj. Close'</span>]) / df[<span class="string">'Adj. Close'</span>] * <span class="number">100.0</span></div><div class="line">df[<span class="string">'PCT_change'</span>] = (df[<span class="string">'Adj. Close'</span>] - df[<span class="string">'Adj. Open'</span>]) /df[<span class="string">'Adj. Open'</span>] * <span class="number">100.0</span></div><div class="line"></div><div class="line">df = df[[<span class="string">'Adj. Close'</span>, <span class="string">'Adj. Volume'</span>,<span class="string">'HL_PCT'</span>,<span class="string">'PCT_change'</span>]]</div><div class="line"></div><div class="line">forecast_col = <span class="string">'Adj. Close'</span></div><div class="line"></div><div class="line">df.fillna(value=<span class="number">-99999</span>, inplace=<span class="keyword">True</span>)</div><div class="line">forecast_out = int(math.ceil(<span class="number">0.01</span> * len(df)))</div><div class="line">df[<span class="string">'label'</span>] = df[forecast_col].shift(-forecast_out)</div><div class="line"></div><div class="line">X = np.array(df.drop([<span class="string">'label'</span>], <span class="number">1</span>))</div><div class="line">X = preprocessing.scale(X)</div><div class="line">X_lately = X[-forecast_out:]</div><div class="line">X = X[:-forecast_out]</div><div class="line"></div><div class="line">df.dropna(inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">y = np.array(df[<span class="string">'label'</span>])</div><div class="line"></div><div class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</div><div class="line">clf = LinearRegression(n_jobs=<span class="number">-1</span>)</div><div class="line">clf.fit(X_train, y_train)</div><div class="line">confidence = clf.score(X_test, y_test)</div><div class="line"></div><div class="line">forecast_set = clf.predict(X_lately)</div><div class="line">df[<span class="string">'Forecast'</span>] = np.nan</div><div class="line"></div><div class="line">last_date = df.iloc[<span class="number">-1</span>].name</div><div class="line">last_unix = last_date.timestamp()</div><div class="line">one_day = <span class="number">86400</span></div><div class="line">next_unix = last_unix + one_day</div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> forecast_set:</div><div class="line">    next_date = datetime.datetime.fromtimestamp(next_unix)</div><div class="line">    next_unix += <span class="number">86400</span></div><div class="line">    df.loc[next_date] = [np.nan <span class="keyword">for</span> _ <span class="keyword">in</span> range(len(df.columns)<span class="number">-1</span>)]+[i]</div><div class="line"></div><div class="line">df[<span class="string">'Adj. Close'</span>].plot()</div><div class="line">df[<span class="string">'Forecast'</span>].plot()</div><div class="line">plt.legend(loc=<span class="number">4</span>)</div><div class="line">plt.xlabel(<span class="string">'Date'</span>)</div><div class="line">plt.ylabel(<span class="string">'Price'</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><h2 id="最终效果展示"><a href="#最终效果展示" class="headerlink" title="最终效果展示"></a>最终效果展示</h2><p><img src="http://owudg3xs2.bkt.clouddn.com/Oct-18-2018%2020-13-50.gif" alt=""></p><blockquote><p>可以查看到预测的部分展示。</p></blockquote><h2 id="补助链接"><a href="#补助链接" class="headerlink" title="补助链接"></a>补助链接</h2><p>这里是帮助理解的链接。</p><ul><li><p><a href="https://blog.csdn.net/brucewong0516/article/details/80157639" target="_blank" rel="external">python pandas库常用函数之shift详解</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/37891729" target="_blank" rel="external">样式美化matplotlib.pyplot.style.use定制画布风格</a></p></li><li><p><a href="http://www.wklken.me/posts/2015/03/03/python-base-datetime.html#6-huo-qu-ben-zhou-ben-yue-shang-yue-zui-hou-yi-tian" target="_blank" rel="external">PYTHON-基础-时间日期处理小结</a></p></li><li><p><a href="https://morvanzhou.github.io/tutorials/data-manipulation/np-pd/3-2-pd-indexing/" target="_blank" rel="external">Pandas 选择数据</a></p></li><li><p><a href="https://morvanzhou.github.io/tutorials/data-manipulation/plt/2-5-lagend/" target="_blank" rel="external">Legend 图例</a></p></li></ul><p>值得说明一下<em>Legend 图例</em>的一些知识：</p><p>使用<code>plt.legend(loc=n)</code>中<code>n</code>的选择代表什么：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="string">'best'</span> : <span class="number">0</span>,          </div><div class="line"><span class="string">'upper right'</span>  : <span class="number">1</span>,</div><div class="line"><span class="string">'upper left'</span>   : <span class="number">2</span>,</div><div class="line"><span class="string">'lower left'</span>   : <span class="number">3</span>,</div><div class="line"><span class="string">'lower right'</span>  : <span class="number">4</span>,</div><div class="line"><span class="string">'right'</span>        : <span class="number">5</span>,</div><div class="line"><span class="string">'center left'</span>  : <span class="number">6</span>,</div><div class="line"><span class="string">'center right'</span> : <span class="number">7</span>,</div><div class="line"><span class="string">'lower center'</span> : <span class="number">8</span>,</div><div class="line"><span class="string">'upper center'</span> : <span class="number">9</span>,</div><div class="line"><span class="string">'center'</span>       : <span class="number">10</span>。</div></pre></td></tr></table></figure><h1 id="补充添加序列化保存预测模型"><a href="#补充添加序列化保存预测模型" class="headerlink" title="补充添加序列化保存预测模型"></a>补充添加序列化保存预测模型</h1><p>添加了如何将预测代码序列化的过程加相关的代码。</p><p>序列化可简单理解为：先保存了这个预测的模型(序列化的过程)，然后我们可以拿出这个模型直接进行以后的预测(反序列化的过程)。</p><p>加上代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pickle</div><div class="line"></div><div class="line"><span class="keyword">with</span> open(<span class="string">'houseforecastmodel.pickle'</span>,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</div><div class="line">   <span class="comment">#下载模型</span></div><div class="line">   pickle.dump(clf,f)</div><div class="line"></div><div class="line">pickle_in = open(<span class="string">'houseforecastmodel.pickle'</span>,<span class="string">'rb'</span>)</div><div class="line">clf = pickle.load(pickle_in) <span class="comment">#加载模型</span></div></pre></td></tr></table></figure><p>完整代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> quandl,math,datetime</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing,svm</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> pickle</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line">df = quandl.get(<span class="string">"WIKI/GOOGL"</span>)</div><div class="line"></div><div class="line">df = df[[<span class="string">'Adj. Open'</span>, <span class="string">'Adj. High'</span>, <span class="string">'Adj. Low'</span>, <span class="string">'Adj. Close'</span>, <span class="string">'Adj. Volume'</span>]] <span class="comment">#取用时需要用大括号</span></div><div class="line">df[<span class="string">'HL_PCT'</span>] = (df[<span class="string">'Adj. High'</span>] - df[<span class="string">'Adj. Close'</span>]) / df[<span class="string">'Adj. Close'</span>] * <span class="number">100.0</span></div><div class="line">df[<span class="string">'PCT_change'</span>] = (df[<span class="string">'Adj. Close'</span>] - df[<span class="string">'Adj. Open'</span>]) /df[<span class="string">'Adj. Open'</span>] * <span class="number">100.0</span></div><div class="line"></div><div class="line">df = df[[<span class="string">'Adj. Close'</span>, <span class="string">'Adj. Volume'</span>,<span class="string">'HL_PCT'</span>,<span class="string">'PCT_change'</span>]]</div><div class="line"></div><div class="line">forecast_col = <span class="string">'Adj. Close'</span></div><div class="line"></div><div class="line">df.fillna(value=<span class="number">-99999</span>, inplace=<span class="keyword">True</span>)</div><div class="line">forecast_out = int(math.ceil(<span class="number">0.01</span> * len(df)))</div><div class="line">df[<span class="string">'label'</span>] = df[forecast_col].shift(-forecast_out)</div><div class="line"></div><div class="line">X = np.array(df.drop([<span class="string">'label'</span>], <span class="number">1</span>))</div><div class="line">X = preprocessing.scale(X)</div><div class="line">X_lately = X[-forecast_out:]</div><div class="line">X = X[:-forecast_out]</div><div class="line"></div><div class="line">df.dropna(inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">y = np.array(df[<span class="string">'label'</span>])</div><div class="line"></div><div class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</div><div class="line">clf = LinearRegression(n_jobs=<span class="number">-1</span>)</div><div class="line">clf.fit(X_train, y_train)</div><div class="line"></div><div class="line"><span class="keyword">with</span> open(<span class="string">'houseforecastmodel.pickle'</span>,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</div><div class="line">   <span class="comment">#下载模型</span></div><div class="line">   pickle.dump(clf,f)</div><div class="line"></div><div class="line">pickle_in = open(<span class="string">'houseforecastmodel.pickle'</span>,<span class="string">'rb'</span>)</div><div class="line">clf = pickle.load(pickle_in) <span class="comment">#加载模型</span></div><div class="line"></div><div class="line">confidence = clf.score(X_test, y_test)</div><div class="line"></div><div class="line">forecast_set = clf.predict(X_lately)</div><div class="line">df[<span class="string">'Forecast'</span>] = np.nan</div><div class="line"></div><div class="line">last_date = df.iloc[<span class="number">-1</span>].name</div><div class="line">last_unix = last_date.timestamp()</div><div class="line">one_day = <span class="number">86400</span></div><div class="line">next_unix = last_unix + one_day</div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> forecast_set:</div><div class="line">    next_date = datetime.datetime.fromtimestamp(next_unix)</div><div class="line">    next_unix += <span class="number">86400</span></div><div class="line">    df.loc[next_date] = [np.nan <span class="keyword">for</span> _ <span class="keyword">in</span> range(len(df.columns)<span class="number">-1</span>)]+[i]</div><div class="line"></div><div class="line">df[<span class="string">'Adj. Close'</span>].plot()</div><div class="line">df[<span class="string">'Forecast'</span>].plot()</div><div class="line">plt.legend(loc=<span class="number">4</span>)</div><div class="line">plt.xlabel(<span class="string">'Date'</span>)</div><div class="line">plt.ylabel(<span class="string">'Price'</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p>在运行一遍以上的代码之后，就可以直接从保存的文件来加载模型来预测数据啦，如下可测试：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> quandl,math,datetime</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing,svm</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> pickle</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line">df = quandl.get(<span class="string">"WIKI/GOOGL"</span>)</div><div class="line"></div><div class="line">df = df[[<span class="string">'Adj. Open'</span>, <span class="string">'Adj. High'</span>, <span class="string">'Adj. Low'</span>, <span class="string">'Adj. Close'</span>, <span class="string">'Adj. Volume'</span>]] <span class="comment">#取用时需要用大括号</span></div><div class="line">df[<span class="string">'HL_PCT'</span>] = (df[<span class="string">'Adj. High'</span>] - df[<span class="string">'Adj. Close'</span>]) / df[<span class="string">'Adj. Close'</span>] * <span class="number">100.0</span></div><div class="line">df[<span class="string">'PCT_change'</span>] = (df[<span class="string">'Adj. Close'</span>] - df[<span class="string">'Adj. Open'</span>]) /df[<span class="string">'Adj. Open'</span>] * <span class="number">100.0</span></div><div class="line"></div><div class="line">df = df[[<span class="string">'Adj. Close'</span>, <span class="string">'Adj. Volume'</span>,<span class="string">'HL_PCT'</span>,<span class="string">'PCT_change'</span>]]</div><div class="line"></div><div class="line">forecast_col = <span class="string">'Adj. Close'</span></div><div class="line"></div><div class="line">df.fillna(value=<span class="number">-99999</span>, inplace=<span class="keyword">True</span>)</div><div class="line">forecast_out = int(math.ceil(<span class="number">0.01</span> * len(df)))</div><div class="line">df[<span class="string">'label'</span>] = df[forecast_col].shift(-forecast_out)</div><div class="line"></div><div class="line">X = np.array(df.drop([<span class="string">'label'</span>], <span class="number">1</span>))</div><div class="line">X = preprocessing.scale(X)</div><div class="line">X_lately = X[-forecast_out:]</div><div class="line">X = X[:-forecast_out]</div><div class="line"></div><div class="line">df.dropna(inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">y = np.array(df[<span class="string">'label'</span>])</div><div class="line"></div><div class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</div><div class="line"><span class="comment">#clf = LinearRegression(n_jobs=-1)</span></div><div class="line"><span class="comment">#clf.fit(X_train, y_train)</span></div><div class="line"></div><div class="line"><span class="comment">#with open('houseforecastmodel.pickle','wb') as f:</span></div><div class="line">   <span class="comment">#下载模型</span></div><div class="line">   <span class="comment">#pickle.dump(clf,f)</span></div><div class="line"></div><div class="line">pickle_in = open(<span class="string">'houseforecastmodel.pickle'</span>,<span class="string">'rb'</span>)</div><div class="line">clf = pickle.load(pickle_in) <span class="comment">#加载模型</span></div><div class="line"></div><div class="line">confidence = clf.score(X_test, y_test)</div><div class="line"></div><div class="line">forecast_set = clf.predict(X_lately)</div><div class="line">df[<span class="string">'Forecast'</span>] = np.nan</div><div class="line"></div><div class="line">last_date = df.iloc[<span class="number">-1</span>].name</div><div class="line">last_unix = last_date.timestamp()</div><div class="line">one_day = <span class="number">86400</span></div><div class="line">next_unix = last_unix + one_day</div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> forecast_set:</div><div class="line">    next_date = datetime.datetime.fromtimestamp(next_unix)</div><div class="line">    next_unix += <span class="number">86400</span></div><div class="line">    df.loc[next_date] = [np.nan <span class="keyword">for</span> _ <span class="keyword">in</span> range(len(df.columns)<span class="number">-1</span>)]+[i]</div><div class="line"></div><div class="line">df[<span class="string">'Adj. Close'</span>].plot()</div><div class="line">df[<span class="string">'Forecast'</span>].plot()</div><div class="line">plt.legend(loc=<span class="number">4</span>)</div><div class="line">plt.xlabel(<span class="string">'Date'</span>)</div><div class="line">plt.ylabel(<span class="string">'Price'</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><blockquote><p>得出的结果与上方展示的一致。</p></blockquote><h2 id="了解pickle"><a href="#了解pickle" class="headerlink" title="了解pickle"></a>了解pickle</h2><ul><li><p><a href="https://morvanzhou.github.io/tutorials/python-basic/basic/13-08-pickle/" target="_blank" rel="external">pickle 保存数据</a></p></li><li><p><a href="https://docs.python.org/3/library/pickle.html" target="_blank" rel="external">pickle — Python object serialization</a></p></li><li><p><a href="https://www.jianshu.com/p/113f33ab6f31" target="_blank" rel="external">scikit-learn系列之如何存储和导入机器学习模型</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇文章不是给纯粹的小白看的，需要一定的基础，需要小白补充一定的基础知识，在我的博客有&lt;a href=&quot;http://liujunworld.com/2018/09/16/%E5%88%9D%E5%AD%A6%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8D%97/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;相关的资源&lt;/a&gt;介绍。&lt;/p&gt;
&lt;p&gt;在这里记录下这篇文章时因为很实用，并且也希望以此帮助需要的人。&lt;/p&gt;
&lt;p&gt;这是我在&lt;em&gt;YouTube&lt;/em&gt;上学习到的。&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/QLVMqwpOLPk&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; encrypted-media&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;ul&gt;
&lt;li&gt;中文地址(不全)：&lt;a href=&quot;https://www.yxgapp.com/channel/349.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://www.yxgapp.com/channel/349.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;对应的网页课程地址在此：&lt;a href=&quot;https://pythonprogramming.net/forecasting-predicting-machine-learning-tutorial/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://pythonprogramming.net/forecasting-predicting-machine-learning-tutorial/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在作者的基础上进行了一点点的改动。说明一下：&lt;strong&gt;相关的库自行安装，就不一一废话了。&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Mac下安装lightGBM</title>
    <link href="https://liujunjie11.github.io/2018/10/16/Mac%E4%B8%8B%E5%AE%89%E8%A3%85lightGBM/"/>
    <id>https://liujunjie11.github.io/2018/10/16/Mac下安装lightGBM/</id>
    <published>2018-10-16T05:13:23.000Z</published>
    <updated>2018-10-19T22:39:52.404Z</updated>
    
    <content type="html"><![CDATA[<p>最近需要这个算法做点东西，在此记录一下安装的过程。</p><a id="more"></a><h1 id="安装过程"><a href="#安装过程" class="headerlink" title="安装过程"></a>安装过程</h1><p>用homebrew安装相关的插件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">brew install cmake</div><div class="line">brew install gcc --without-multilib</div></pre></td></tr></table></figure><blockquote><p>在安装之后如果在使用<code>cmake ..</code>命令行出现了关于在下载的<em>cmake</em>的相关的问题时，可以考虑<code>brew uninstall cmake</code>，然后重新下载。这种问题我就遇上了…</p></blockquote><p>下载好gcc之后，我配置了一下环境问题，如图：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-16%20%E4%B8%8B%E5%8D%881.25.10.png" alt=""></p><blockquote><p>使用命令行<code>vi ~/.bash_profile</code>配置环境变量问题。</p></blockquote><p>接下来是git下载相关的GitHub资源：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git <span class="built_in">clone</span> --recursive https://github.com/Microsoft/LightGBM</div></pre></td></tr></table></figure><p>依次使用下方命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> LightGBM</div><div class="line"><span class="built_in">export</span> CXX=g++-8 CC=gcc-8</div><div class="line">mkdir build </div><div class="line"><span class="built_in">cd</span> build</div><div class="line">cmake ..</div><div class="line">make -j4</div></pre></td></tr></table></figure><blockquote><p>这样只要相关的插件下载完全了，一般就没什么问题出现了。</p></blockquote><p>之后可以使用pip命令下载了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install --no-binary :all: lightgbm</div></pre></td></tr></table></figure><blockquote><p>由于不是很懂这个命令，我又使用了<code>pip install lightgbm</code>。</p></blockquote><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>如图：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-16%20%E4%B8%8B%E5%8D%881.23.55.png" alt=""></p><blockquote><p>用的是anaconda默认的python3环境。</p></blockquote><h1 id="遇到的错误问题"><a href="#遇到的错误问题" class="headerlink" title="遇到的错误问题"></a>遇到的错误问题</h1><p>如下类似问题：</p><pre><code>OSError: dlopen(/usr/local/lib/python3.6/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/gcc/lib/gcc/7/libgomp.1.dylib  Referenced from: /usr/local/lib/python3.6/site-packages/lightgbm/lib_lightgbm.so  Reason: image not found</code></pre><blockquote><p>解决方案：<a href="https://github.com/Microsoft/LightGBM/issues/1369" target="_blank" rel="external">https://github.com/Microsoft/LightGBM/issues/1369</a></p></blockquote><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li><p><a href="http://lightgbm.apachecn.org/cn/latest/Installation-Guide.html" target="_blank" rel="external">http://lightgbm.apachecn.org/cn/latest/Installation-Guide.html</a></p></li><li><p><a href="https://blog.csdn.net/fitzgerald0/article/details/78321527?utm_source=blogxgwz4" target="_blank" rel="external">https://blog.csdn.net/fitzgerald0/article/details/78321527?utm_source=blogxgwz4</a></p></li><li><p><a href="https://github.com/Microsoft/LightGBM/issues/1369" target="_blank" rel="external">https://github.com/Microsoft/LightGBM/issues/1369</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近需要这个算法做点东西，在此记录一下安装的过程。&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Mac上下载xgboost</title>
    <link href="https://liujunjie11.github.io/2018/10/15/Mac%E4%B8%8A%E4%B8%8B%E8%BD%BDxgboost/"/>
    <id>https://liujunjie11.github.io/2018/10/15/Mac上下载xgboost/</id>
    <published>2018-10-15T14:01:48.000Z</published>
    <updated>2018-10-19T22:41:12.096Z</updated>
    
    <content type="html"><![CDATA[<p>这会有事了，感觉有必要记录一下。</p><p>最近想搞搞<em>kaggle</em>的入门级比赛，参考他人的<em>kernel</em>用到了<em>xgboost</em>，但是安装时遇到了一些坑，特别是<a href="https://xgboost.readthedocs.io/en/latest/build.html" target="_blank" rel="external">官网的安装教程</a>…真的让人吐血，根本不能解决我要安装的欲望。以下是我参考了一些文章并且成功安装的经验记录。</p><a id="more"></a><h1 id="安装过程"><a href="#安装过程" class="headerlink" title="安装过程"></a>安装过程</h1><p>先用homebrew下载相关的依赖：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">brew install gcc --without-multilib</div></pre></td></tr></table></figure><blockquote><p>加上<code>--without-multilib</code>目的是开启默认不开启支持多线程的插件。</p></blockquote><p>然后git下载在GitHub上的xgboost：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git <span class="built_in">clone</span> --recursive https://github.com/dmlc/xgboost</div></pre></td></tr></table></figure><blockquote><p>最好下载在根目录。</p></blockquote><p>下载完成之后：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> xgboost</div></pre></td></tr></table></figure><p>修改相关的配置文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vi config.mk</div></pre></td></tr></table></figure><blockquote><p>实际上这个文件有好多个，我最终都修改成一致的了…如下图</p></blockquote><p><img src="http://owudg3xs2.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-16%20%E4%B8%8A%E5%8D%8810.25.58.png" alt=""></p><p>修改内容为，改成用homebrew下载的gcc版本目录地址：</p><pre><code>export CC = /usr/local/Cellar/gcc/8.2.0/bin/gcc-8export CXX = /usr/local/Cellar/gcc/8.2.0/bin/g++-8export MPICXX = /usr/local/Cellar/gcc/8.2.0/bin/mpicxx</code></pre><p>如图：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-16%20%E4%B8%8A%E5%8D%8810.27.14.png" alt=""></p><p>之后使用命令行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cp make/config.mk ./config.mk</div><div class="line">make -j4</div></pre></td></tr></table></figure><blockquote><p><code>-j4</code>是开启4个线程的意思。</p></blockquote><p>之后就是编译成包的过程了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> python-package</div><div class="line">   python setup.py install</div></pre></td></tr></table></figure><blockquote><p>我用的是anaconda的python版本。</p></blockquote><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>如图：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-16%20%E4%B8%8A%E5%8D%8810.31.22.png" alt=""></p><p>这样就大功告成了。</p><h1 id="期间遇到过的问题"><a href="#期间遇到过的问题" class="headerlink" title="期间遇到过的问题"></a>期间遇到过的问题</h1><h2 id="问题一："><a href="#问题一：" class="headerlink" title="问题一："></a>问题一：</h2><pre><code>XGBoostLibraryNotFound: Cannot find XGBoost Libarary in the candidate path, did you install compilers and run build.sh in root path?List of candidates:/home/dmlc/anaconda/lib/python3.6/site-packages/xgboost-0.4-py3.6.egg/xgboost/libxgboostwrapper.so/home/dmlc/anaconda/lib/python3.6/site-packages/xgboost-0.4-py3.6.egg/xgboost/../../wrapper/libxgboostwrapper.so/home/dmlc/anaconda/lib/python3.6/site-packages/xgboost-0.4-py3.6.egg/xgboost/./wrapper/libxgboostwrapper.so</code></pre><p>此类问题，可能是<code>git clone --recursive https://github.com/dmlc/xgboost</code>下载执行未完全。</p><h2 id="问题二"><a href="#问题二" class="headerlink" title="问题二"></a>问题二</h2><p>使用命令行<code>make -j4</code>时出现：</p><pre><code>clang: error: unsupported option &apos;-fopenmp&apos;</code></pre><p>如图：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-16%20%E4%B8%8A%E5%8D%8810.47.57.png" alt=""></p><p>解决方案：</p><pre><code>export CC = /usr/local/Cellar/gcc/8.2.0/bin/gcc-8export CXX = /usr/local/Cellar/gcc/8.2.0/bin/g++-8export MPICXX = /usr/local/Cellar/gcc/8.2.0/bin/mpicxx</code></pre><blockquote><p>这只是未能识别相关插件的问题，修改文件<code>config.mk</code>相关的部分如上即可。</p><p>在此参考了：<a href="https://stackoverflow.com/questions/36211018/clang-error-errorunsupported-option-fopenmp-on-mac-osx-el-capitan-buildin" target="_blank" rel="external">https://stackoverflow.com/questions/36211018/clang-error-errorunsupported-option-fopenmp-on-mac-osx-el-capitan-buildin</a></p></blockquote><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><ul><li><p><a href="https://www.jianshu.com/p/c2b0c3067d84" target="_blank" rel="external">https://www.jianshu.com/p/c2b0c3067d84</a></p></li><li><p><a href="https://www.jianshu.com/p/76ff402a8b58" target="_blank" rel="external">https://www.jianshu.com/p/76ff402a8b58</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/23996104" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/23996104</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这会有事了，感觉有必要记录一下。&lt;/p&gt;
&lt;p&gt;最近想搞搞&lt;em&gt;kaggle&lt;/em&gt;的入门级比赛，参考他人的&lt;em&gt;kernel&lt;/em&gt;用到了&lt;em&gt;xgboost&lt;/em&gt;，但是安装时遇到了一些坑，特别是&lt;a href=&quot;https://xgboost.readthedocs.io/en/latest/build.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;官网的安装教程&lt;/a&gt;…真的让人吐血，根本不能解决我要安装的欲望。以下是我参考了一些文章并且成功安装的经验记录。&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>思考意义</title>
    <link href="https://liujunjie11.github.io/2018/10/15/%E6%80%9D%E8%80%83%E6%84%8F%E4%B9%89/"/>
    <id>https://liujunjie11.github.io/2018/10/15/思考意义/</id>
    <published>2018-10-15T12:38:30.000Z</published>
    <updated>2018-10-15T13:17:01.567Z</updated>
    
    <content type="html"><![CDATA[<p>追个不舍，活着的意义是什么，我还在寻找。</p><p>但现在我想我有些开怀了。</p><p>从来到走，不谈虚无，我想记录一些实在的心里话。</p><a id="more"></a><p>我向着“大爱”，做我能做和我想做的事，而我在平凡，苟活之间有些小的挣扎，但我依然也对什么虚荣不感冒。我矛盾，还是无法完全说服自己。我有些犹豫，这世间的种种诱惑真的有些感染到我，曾经的我，不为所动，但如今我愿意去了解更多存在于在这世间的人们，我变得有些“贪恋”人间了，如今的世界在我眼里更偏向像是个乌托邦式。</p><p>但是现在冷静下来想想，原来还是我向着“大爱”的心绪不宁了。我自相矛盾有时就会无缘无故的在我思维里像是小鹿乱撞一样，到头来也是把我自己搞得哭笑不得。</p><p>我想接下传承的接力棒，做我能做和做我想做的事。我也想尽一份力，帮助需要的所有，我愿意付出，但不会盲目。</p><p>得先是我自己，体验生而为“人”的人生生活。生而为“人”，有着各自的灵魂，做自己是生为“人”的基本原则。</p><p>我知道我的答案可能只是暂时的，但只会比现在更加积极。</p><p>即刻想想，现在心血来潮记录的这些东西也不足挂齿了，心里想说的话是永远说不完，写不完的，我再想想我执着着记录这些东西是为什么，不过是为了记录当今这个时段我内心的部分想法罢了。</p><p>看了看，又是草草了事呐～</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;追个不舍，活着的意义是什么，我还在寻找。&lt;/p&gt;
&lt;p&gt;但现在我想我有些开怀了。&lt;/p&gt;
&lt;p&gt;从来到走，不谈虚无，我想记录一些实在的心里话。&lt;/p&gt;
    
    </summary>
    
      <category term="思考" scheme="https://liujunjie11.github.io/categories/%E6%80%9D%E8%80%83/"/>
    
    
      <category term="思考" scheme="https://liujunjie11.github.io/tags/%E6%80%9D%E8%80%83/"/>
    
  </entry>
  
  <entry>
    <title>吾道</title>
    <link href="https://liujunjie11.github.io/2018/10/13/%E5%90%BE%E9%81%93/"/>
    <id>https://liujunjie11.github.io/2018/10/13/吾道/</id>
    <published>2018-10-13T09:06:00.000Z</published>
    <updated>2018-10-13T09:15:09.856Z</updated>
    
    <content type="html"><![CDATA[<p>道非道，自成道。</p><p>吾道，非常言道，非万物道，吾道属吾道。</p><a id="more"></a><p>吾道，在吾一念之间，可从无，可从有。</p><p>吾道，吾道，还在继往开来之时。</p><p>吾道，与时无关，与实无关，可有可无。</p><p>吾道，贪恋未来，不念过往。</p><p>吾道之成，在终了之时。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;道非道，自成道。&lt;/p&gt;
&lt;p&gt;吾道，非常言道，非万物道，吾道属吾道。&lt;/p&gt;
    
    </summary>
    
      <category term="何为吾道" scheme="https://liujunjie11.github.io/categories/%E4%BD%95%E4%B8%BA%E5%90%BE%E9%81%93/"/>
    
    
      <category term="何为吾道" scheme="https://liujunjie11.github.io/tags/%E4%BD%95%E4%B8%BA%E5%90%BE%E9%81%93/"/>
    
  </entry>
  
  <entry>
    <title>Hexo博客绑定独立域名以及转移云服务器</title>
    <link href="https://liujunjie11.github.io/2018/10/12/Hexo%E5%8D%9A%E5%AE%A2%E7%BB%91%E5%AE%9A%E7%8B%AC%E7%AB%8B%E5%9F%9F%E5%90%8D%E4%BB%A5%E5%8F%8A%E8%BD%AC%E7%A7%BB%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
    <id>https://liujunjie11.github.io/2018/10/12/Hexo博客绑定独立域名以及转移云服务器/</id>
    <published>2018-10-12T06:41:54.000Z</published>
    <updated>2018-10-19T22:43:56.939Z</updated>
    
    <content type="html"><![CDATA[<p>最近对我的博客进行了一系列大换血，以前的样子太难看了，而且速度也一直不怎么满意，这次想好好的修改一下，其中包括了买了个域名，转移到了云服务器上运行。</p><p>当然在昨天开始就开始折腾了，所以把所有想要记录的都在此记录一下。</p><a id="more"></a><h1 id="大换血修改设置"><a href="#大换血修改设置" class="headerlink" title="大换血修改设置"></a>大换血修改设置</h1><p>关于这个我就贴上相关的链接好了，毕竟重复造轮子不是我的初衷。</p><p>一些对我有帮助的链接，谢谢分享的网友们：</p><ul><li><p><a href="https://asdfv1929.github.io/2018/01/21/daovoice/" target="_blank" rel="external">Hexo NexT主题内接入网页在线联系功能</a></p></li><li><p><a href="https://blog.csdn.net/qq_33699981/article/details/72716951" target="_blank" rel="external">hexo的next主题个性化教程：打造炫酷网站</a></p></li><li><p><a href="http://blog.sciencenet.cn/blog-3247241-1139774.html" target="_blank" rel="external">hexo博客解决不蒜子统计无法显示问题</a></p></li><li><p><a href="http://zouzls.github.io/2017/03/17/Next主题背景个性化DIY/" target="_blank" rel="external">Next主题背景个性化DIY</a></p></li><li><p><a href="https://www.jianshu.com/p/b20fc983005f" target="_blank" rel="external">Hexo设置主题以及Next主题个性设置</a></p></li><li><p><a href="http://leozzy.com/2017/09/08/hexo-sidebar-auto/" target="_blank" rel="external">2017版 Hexo Next主题侧边栏 Sidebar 配置自动展开教程</a></p></li><li><p><a href="https://ohmyarch.github.io/2014/12/24/Hexo主页显示摘要/" target="_blank" rel="external">Hexo主页显示摘要</a></p></li><li><p><a href="https://segmentfault.com/q/1010000004840061/a-1020000004895286" target="_blank" rel="external">hexo next主题如何在首页摘要里显示文章图片？</a></p></li><li><p><a href="https://www.ofind.cn/blog/HEXO/HEXO下的语法高亮拓展修改.html" target="_blank" rel="external">HEXO下的语法高亮拓展修改</a></p></li><li><p><a href="https://juejin.im/entry/59d4a6a651882530f31a43f4" target="_blank" rel="external">打造个性超赞博客Hexo+NexT+GithubPages的超深度优化</a></p></li><li><p><a href="http://mashirosorata.vicp.io/HEXO-NEXT主题个性化配置.html" target="_blank" rel="external">HEXO+NEXT主题个性化配置</a></p></li></ul><blockquote><p>以上就不在写明作者了，都是一些比较有帮助的文章。</p></blockquote><p>在此简单说明一下关于我在<code>next</code>主题设置头像的问题，其实在主页的<code>_config.yml</code>设置一下就可以得出头像了，如下图，我将图片发在七牛云上，将外链拿到这里存放就好了。</p><p><img src="http://owudg3xs2.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-12%20%E4%B8%8B%E5%8D%882.54.00.png" alt=""></p><hr><h1 id="关于hexo博客绑定域名"><a href="#关于hexo博客绑定域名" class="headerlink" title="关于hexo博客绑定域名"></a>关于hexo博客绑定域名</h1><p>关于这个事我简单说一下好了，先放有用的链接，再稍微补充一下。</p><ul><li><p><a href="http://fengdaoting.com/2017/11/12/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/%E7%BB%91%E5%AE%9AGithub%E4%B8%8A%E7%9A%84%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E5%88%B0Godaddy%E5%9F%9F%E5%90%8D/" target="_blank" rel="external">绑定Github上的个人博客到Godaddy域名</a></p></li><li><p><a href="http://hushiyu1995.com/2017/10/01/build-web-1/index.html" target="_blank" rel="external">Github Page + Hexo + Godaddy 搭建一个个性域名的博客网站</a></p></li><li><p><a href="https://www.jianshu.com/p/6a3ee5b5abfd" target="_blank" rel="external">基于github和hexo搭建博客—-绑定个人域名</a></p></li><li><p><a href="https://www.dute.me/godaddy-alipay.html" target="_blank" rel="external">GoDaddy不支持支付宝的解决办法</a></p></li><li><p><a href="https://www.dute.me/" target="_blank" rel="external">GoDaddy优惠码</a></p></li></ul><h2 id="补充说明"><a href="#补充说明" class="headerlink" title="补充说明"></a>补充说明</h2><h3 id="关于查找GitHub-pages的ip"><a href="#关于查找GitHub-pages的ip" class="headerlink" title="关于查找GitHub pages的ip"></a>关于查找GitHub pages的ip</h3><p>两种方法：</p><p>第一种：</p><blockquote><p><code>ping liujunjie11.github.io</code> ping自己的博客目录地址</p></blockquote><p>如图：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-12%20%E4%B8%8B%E5%8D%883.00.33.png" alt=""></p><p>第二种：</p><p>打开网站<a href="https://help.github.com/articles/troubleshooting-custom-domains/，拉到下面查看相关的IP，如图：" target="_blank" rel="external">https://help.github.com/articles/troubleshooting-custom-domains/，拉到下面查看相关的IP，如图：</a></p><p><img src="http://owudg3xs2.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-12%20%E4%B8%8B%E5%8D%883.02.32.png" alt=""></p><h3 id="建立CNAME文件的存放目录"><a href="#建立CNAME文件的存放目录" class="headerlink" title="建立CNAME文件的存放目录"></a>建立CNAME文件的存放目录</h3><p>是要放在Hexo项目的sources目录下的，我为了保险在next的sources目录下也放了一份。</p><p>补充的就这么点了。</p><h1 id="Hexo转移到云服务器"><a href="#Hexo转移到云服务器" class="headerlink" title="Hexo转移到云服务器"></a>Hexo转移到云服务器</h1><p>这地方因为不怎么懂而且自身能力也不够，所以遇到了很多的坑，唉，有些人可能自己都搞不清楚就写文章了，搞完所有流程又不对…真的是无力吐槽了，花费了那么多精力。现在还没搞好，到时候补上需要说明的。</p><p>因为GitHub允许每个仓库在1GB左右的空间，而我现在寄托在GitHub的博客大小才130M…so,我现在不打算转移到云服务器了，到时候再说吧。</p><blockquote><p>GitHub的仓库内存说明：<a href="https://help.github.com/articles/what-is-my-disk-quota/" target="_blank" rel="external">https://help.github.com/articles/what-is-my-disk-quota/</a></p></blockquote><p>贴上参考过的链接：</p><ul><li><p><a href="https://segmentfault.com/a/1190000005723321" target="_blank" rel="external">阿里云VPS搭建自己的的Hexo博客</a></p></li><li><p><a href="https://www.hellolvs.com/hexo/" target="_blank" rel="external">VPS服务器搭建Hexo博客教程</a></p></li><li><p><a href="https://www.jianshu.com/p/ad71f7a531a5" target="_blank" rel="external">利用云服务器搭架Hexo个人博客</a></p></li><li><p><a href="https://www.laoyuyu.me/2017/10/10/hexo_deploy_vps/" target="_blank" rel="external">HEXO 部署到云服务器详细指南</a></p></li></ul><blockquote><p>也就是在云服务器上建好一些需要的软件，然后就像使用命令<code>hexo g -d</code>一样上传GitHub一样，并不需要重新开始所有。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近对我的博客进行了一系列大换血，以前的样子太难看了，而且速度也一直不怎么满意，这次想好好的修改一下，其中包括了买了个域名，转移到了云服务器上运行。&lt;/p&gt;
&lt;p&gt;当然在昨天开始就开始折腾了，所以把所有想要记录的都在此记录一下。&lt;/p&gt;
    
    </summary>
    
      <category term="Heox博客" scheme="https://liujunjie11.github.io/categories/Heox%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="Heox博客" scheme="https://liujunjie11.github.io/tags/Heox%E5%8D%9A%E5%AE%A2/"/>
    
  </entry>
  
  <entry>
    <title>关于错误ERROR Asset render failed: css/main.css</title>
    <link href="https://liujunjie11.github.io/2018/10/11/%E5%85%B3%E4%BA%8E%E9%94%99%E8%AF%AFERROR-Asset-render-failed-css-main-css/"/>
    <id>https://liujunjie11.github.io/2018/10/11/关于错误ERROR-Asset-render-failed-css-main-css/</id>
    <published>2018-10-11T11:54:03.000Z</published>
    <updated>2018-10-19T22:44:14.649Z</updated>
    
    <content type="html"><![CDATA[<p>在修改一些字体的时候使用<code>hexo s</code>/<code>hexo s -debug</code>时出现了以下错误：</p><pre><code>ERROR Asset render failed: css/main.cssError: /Users/junjieliu/liujunjie11.github.io/themes/next/source/css/main.styl:14:27   10|    11| // Variables Layer   12| // --------------------------------------------------   13| for $variable in $variables   14|   @import &quot;_variables/&quot; + $variable;---------------------------------^   15|    16|    17| // Mixins Layerfailed to locate @import file _variables/base.styl</code></pre><a id="more"></a><p>如图：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-11%20%E4%B8%8B%E5%8D%887.48.37.png" alt=""></p><h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><p>有个文件在我修改了一个字体参数之后出现了(如图)。还好我记得前面打开目录时是没有这个文件存在的，之后我把它删除再使用上面的命令就没有再报错了。</p><p><img src="http://owudg3xs2.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-11%20%E4%B8%8B%E5%8D%887.47.24.png" alt=""></p><blockquote><p>这个文件估计是在第一次修改相关文件的参数时才会出现，删除之后就能恢复正常了。</p></blockquote><h1 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h1><p>在删除之后发现问题还是解决不了，折腾了一下，去文件所指的目录地址去看了一下，发现了以下问题(如图)：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-12%20%E4%B8%8A%E5%8D%889.31.21.png" alt=""></p><blockquote><p>在此处的文件名自己发生了改变了，而且不知为何当初自己进了垃圾桶…把名字改回来<code>base.styl</code>之后再使用命令就没有再出现以上错误了。</p></blockquote><p>以下是这次错误相关的文件目录：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-12%20%E4%B8%8A%E5%8D%889.32.59.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在修改一些字体的时候使用&lt;code&gt;hexo s&lt;/code&gt;/&lt;code&gt;hexo s -debug&lt;/code&gt;时出现了以下错误：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ERROR Asset render failed: css/main.css
Error: /Users/junjieliu/liujunjie11.github.io/themes/next/source/css/main.styl:14:27
   10| 
   11| // Variables Layer
   12| // --------------------------------------------------
   13| for $variable in $variables
   14|   @import &amp;quot;_variables/&amp;quot; + $variable;
---------------------------------^
   15| 
   16| 
   17| // Mixins Layer

failed to locate @import file _variables/base.styl
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="Hexo博客" scheme="https://liujunjie11.github.io/categories/Hexo%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="Hexo博客" scheme="https://liujunjie11.github.io/tags/Hexo%E5%8D%9A%E5%AE%A2/"/>
    
  </entry>
  
  <entry>
    <title>Mac升级到Mojave版本之后的Safari插件问题</title>
    <link href="https://liujunjie11.github.io/2018/10/11/Mac%E5%8D%87%E7%BA%A7%E5%88%B0Mojave%E7%89%88%E6%9C%AC%E4%B9%8B%E5%90%8E%E7%9A%84Safari%E6%8F%92%E4%BB%B6%E9%97%AE%E9%A2%98/"/>
    <id>https://liujunjie11.github.io/2018/10/11/Mac升级到Mojave版本之后的Safari插件问题/</id>
    <published>2018-10-11T02:57:55.000Z</published>
    <updated>2018-10-11T12:48:50.791Z</updated>
    
    <content type="html"><![CDATA[<p>在升级到了<em>Mojave</em>最新版本之后的最大问题发现就是<em>Safari</em>浏览器之前一些常用的插件不能用了，其他的对我来说都是优点，系统比以前更加流畅了，优化了不少。</p><p>废话不多说了，我在此仅列出我常用的插件列表以及如何再次正常使用它们。</p><h1 id="插件一：Search-Engine-Switcher"><a href="#插件一：Search-Engine-Switcher" class="headerlink" title="插件一：Search Engine Switcher"></a>插件一：<em>Search Engine Switcher</em></h1><p>这款插件能够使得在使用浏览器搜索关键词时可以在百度、谷歌之间的搜索引擎变换搜索相关内容。在升级之后本来不被<em>Safari</em>支持了。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>打开新版的<em>app store</em>搜索关键词<em>Search Engine Switcher</em>直接下载即可用了。</p><a id="more"></a><h1 id="插件二：Adblock-Plus"><a href="#插件二：Adblock-Plus" class="headerlink" title="插件二：Adblock Plus"></a>插件二：<em>Adblock Plus</em></h1><p>这是一个让人头疼的问题，没有了之后广告太多了，受不了，找了一些付费的替代品，但是还是都不如<em>Adblock Plus</em>好用，在逛国外的一些论坛时发现了一个解决方案。</p><h2 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h2><p>下载<em>Adblock Plus</em>的最后一个在<em>Safari</em>的插件版本即可完美解决这个问题，不用去<em>app store</em>下载了，那个根本没什么用。</p><p>具体的可以先去下载这个插件即可直接使用了：</p><ul><li><strong><a href="https://uploadfiles.io/3q7wu" target="_blank" rel="external">https://uploadfiles.io/3q7wu</a></strong></li></ul><blockquote><p>这个链接是国外网友的分享，链接在此：<a href="https://forums.macrumors.com/threads/adblock-plus-not-working.2121621/" target="_blank" rel="external">https://forums.macrumors.com/threads/adblock-plus-not-working.2121621/</a></p><p>这是他的原话：Here you go dude: <a href="https://ufile.io/3q7wu" target="_blank" rel="external">https://ufile.io/3q7wu</a><br>It’s the original AdBlock.safariextz latest version! Just put it in the folder I mentioned above and enable it in Safari’s preferences. It should work. Good luck!</p></blockquote><p>下载完之后会跳转到这个网页：<a href="https://safari-extensions.apple.com/details/?id=com.betafish.adblockforsafari-UAMUU4S2D9" target="_blank" rel="external">https://safari-extensions.apple.com/details/?id=com.betafish.adblockforsafari-UAMUU4S2D9</a></p><p>直接下载就是了，一切和从前一样了…</p><p>如果在你下载之后没有得到什么实质性的作用，不妨可以看看官方的<a href="https://getadblock.com/update/2.70.0/?u=a210xe6x25809560" target="_blank" rel="external">解释</a>：</p><blockquote><p>在 2019 年的某个时候，我们将停止对传统扩展的支持，极少数特例除外。 我们强烈建议您迁移到我们的新 Mac 应用上来。 我们将在新的应用上投入全部精力，让 AdBlock for Safari 成为 Apple 设备上最好的广告拦截工具。</p></blockquote><p>这是好像有点运气成分的…</p><p>就这样了，that’s all!good luck~~</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在升级到了&lt;em&gt;Mojave&lt;/em&gt;最新版本之后的最大问题发现就是&lt;em&gt;Safari&lt;/em&gt;浏览器之前一些常用的插件不能用了，其他的对我来说都是优点，系统比以前更加流畅了，优化了不少。&lt;/p&gt;
&lt;p&gt;废话不多说了，我在此仅列出我常用的插件列表以及如何再次正常使用它们。&lt;/p&gt;
&lt;h1 id=&quot;插件一：Search-Engine-Switcher&quot;&gt;&lt;a href=&quot;#插件一：Search-Engine-Switcher&quot; class=&quot;headerlink&quot; title=&quot;插件一：Search Engine Switcher&quot;&gt;&lt;/a&gt;插件一：&lt;em&gt;Search Engine Switcher&lt;/em&gt;&lt;/h1&gt;&lt;p&gt;这款插件能够使得在使用浏览器搜索关键词时可以在百度、谷歌之间的搜索引擎变换搜索相关内容。在升级之后本来不被&lt;em&gt;Safari&lt;/em&gt;支持了。&lt;/p&gt;
&lt;h2 id=&quot;解决方案&quot;&gt;&lt;a href=&quot;#解决方案&quot; class=&quot;headerlink&quot; title=&quot;解决方案&quot;&gt;&lt;/a&gt;解决方案&lt;/h2&gt;&lt;p&gt;打开新版的&lt;em&gt;app store&lt;/em&gt;搜索关键词&lt;em&gt;Search Engine Switcher&lt;/em&gt;直接下载即可用了。&lt;/p&gt;
    
    </summary>
    
      <category term="Mac教程" scheme="https://liujunjie11.github.io/categories/Mac%E6%95%99%E7%A8%8B/"/>
    
    
      <category term="Mac教程" scheme="https://liujunjie11.github.io/tags/Mac%E6%95%99%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>旅程</title>
    <link href="https://liujunjie11.github.io/2018/09/29/%E6%97%85%E7%A8%8B/"/>
    <id>https://liujunjie11.github.io/2018/09/29/旅程/</id>
    <published>2018-09-29T10:40:55.000Z</published>
    <updated>2018-10-11T12:49:14.163Z</updated>
    
    <content type="html"><![CDATA[<p>一段在活着的人生旅程是相对矛盾的，常常也因此而把自己堵塞的一言不能发。</p><p>观看完《云图》之后引发了我的一系列思考，虽然在曾经都有过接触的那些思想，但是从书上或者是自己思考得出的相比，从电影的形式来进行描述何尝不是一种更好的选择。《云图》是一部好作品，她给我的启示对于我想要寻找的答案来说是有一定推进作用的，不知怎么的我想记下现在所想的一些东西，不妨叫其为，“观《云图》有感吧”。</p><a id="more"></a><p>人与人之间是相互牵连着的，每个人的所作所为都会对在这世上的人产生一定的影响的，继而形成一个链式反应，“人类是命运共同体”，这样理解也不为过。我看完《云图》感受是一股“勿以善小而不为”的感受的，当然这部作品本身给我的信息远不止如此。她另外给了我的信息是：捍卫心中认为正确的真相、真理，哪怕付出所有；勇敢去做自己认为对的事情，哪怕只有自身一人的力量那般微不足道。在上的前提是我们真的是我们自己，不受世间规则的约束，不受世间传统的的纠缠。</p><p>“稳定的发展”不应成为“被规则”的理由。世界的稳定维持，好似是有一股神秘的力量在背后发挥着作用，这股力量引导着世世代代的人们生活着的世界从有到现在，如今的人们把这股力量称为世间的自然秩序。多数的人们怕破坏了这秩序，世间的稳定发展会发生动摇，会引来这股神秘力量的报复，久而久之秩序成为了一种活着的人们都应该要被遵守的规则，秩序规则，规则秩序，源远流长，不声不息。所以会有大多数人会为了“稳定的发展”而也会要求其他人不要不遵守这些规则，更不允许被破坏这些股规则。该称之为一般的“伟大”吗？套着“稳定”外衣的“规则”。这股秩序规则的存在恰恰也是限制当世人们的一条锁链，给人的感觉就是一切都是被安排好的，一切都是冥冥中自有的存在与发生，这难道不是一种“洗脑”吗？大多数人们会因此变得沉默，他们以为这就是一切早已安排好的天命，而我只需要静静的，毫无波澜的干自己该做的事便好。这是一种对鲜活生命的摧残，一种对生命的不尊重，一种教人们对自己生命的不负责。一条生命在诞生之时，他就是独立的，并且一直都是独立的，孤独？“孤独”不过是煽情的人们用来安慰、说服自己的字词理由罢了。人，生而孤独，生而独立，所以这世间的规则并不是我们应当铭记于心的，而应该是我们根据自己的选择去选择的，世间规则不应当成为生而为人的我们的必须枷锁。但是世间也需要规则，也需要秩序，这一点也是毫无破绽的。我可以适当的遵守一定规则，但我永远不会将其铭记于心，更不会让其成为我自由生长的一把枷锁。“规则”有时一旦被另有企图的人们所利用，稍加不当作为一种源远流长，依旧可能会成为一些人们堕落的根源。</p><p>一个人真正的成长与成熟不是学会了如何精通这世间的规则继而将此铭记于心成为一个形态意识上的墨守陈规的人，而是一个在知晓了这世间大多数的规则之下，却依旧能做自己的人。前者已经失去了自我，不再是一个真正独立的人了。</p><p>活在这世间，实属不易，有牵绊，有诱惑，有不解。守护本心，活成自己有时变得那么难，那么难，很多时候我们难真正的成为自己，过着自己理想的生活，做着自己喜欢的事。但是这些都不能成为理由而不去成为自己，多些在自己的空间里多加思考会发现这原本只是两回事的存在罢了。</p><p>守护那来之不易的真相，并且舍得去奉献。</p><p>人生来的旅程，一千个人有一千颗心，有一千个自己的存在。世间因此也变得“矛盾”，还是本身就是一个矛盾体？无论如何，人类命运体中伴随着矛盾是不可避免的事实，那是因为”我们“的存在。这世间值得一走，一走一停，探究其秘，何乐而不为。</p><p>我曾看到一句话我很喜欢：</p><blockquote><p><strong>笑对人生，独立寰宇。</strong></p></blockquote><p>完。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一段在活着的人生旅程是相对矛盾的，常常也因此而把自己堵塞的一言不能发。&lt;/p&gt;
&lt;p&gt;观看完《云图》之后引发了我的一系列思考，虽然在曾经都有过接触的那些思想，但是从书上或者是自己思考得出的相比，从电影的形式来进行描述何尝不是一种更好的选择。《云图》是一部好作品，她给我的启示对于我想要寻找的答案来说是有一定推进作用的，不知怎么的我想记下现在所想的一些东西，不妨叫其为，“观《云图》有感吧”。&lt;/p&gt;
    
    </summary>
    
      <category term="感想日记" scheme="https://liujunjie11.github.io/categories/%E6%84%9F%E6%83%B3%E6%97%A5%E8%AE%B0/"/>
    
    
      <category term="感想日记" scheme="https://liujunjie11.github.io/tags/%E6%84%9F%E6%83%B3%E6%97%A5%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>科学上网，自建VPS-SS应用</title>
    <link href="https://liujunjie11.github.io/2018/09/28/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%EF%BC%8C%E8%87%AA%E5%BB%BAVPS-SS%E5%BA%94%E7%94%A8/"/>
    <id>https://liujunjie11.github.io/2018/09/28/科学上网，自建VPS-SS应用/</id>
    <published>2018-09-28T14:15:07.000Z</published>
    <updated>2018-10-19T22:44:22.381Z</updated>
    
    <content type="html"><![CDATA[<p>最近因为需求想自己搭建一个VPS加SS应用。用的是<a href="https://www.vultr.com/?ref=7548655" target="_blank" rel="external">Vultr</a>这个平台。</p><p>唉…这东西的教程已经是满大街都是了，我就不重复造轮子了，现在的轮子还没有失效。</p><a id="more"></a><p>具体的服务器租建过程可参考：</p><ul><li><p><a href="https://github.com/Alvin9999/new-pac/wiki/自建ss服务器教程" target="_blank" rel="external">自建ss服务器教程</a></p></li><li><p><a href="https://medium.com/@zoomyale/科学上网的终极姿势-在-vultr-vps-上搭建-shadowsocks-fd57c807d97e" target="_blank" rel="external">科学上网的终极姿势-在-vultr-vps-上搭建</a></p></li><li><p><a href="http://mpc2008cn.github.io/2015/10/22/vps/" target="_blank" rel="external">Vultr的vps搭建shadowsocks翻墙</a></p></li><li><p><a href="https://segmentfault.com/a/1190000015558387" target="_blank" rel="external">超详细 Vultr（VPS）搭建 SS / 新手图文指导教程</a></p></li><li><p><a href="https://blog.whsir.com/post-1045.html" target="_blank" rel="external">如何查看修改ss服务器的端口密码</a></p></li><li><p><a href="https://blog.whsir.com/post-274.html" target="_blank" rel="external">shadowsocks多端口密码手动配置方法</a></p></li><li><p><a href="https://blog.csdn.net/Feng512275/article/details/79701885" target="_blank" rel="external">SS多用户配置</a></p></li><li><p><a href="https://blog.csdn.net/ljbmxsm/article/details/50650008" target="_blank" rel="external">Linux查看端口占用情况和开启端口命令</a></p></li><li><p><a href="http://975156298.iteye.com/blog/2323688" target="_blank" rel="external">Linux下iptables 禁止端口和开放端口</a></p></li></ul><p>关于在<em>TCP Fast Open</em>过程中命令行增加的一些补充(我自己加上的)：</p><blockquote><p>每一次的…ipv4…之外我都加上了…ipv6…的一样的命令行。</p><p>如：<code>echo 3 &gt; /proc/sys/net/ipv4/tcp_fastopen</code><br>另外加上了：<code>echo 3 &gt; /proc/sys/net/ipv6/tcp_fastopen</code></p><p>如：<code>net.ipv4.tcp_fastopen = 3</code><br>另外加上了：<code>net.ipv6.tcp_fastopen = 3</code></p></blockquote><p>…</p><p><strong>其中注意的细节是：</strong></p><ol><li><p><strong>开通服务器时，当出现了ip，不要立马去ping或者用xshell去连接，再等5分钟之后，有个缓冲时间。</strong></p></li><li><p><strong>注意加密算法的对齐填写。</strong></p></li><li><p>后续补充…</p></li></ol><p>简单说说体验吧，用的是在日本的服务器，经过上面的参考之后，换了好几台服务器才有了现在的暂时稳定…另外要补充一下：如果在使用命令行<code>ssh root@&lt;ip&gt;</code>不通时(即没有提示要求输入密码登陆的出现的其他情况，比如超时)，直接重新另外开一台就是了，不用再花多余的时间去测试了。</p><p>我一共换了好几台才有3台是可以用的…心累…可能是我太急了？？有可能。</p><p><strong>补充：目前上YouTube测试最高连接可以达到25M/s…超级快的哈哈哈哈～～估计还可以上升～～～美滋滋～～</strong></p><h1 id="补充说明"><a href="#补充说明" class="headerlink" title="补充说明"></a>补充说明</h1><p>最近添加了多个用户的设置，即添加了多个独立端口以及独立密码，均需要将端口添加至服务器端口列表才行，并且还要注意添加<em>tcp/udp协议</em>，这很重要。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近因为需求想自己搭建一个VPS加SS应用。用的是&lt;a href=&quot;https://www.vultr.com/?ref=7548655&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Vultr&lt;/a&gt;这个平台。&lt;/p&gt;
&lt;p&gt;唉…这东西的教程已经是满大街都是了，我就不重复造轮子了，现在的轮子还没有失效。&lt;/p&gt;
    
    </summary>
    
      <category term="科学上网" scheme="https://liujunjie11.github.io/categories/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"/>
    
    
      <category term="科学上网" scheme="https://liujunjie11.github.io/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"/>
    
  </entry>
  
  <entry>
    <title>读西游，得“真经”</title>
    <link href="https://liujunjie11.github.io/2018/09/27/%E8%AF%BB%E8%A5%BF%E6%B8%B8%EF%BC%8C%E5%BE%97%E2%80%9C%E7%9C%9F%E7%BB%8F%E2%80%9D/"/>
    <id>https://liujunjie11.github.io/2018/09/27/读西游，得“真经”/</id>
    <published>2018-09-27T10:54:40.000Z</published>
    <updated>2018-10-11T12:49:20.923Z</updated>
    
    <content type="html"><![CDATA[<p>这次兴趣来了想读读西游原著，之前也读过一些金典原著，都是读过几章节便草草了事了…</p><p>由于很喜欢孙悟空这个角色，所以才有心血来潮之意想认真读读，其中又惊又喜，发现了一个不同的孙悟空，各位对西游感兴趣的真应该好好读读呀。</p><blockquote><ul><li><a href="https://pan.baidu.com/s/1ygYeZSm2jSIm7gJFPJjDvA" target="_blank" rel="external">西游记原著下载链接</a></li></ul></blockquote><p>西游记乃是我等先辈所流传下来的文化宝藏，值得我等后辈花点时间精力来进行基本上的纠正解读，以此来”普度众生”，哈哈。</p><p>所以，记下的这篇文章仅是起到普及有关西游知识之用。</p><a id="more"></a><h1 id="西游记别全名"><a href="#西游记别全名" class="headerlink" title="西游记别全名"></a>西游记别全名</h1><p>见文第一章：</p><blockquote><p>诗曰:<br>  混沌未分天地乱，茫茫渺渺无人见。<br>  自从盘古破鸿蒙，开辟从兹清浊辨。<br>  覆载群生仰至仁，发明万物皆成善。<br>  欲知造化会元功，须看西游释厄传。</p></blockquote><p>在此我们可以看到西游记的别全名为“<strong>西游释厄传</strong>”。</p><h1 id="孙悟空“美猴王”一称呼由来"><a href="#孙悟空“美猴王”一称呼由来" class="headerlink" title="孙悟空“美猴王”一称呼由来"></a>孙悟空“美猴王”一称呼由来</h1><p>见文第一章：</p><blockquote><p>…石猿端坐上面道: “列位呵，‘人而无信，不知其可。’你们才说有本事进得来，出得去，不伤身体者，就拜他 为王。我如今进来又出去，出去又进来，寻了这一个洞天与列位安眠稳睡，各享成家之福， 何不拜我为王?”众猴听说，即拱伏无违。一个个序齿排班，朝上礼拜，都称“千岁大王”。 自此，石猴高登王位，将“石”字儿隐了，遂称美猴王。…</p></blockquote><p>进得来进得去指的是水帘洞。以上解读已经清晰明了，孙悟空以大胆之能征服了众猴，使得众猴甘拜称呼孙悟空为“美猴王”了。在这之后作者本人也经常引用“美猴王”来称呼孙悟空，这就容易造成人们也如出一辙的叫孙悟空为美猴王了，更有甚者，以为孙悟空长得漂亮…其实不然，可见我下面的纠正解读。</p><h1 id="孙悟空为何要执意学道，离走花果山？"><a href="#孙悟空为何要执意学道，离走花果山？" class="headerlink" title="孙悟空为何要执意学道，离走花果山？"></a>孙悟空为何要执意学道，离走花果山？</h1><p>见文第一章：</p><blockquote><p>…一日，与群猴喜宴之间，忽然忧恼，堕下泪来。众猴慌忙罗拜道:“大王何为烦恼?”猴王道:“我虽在欢喜之时，却有一点儿远虑，故此烦恼。” 众猴又笑道:“大王好不知足!我等日日欢会，在仙山福地，古洞神州，不伏麒麟辖，不伏凤 凰管，又不伏人间王位所拘束，自由自在，乃无量之福，为何远虑而忧也?”猴王道:“今日 虽不归人王法律，不惧禽兽威服，将来年老血衰，暗中有阎王老子管着，一旦身亡，可不枉 生世界之中，不得久住天人之内?”众猴闻此言，一个个掩面悲啼，俱以无常为虑。只见那班部中，忽跳出一个通背猿猴，厉声高叫道:“大王若是这般远虑，真所谓道心开 发也!如今五虫之内，惟有三等名色，不伏阎王老子所管。”猴王道:“你知那三等人?”猿 猴道:“乃是佛与仙与神圣三者，躲过轮回，不生不灭，与天地山川齐寿。”猴王道:“此三者 居于何所?”猿猴道:“他只在阎浮世界之中，古洞仙山之内。”猴王闻之，满心欢喜，道: “我明日就辞汝等下山，云游海角，远涉天涯，务必访此三者，学一个不老长生，常躲过阎 君之难。”噫!这句话，顿教跳出轮回网，致使齐天大圣成。众猴鼓掌称扬，都道:“善哉! 善哉!我等明日越岭登山，广寻些果品，大设筵宴送大王也。”…</p></blockquote><p>在此的“猴王”指的是孙悟空。孙悟空是个有情有义有担当的首领，是个为民为小的们为花果山着想的好大王，他有远见并且有勇有谋有智慧，愿意为了小的们独自一人去花费数年走尽千山万水，忍受人间俗人们的骂和打去寻求永生之道,以便学成之后带回来教授与小的们。在花果山他是个不折不扣的英雄。这也是为何孙悟空每次一回来花果山(在电视剧中就能感受到)就那么深得猴心，猴们和他的感情相互都很深的原因。其中论据可见下文证：</p><blockquote><p>…次日，美猴王早起， 教:“小的们，替我折些枯松，编作筏子，取个竹竿作篙，收拾些果品之类，我将去也。”果 独自登筏，尽力撑开，飘飘荡荡，径向大海波中，趁天风，来渡南赡部洲地界。…</p><p>…猴王参访仙道，无缘得遇。在于南赡部洲，串长城，游小县，不觉八九年馀。忽行至西洋大海，他想着海外必有神仙。独自个依前作筏，又飘过西海，直至西牛贺洲地界。…</p><p>…祖师道:“既是逐渐行来的也罢。你姓甚么?”猴王又道:“我无性。人若骂我，我也不 恼;若打我，我也不嗔，只是陪个礼儿就罢了。一生无性。”…</p></blockquote><h1 id="孙悟空的本性"><a href="#孙悟空的本性" class="headerlink" title="孙悟空的本性"></a>孙悟空的本性</h1><p>暂且不谈孙悟空自从石中蹦出来以能力以胆量征服众猴称王得“美猴王”美名的事(不是强迫众猴俯首称臣)，况且可见下文：</p><blockquote><p>…将那跑不动的拿住一个，剥了他衣裳，也学人 穿在身上，摇摇摆摆，穿州过府，在市尘中，学人礼，学人话。朝餐夜宿，一心里访问佛仙 神圣之道，觅个长生不老之方。…(兽有兽语，孙悟空与小的们交谈用的不是人语。)</p><p>…猴王用手扯住樵夫道:“老兄， 你便同我去去。若还得了好处，决不忘你指引之恩。”樵夫道:“你这汉子，甚不通变。我方 才这般与你说了，你还不省?假若我与你去了，却不误了我的生意?老母何人奉养?我要斫 柴，你自去，自去。”…</p><p>祖师道:“既是逐渐行来的也罢。你姓甚么?”猴王又道:“我无性。人若骂我，我也不 恼;若打我，我也不嗔，只是陪个礼儿就罢了。一生无性。”…</p></blockquote><p>经过上面的简单分析解读，孙悟空生来性本善，在人间行走懂得去粗取精，学人礼貌行事，也学人懂得用回报来感谢他人帮忙，是只好学并且懂得精学，聪明的猴子(遵守人间规则方才能在人间行走的游刃有余)。另外也可这么分析，他生来就是无性的，如同一张白纸，这原因已经明了，不再啰嗦了，明者自明。</p><h1 id="“孙悟空”名字的由来"><a href="#“孙悟空”名字的由来" class="headerlink" title="“孙悟空”名字的由来"></a>“孙悟空”名字的由来</h1><p>见文第一章：</p><blockquote><p>…祖师道:“既是逐渐行来的也罢。你姓甚么?”猴王又道:“我无性。人若骂我，我也不 恼;若打我，我也不嗔，只是陪个礼儿就罢了。一生无性。”祖师道:“不是这个性。你父母 原来姓甚么?”猴王道:“我也无父母。”祖师道:“既无父母，想是树上生的?”猴王道:“我 虽不是树生，却是石里长的。我只记得花果山上有一块仙石，其年石破，我便生也。”祖师闻 言，暗喜道:“这等说，却是天地生成的。你起来走走我看。”猴王纵身跳起，拐呀拐的走了 两遍。祖师笑道:“你身躯虽是鄙陋，却像个食松果的猢狲。我与你就身上取个姓氏，意思教 你姓‘猢’。猢字去了个兽傍，乃是古月。古者，老也;月者，阴也。老阴不能化育，教你姓 ‘狲’倒好。狲字去了兽傍，乃是个子系。子者，儿男也;系者，婴细也。正合婴儿之本论。 教你姓‘孙’罢。”猴王听说，满心欢喜，朝上叩头道:“好!好!好!今日方知姓也。万望 师父慈悲!既然有姓，再乞赐个名字，却好呼唤。”祖师道:“我门中有十二个字，分派起名 到你乃第十辈之小徒矣。”猴王道:“那十二个字?”祖师道:“乃广、大、智、慧、真、如、 性、海、颖、悟、圆、觉十二字。排到你，正当‘悟’字。与你起个法名叫做‘孙悟空’好 么?”猴王笑道:“好!好!好!自今就叫做孙悟空也!”正是:鸿蒙初辟原无姓，打破顽空 须悟空。…</p></blockquote><p>在上“祖师”所指<strong>须菩提祖师</strong>；“猴王”即指美猴王是也(在此处的“美猴王”其实是花果山上的猴臣子们所奉石猴之名)。</p><h1 id="孙悟空为何不能继续留在须菩提祖师身边得道"><a href="#孙悟空为何不能继续留在须菩提祖师身边得道" class="headerlink" title="孙悟空为何不能继续留在须菩提祖师身边得道"></a>孙悟空为何不能继续留在须菩提祖师身边得道</h1><p>见文第二章：</p><blockquote><p>…一日，春归夏至，大众都在松树下会讲多时。大众曰:“悟空，你是那世修来的缘法?前 日师父拊耳低言，传与你的躲三灾变化之法，可都会么?”悟空笑道:“不瞒诸兄长说，一则 是师父传授，二来也是我昼夜殷勤，那几般儿都会了。”大众道:“趁此良时，你试演演，让 我等看看。”悟空闻说，抖搜精神，卖弄手段道:“众师兄请出个题目。要我变化甚么?”大 众道:“就变棵松树罢。”悟空捻着诀，念动咒语，摇身一变，就变做一棵松树。真个是:郁郁含烟贯四时，凌云直上秀贞姿。全无一点妖猴像，尽是经霜耐雪枝。大众见了，鼓掌呀呀大笑。都道:“好猴儿!好猴儿!” 不觉的嚷闹，惊动了祖师。祖师急拽杖出门来问道:“是何人在此喧哗?”大众闻呼，慌忙检 束，整衣向前。悟空也现了本相，杂在丛中道:“启上尊师，我等在此会讲，更无外姓喧哗。” 祖师怒喝道:“你等大呼小叫，全不像个修行的体段!修行的人，口开神气散，舌动是非生。 如何在此嚷笑?”大众道:“不敢瞒师父，适才孙悟空演变化耍子。教他变棵松树，果然是棵 松树，弟子们俱称扬喝采，故高声惊冒尊师，望乞恕罪。”祖师道:“你等起去。”叫:“悟空， 过来!我问你弄甚么精神，变甚么松树?这个工夫，可好在人前卖弄?假如你见别人有，不 要求他?别人见你有，必然求你。你若畏祸，却要传他;若不传他，必然加害:你之性命又 不可保。”悟空叩道:“只望师父恕罪!”祖师道:“我也不罪你，但只是你去吧。”悟空闻此言， 满眼堕泪道:“师父教我往那里去?”祖师道:“你从那里来，便从那里去就是了。”悟空顿然 醒悟道:“我自东胜神洲傲来国花果山水帘洞来的。”祖师道:“你快回去，全你性命，若在此 间，断然不可!”悟空领罪，“上告尊师，我也离家有二十年矣，虽是回顾旧日儿孙，但念师 父厚恩未报，不敢去。”祖师道:“那里甚么恩义?你只是不惹祸不牵带我就罢了!”悟空见没奈何，只得拜辞，与众相别。祖师道:“你这去，定生不良。凭你怎么惹祸行凶， 却不许说是我的徒弟。你说出半个字来，我就知之，把你这猢狲剥皮锉骨，将神魂贬在九幽 之处，教你万劫不得翻身!”悟空道:“决不敢提起师父一字，只说是我自家会的便罢。”…</p></blockquote><p>大众在此指的是须菩提祖师的弟子们(其中包括孙悟空)。孙悟空生来便有一番天赋，学东西很快，深得须菩提祖师喜爱，这一番天赋必与孙悟空其本就是天地日月精华所铸成有关。如上文亦知，孙悟空也是个有情有义，有血有肉之物。另外可在此收获到重要信息，孙悟空本身的能力其实是很有限的，他从一穷二白花费数年之久来此学道，他虽然得须菩提祖师喜爱私下传授了几功夫，但是从上可知他只是个“半路被出师”的学徒罢了，这些都能为以后他能力不足的体现做伏笔。<strong>孙悟空并不是有可以“无法无天”的本事的，而且孙悟空本身性格也不够“无法无天”，而是拘于温和有礼的类型，这点从我上面的解读可得知一二。</strong></p><h1 id="筋斗云的由来"><a href="#筋斗云的由来" class="headerlink" title="筋斗云的由来"></a>筋斗云的由来</h1><p>见下文第二章：</p><blockquote><p>…祖师道:“凡诸仙腾云，皆跌足而起，你却不是这般。我才见你去，连扯方才 跳上。我今只就你这个势，传你个‘筋斗云’罢。”悟空又礼拜恳求，祖师却又传个口诀道: “这朵云，捻着诀，念动真言，攒紧了拳，对身一抖，跳将起来，一筋斗就有十万八千里路哩!”大众听说，一个个嘻嘻笑道:“悟空造化!若会这个法儿，与人家当铺兵，送文书，递 报单，不管那里都寻了饭吃!”师徒们天昏各归洞府。这一夜，悟空即运神炼法，会了筋斗云。 逐日家无拘无束，自在逍遥此一长生之美。…</p></blockquote><p>从上可知，筋斗云是诸神仙的标配，其中可能就名字的叫法不同且配置各有不同而已(比如太白金星的叫做“祥云”，配置不及孙悟空的筋斗云快疾)，而且另外要说的是关于总是说的孙悟空一跟头十万八千里，其实也是跟筋斗云是有关系的，并不是单纯的以跟头就可以达到十万八千里路的。</p><p>“祥云”不及孙悟空的筋斗云快疾证据：</p><blockquote><p>…那太白金星与美猴王，同出了洞天深处，一齐驾云而起。原来悟空筋斗云比众不同，十 分快疾，把个金星撇在脑后，先至南天门外。…</p></blockquote><h1 id="孙悟空的大概真实样子"><a href="#孙悟空的大概真实样子" class="headerlink" title="孙悟空的大概真实样子"></a>孙悟空的大概真实样子</h1><p>孙悟空的大概样子以作者的描述为准。</p><p>见下文第一章：</p><blockquote><p>…<strong>石猴</strong>却又瞑目蹲身，往里一跳，叫道:“都随我进来!进来!”那些猴有胆大的，都跳进去了;胆小的，一个个伸头 缩颈，抓耳挠腮，大声叫喊，缠一会，也都进去了。跳过桥头，一个个抢盆夺碗，占灶争床， 搬过来，移过去，正是猴性顽劣，再无一个宁时，只搬得力倦神疲方止。<strong>石猿</strong>端坐上面道:…</p><p>…祖师闻言，咄的一声，跳下高台，手持戒尺，指定悟空道:“你这<strong>猢狲</strong>，这般不学，那般 不学，却待怎么?”走上前，将悟空头上打了三下，倒背着手，走入里面，将中门关了，撇 下大众而去。…</p><p>…悟空 道:“我也头圆顶天，足方履地，一般有九窍四肢，五脏六腑，何以比人不同?”祖师道:“你 虽然像人，却比人<strong>少腮</strong>。”原来那猴子<strong>孤拐面，凹脸尖嘴</strong>。…</p><p>…魔王 笑道:“我常闻得那些猴精说他有个大王，出家修行去，想是今番来了。你们见他怎生打扮， 有甚器械?”小妖道:“他也没甚么器械，<strong>光着个头</strong>，穿一领红色衣，勒一条黄绦，足下踏一 对乌靴，不僧不俗，又不像道士神仙，赤手空拳，在门外叫哩。”…</p><p>…魔王见了，笑道:“你<strong>身不满四尺</strong>，年不过 三旬，手内又无兵器，怎么大胆猖狂，要寻我见甚么上下?”悟空骂道:“你这泼魔，原来没 眼!你量我小，要大却也不难。你量我无兵器，我两只手勾着天边月哩!你不要怕，只吃老 孙一拳!”纵一纵，跳上去，劈脸就打。那魔王伸手架住道:“你这般矬矮，我这般高长，你 要使拳，我要使刀，使刀就杀了你，也吃人笑，待我放下刀，与你使路拳看。”…</p><p>…唬得那牛头鬼东躲西藏，马面鬼南奔北跑，众鬼卒奔上森罗殿，报着:“大王!祸 事!祸事!外面一个<strong>毛脸雷公</strong>，打将来了!”…</p><p>…身穿金甲亮堂堂，头戴金冠光映映。手举金箍棒一根，足踏云鞋皆相称。 <strong>一双怪眼似明星，两耳过肩查又硬</strong>。挺挺身才变化多，声音响亮如钟磬。 尖嘴咨牙弼马温，心高要做齐天圣。…</p></blockquote><p>以上的关键词我也已经标出来了，根据上方的关键词基本上能得出孙悟空的真实模样轮廓了，就不废言了。</p><h1 id="孙悟空为何一把毫毛可变许多个猴子出来？"><a href="#孙悟空为何一把毫毛可变许多个猴子出来？" class="headerlink" title="孙悟空为何一把毫毛可变许多个猴子出来？"></a>孙悟空为何一把毫毛可变许多个猴子出来？</h1><p>见下文第二章：</p><blockquote><p>…悟空见他凶猛， 即使身外身法，拔一把毫毛，丢在口中嚼碎，望空中喷去，叫一声“变!”，即变做三二百个 小猴，周围攒簇。原来人得仙体，出神变化，无方不知。这猴王自从了道之后，身上有八万四千毛羽，根根能变，应物随心。那些小猴，眼乖会跳，刀来砍不着，枪去不能伤。…</p><p>…好猴王，即拔一 把毫毛，入口嚼烂，喷将处去，念动咒语，叫声:“变!”变做千百个小猴，都乱搬乱抢…</p></blockquote><p>以上。孙悟空得道已成为仙体，有不死之身除外，还有其他的一些隐藏技能…毛变猴子不过是其中一角。</p><ul><li>孙悟空有不死之身的部分证据：</li></ul><blockquote><p>…悟空备细言了一遍，众猴称扬不尽道:“大王去到 那方，不意学得这般手段!”悟空又道:“我当年别汝等，随波逐流，飘过东洋大海，径至南 赡部洲，学成人像，着此衣，穿此履，摆摆摇摇，云游八九年馀，更不曾有道;又渡西洋大 海，到西牛贺洲地界，访问多时，幸遇一老祖，传了我与天同寿的真功果，<strong>不死长生</strong>的大法门。”众猴称贺。都道:“万劫难逢也!”…</p></blockquote><h1 id="孙悟空与二郎神谁更强？"><a href="#孙悟空与二郎神谁更强？" class="headerlink" title="孙悟空与二郎神谁更强？"></a>孙悟空与二郎神谁更强？</h1><p>在孙悟空<strong>“封做‘齐天大 圣’，先有官无禄。着他代管蟠桃园;他即偷桃;又走至瑶池，偷肴，偷酒，搅乱大会;仗酒 又暗入兜率宫，偷老君仙丹，反出天宫。玉帝复遣十万天兵，亦不能收伏。”**</strong>“后观世音举二郎 真君同他义兄弟追杀。”**</p><p>实际上是二郎神携自己的义兄弟大战孙悟空一人，但是他的义兄弟们虽然发挥的作用不大，但是多多少少也是对于两人的战斗是有一定影响的，不妨听我慢慢说来。</p><blockquote><p>…真君与大圣斗经三百馀合，不知胜负。那真君抖擞神威，摇身一变，变得身高万丈，两只手，举着三尖两刃神锋，好便似华山顶上之峰，青脸獠牙，朱红头发，恶狠狠，望大圣着头就砍。这大圣也使神通，变得与二郎身躯一样，嘴脸一般，举一条如意金箍棒，却就是昆仑顶上擎天之柱，抵住二郎神，唬得那马、流元帅，战兢兢，摇不得旌旗;崩、巴二将，虚怯怯，使不得刀剑。这阵上，康、张、姚、李、郭申、直健，传号令，撒放草头神，向他那水帘洞外，纵着鹰犬，搭弩张弓，一齐掩杀。可怜冲散妖猴四健将，捉拿灵怪二三千!那些猴，抛戈弃甲，撇剑抛枪;跑的跑，喊的喊;上山的上山，归洞的归洞;好似夜猫惊宿鸟，飞洒满天星。众兄弟得胜不题。却说真君与大圣变做法天象地的规模，正斗时，大圣忽见本营中妖猴惊散，自觉心慌， 收了法象，掣棒抽身就起。真君见他败走，大步赶上道:“那里走，趁早归降，饶你性命!” 大圣不恋战，只情跑起，将近洞口，正撞着康、张、姚、李四太尉，郭申、直健二将军，一 齐帅众挡住道:“泼猴!那里走!”大圣慌了手脚，就把金箍棒捏做绣花针，藏在耳内，摇身 一变，变作个麻雀儿，飞在树稍头钉住。那六兄弟，慌慌张张，前后寻觅不见，一齐吆喝道: “走了这猴精也!走了这猴精也!”…</p></blockquote><p>二郎神的义兄弟们在孙悟空与二郎神单挑时攻打孙悟空的“后宫”，导致孙悟空心态发生变化，战斗好似是孙悟空处于一种劣势了。实际上在单独与二郎神单挑时，孙悟空的实力并不比二郎神的实力差。有人可能会有疑问，说孙悟空的变化都被二郎神给看破了，这一点就能看出二郎神实力更胜一筹，非也非也，且看：</p><blockquote><p>…正嚷间，真君到了，问:“兄弟们，赶到那厢不见了?”众神道:“才在这里围住，就不 见了。”二郎圆睁凤眼观看，见大圣变了麻雀儿，钉在树上，就收了法象，撇了神锋，卸下弹 弓，摇身一变，变作个雀鹰儿，抖开翅，飞将去扑打。大圣见了，搜的一翅飞起，去变作一 只大鹚老，冲天而去。二郎见了，急抖翎毛，摇身一变，变作一只大海鹤，钻上云霄来衔。 大圣又将身按下，入涧中，变作一个鱼儿，淬入水内。二郎赶至涧边，不见踪迹。心中暗想 道:“这猢狲必然下水去也。定变作鱼虾之类。等我再变变拿他。”果一变变作个鱼鹰儿，飘 荡在下溜头波面上。等待片时，那大圣变鱼儿，顺水正游，忽见一只飞禽，似青鹞，毛片不 青;似鹭鸶，顶上无缨;似老鹳，腿又不红:“想是二郎变化了等我哩!⋯⋯”急转头，打个 花就走。二郎看见道:“打花的鱼儿，似鲤鱼，尾巴不红;似鳜鱼，花鳞不见;似黑鱼，头上 无星;似鲂鱼，腮上无针。他怎么见了我就回去了?必然是那猴变的。”赶上来，刷的啄一嘴。 那大圣就撺出水中，一变，变作一条水蛇，游近岸，钻入草中。二郎因衔他不着，他见水响 中，见一条蛇撺出去，认得是大圣，急转身，又变了一只朱绣顶的灰鹤，伸着一个长嘴，与 一把尖头铁钳子相似，径来吃这水蛇。水蛇跳一跳，又变做一只花鸨，木木樗樗的，立在蓼 汀之上。二郎见他变得低贱，——花鸨乃鸟中至贱至淫之物，不拘鸾、凤、鹰、鸦都与交群——故此不去拢傍，即现原身，走将去，取过弹弓拽满，一弹子把他打个〔足龙〕踵。那大圣趁着机会，滚下山崖，伏在那里又变，变一座土地庙儿;大张着口，似个庙门;牙齿变做门扇，舌头变做菩萨，眼睛变做窗棂。只有尾巴不好收拾，竖在后面，变做一根旗竿。真君赶到崖下，不见打倒的鸨鸟，只有一间小庙，急睁凤眼，仔细看之，见旗竿立在后面，笑道:“是这猢狲了!他今又在那里哄我。我也曾见庙宇，更不曾见一个旗竿竖在后面的。 断是这畜生弄谊!他若哄我进去，他便一口咬住。我怎肯进去?等我掣拳先捣窗棂，后踢门 扇!”大圣听得，心惊道:“好狠!好狠!门扇是我牙齿，窗棂是我眼睛;若打了牙，捣了眼， 却怎么是好?”扑的一个虎跳，又冒在空中不见。…</p></blockquote><p>综上分析，两者在这方面其实也是没个高下。</p><p>那么二郎神是如何拿下孙悟空，继而得到玉帝舅舅的奖赏的呢？不说那<strong>“李天王高擎照妖镜，与哪吒住立云端”</strong>相助之外，其实还有高人相助的(天兵天将在此仅是补下天罗地网之用，与分析实力基本上不挂钩，在此忽略不计)：</p><blockquote><p>…早有些天丁、力士接着，开门遥观，只见众天丁布罗 网，围住四面;李天王与哪吒，擎照妖镜，立在空中;真君把大圣围绕中间，纷纷赌斗呢。 菩萨开口对老君说:“贫僧所举二郎神如何?——果有神通，已把那大圣围困，只是未得擒拿。 我如今助他一功，决拿住他也。”老君道:“菩萨将甚兵器?怎能助他?”菩萨道:“我将那净 瓶杨柳抛下去，打那猴头;即不能打死，也打一跌，教二郎小圣，好去拿他。”老君道:“你 这瓶是个磁器，准打着他便好;如打不着他的头，或撞着他的铁棒，却不打碎了?你且莫动 手，等我老君助他一功。”菩萨道:“你有甚么兵器?”老君道:“有，有，有。”捋起衣袖， 左膊上，取下一个圈子，说道:“这件兵器，乃锟钢抟炼的，被我将还丹点成，养就一身灵气， 善能变化，水火不侵，又能套诸物;一名‘金钢琢’，又名‘金钢套’。当年过函关，化胡为 佛，甚是亏他。早晚最可防身。等我丢下去打他一下。”话毕，自天门上往下一掼，滴流流，径落花果山营盘里，可可的着猴王头上一下。猴王 只顾苦战七圣，却不知天上坠下这兵器，打中了天灵，立不稳脚，跌了一跤，爬将起来就跑; 被二郎爷爷的细犬赶上，照腿肚子上一口，又扯了一跌。他睡倒在地，骂道:“这个亡人!你 不去妨家长，却来咬老孙!”急翻身爬不起来，被七圣一拥按住，即将绳索捆绑，使勾刀穿了 琵琶骨，再不能变化。…</p></blockquote><p>以上分析来看，孙悟空的实力与二郎神相比较，两者估计是不相上下的，如果“极端“一点的话估计也是孙悟空更胜一筹，原因在上，不再多言。</p><h1 id="孙悟空闹天宫部分实情"><a href="#孙悟空闹天宫部分实情" class="headerlink" title="孙悟空闹天宫部分实情"></a>孙悟空闹天宫部分实情</h1><p>孙悟空并没有打入凌霄殿，更没有玉帝躲藏椅下一幕：</p><blockquote><p>…那二圣得了旨，径到灵山胜境，雷音宝刹之前，对四金刚、八菩萨礼毕，即烦转达。众 神随至宝莲台下启知，如来召请。二圣礼佛三匝，侍立台下。如来问:“玉帝何事，烦二圣下 凡?”二圣即启道:“向时花果山产一猴，在那里弄神通，聚众猴搅乱世界。玉帝降招安旨， 封为‘弼马温’，他嫌官小反去。当遣李天王、哪吒太子擒拿未获，复招安他，封做‘齐天大 圣’，先有官无禄。着他代管蟠桃园;他即偷桃;又走至瑶池，偷肴，偷酒，搅乱大会;仗酒 又暗入兜率宫，偷老君仙丹，反出天宫。玉帝复遣十万天兵，亦不能收伏。后观世音举二郎 真君同他义兄弟追杀，他变化多端，亏老君抛金钢琢打重，二郎方得拿住。解赴御前，即命 斩之。刀砍斧剁，火烧雷打，俱不能伤，老君准奏领去，以火煅炼。四十九日开鼎，他却又 跳出八卦炉，打退天丁，<strong>径入通明殿里，灵霄殿外;被佑圣真君的佐使王灵官挡住苦战，又 调三十六员雷将，把他困在垓心，终不能相近。事在紧急，因此，玉帝特请如来救驾。</strong>”如来 闻说，即对众菩萨道:“汝等在此稳坐法庭，休得乱了禅位，待我炼魔救驾去来。”…</p></blockquote><p>玉帝是传旨如来来救驾：</p><blockquote><p>…善时成佛与成仙，恶处披毛并带角。无穷变化闹天宫，雷将神兵不可捉。当时众神把大圣攒在一处，却不能近身，乱嚷乱斗，早惊动玉帝。遂传旨着游弈灵官同翊圣真君上西方请佛老降伏。…</p></blockquote><h1 id="五行山指哪五行？"><a href="#五行山指哪五行？" class="headerlink" title="五行山指哪五行？"></a>五行山指哪五行？</h1><p>见下文：</p><blockquote><p>…好大圣，急纵身又要跳出，被佛祖翻掌一扑，把这猴王推出西天门外，将五指化作金、 木、水、火、土五座联山，唤名“五行山”，轻轻的把他压住。众雷神与阿傩、迦叶，一个个 合掌称扬道:“善哉!善哉!…</p></blockquote><p>以上。</p><h1 id="最后，为何仅指明还原这些内容"><a href="#最后，为何仅指明还原这些内容" class="headerlink" title="最后，为何仅指明还原这些内容"></a>最后，为何仅指明还原这些内容</h1><p>因为很喜欢孙悟空这个角色，也比较喜欢“齐天大圣”那段恩怨情怀，所以仅在此还原这段剧情。再者因为这段剧情被人喜欢的也多，继而被人更改的也多，所以如今的“齐天大圣”好像真的是给大多数没看过原著的人“无法无天”、bug一般的存在，所以我认为有必要写下这篇文章以作指正、纠正，“普度众生”，哈哈。</p><p>仅此。</p><p>另外说一句，80年代拍的那部西游记的一系列曲目如今听起来真的是非常不错，这些曲目的原作者为许镜清老先生。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这次兴趣来了想读读西游原著，之前也读过一些金典原著，都是读过几章节便草草了事了…&lt;/p&gt;
&lt;p&gt;由于很喜欢孙悟空这个角色，所以才有心血来潮之意想认真读读，其中又惊又喜，发现了一个不同的孙悟空，各位对西游感兴趣的真应该好好读读呀。&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://pan.baidu.com/s/1ygYeZSm2jSIm7gJFPJjDvA&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;西游记原著下载链接&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;西游记乃是我等先辈所流传下来的文化宝藏，值得我等后辈花点时间精力来进行基本上的纠正解读，以此来”普度众生”，哈哈。&lt;/p&gt;
&lt;p&gt;所以，记下的这篇文章仅是起到普及有关西游知识之用。&lt;/p&gt;
    
    </summary>
    
      <category term="读西游" scheme="https://liujunjie11.github.io/categories/%E8%AF%BB%E8%A5%BF%E6%B8%B8/"/>
    
    
      <category term="读西游" scheme="https://liujunjie11.github.io/tags/%E8%AF%BB%E8%A5%BF%E6%B8%B8/"/>
    
  </entry>
  
  <entry>
    <title>在Macbook上玩PS/win本游戏</title>
    <link href="https://liujunjie11.github.io/2018/09/18/%E5%9C%A8Macbook%E4%B8%8A%E7%8E%A9PS-win%E6%9C%AC%E6%B8%B8%E6%88%8F/"/>
    <id>https://liujunjie11.github.io/2018/09/18/在Macbook上玩PS-win本游戏/</id>
    <published>2018-09-18T06:00:37.000Z</published>
    <updated>2018-10-11T12:49:29.985Z</updated>
    
    <content type="html"><![CDATA[<p>昨天想在电脑上玩玩<em>龙珠电光火石3</em>，这是一款我小时候经常喜欢玩的游戏呢，哈哈，甚是怀念～</p><p>话不多说，因为手上设备是<em>Macbook</em>，所以研究了一下，但是并不难，开始下面的教程吧。</p><a id="more"></a><h1 id="安装虚拟机"><a href="#安装虚拟机" class="headerlink" title="安装虚拟机"></a>安装虚拟机</h1><p>第一步当然是安装好我们的虚拟机了，这款虚拟机是微软开发的一款可以实现与<em>Macbook</em>文件共享的软件。什么叫文件共享？简单的说就是我们可以通过<em>Mac</em>上的下载软件下载好游戏以及模拟器之后直接打开<em>window虚拟机</em>则可以直接玩耍啦，因为文件是共享的！</p><p>这款要收费…所以不妨可参考哦我曾经的博文，里面有破解安装的链接：</p><blockquote><p><a href="https://liujunjie11.github.io/2018/04/17/关于Parallels-Desktop13的简单使用/">关于Parallels-Desktop13的简单使用</a></p></blockquote><p>这样虚拟机的问题就解决了～环境已经没问题啦，但是我还是要说明一下，这个虚拟机真的非常的强大啊～,我在玩游戏时没有一点点延迟，<strong>所以用这个来玩win本游戏又有何不可？当然分配内存大一点基本上是没什么问题的，所以用Macbook玩win本游戏就此也随便搞定了～</strong></p><h1 id="安装wii模拟器以及游戏"><a href="#安装wii模拟器以及游戏" class="headerlink" title="安装wii模拟器以及游戏"></a>安装wii模拟器以及游戏</h1><p>这里以安装<em>wii模拟器</em>以及<em>七龙珠电光火石3</em>游戏镜像为例。</p><p>直接参考这一篇吧，一路安装好就行了：</p><blockquote><p><a href="https://jingyan.baidu.com/article/3f16e00308e4482591c103df.html" target="_blank" rel="external">https://jingyan.baidu.com/article/3f16e00308e4482591c103df.html</a></p></blockquote><p><strong>补充一个快速下载龙珠电光火石3的迅雷链接(复制粘贴即可)：</strong></p><pre><code>ed2k://|file|%5B%E9%BE%99%E7%8F%A0Z.%E7%94%B5%E5%85%89%E7%81%AB%E7%9F%B33%5D.Dragon.Ball.Z.Sparking.Meteor.JPN.Wii.iso|4699979776|bdd5b903db318f4f20f9326ee0dbbb5f|h=mkxmrsue6bqztfa2dqm22324rzzobfss|/</code></pre><p><strong>如果链接失效了不妨可以留言我，我已经保存了，现在的这个链接还没有失效。</strong></p><h2 id="安装之后"><a href="#安装之后" class="headerlink" title="安装之后"></a>安装之后</h2><p>不知如何打开？请看此处的链接：<br><a href="https://tieba.baidu.com/p/3069784385?red_tag=0039514238" target="_blank" rel="external">https://tieba.baidu.com/p/3069784385?red_tag=0039514238</a></p><blockquote><p><strong>另外，我要补充一下，就是在初次打开时会出现错误‘Failed to load any D3DX9 dll, update your DX9 runtime, please’，解决方案在这里：<a href="https://www.microsoft.com/zh-cn/download/confirmation.aspx?id=35" target="_blank" rel="external">下载DirectX驱动</a></strong></p></blockquote><ul><li>在这里参考了：<a href="https://forums.dolphin-emu.org/Thread-dxd39-dll-loading-error" target="_blank" rel="external">https://forums.dolphin-emu.org/Thread-dxd39-dll-loading-error</a></li></ul><p>这样就能完成基本上的任务了，不过就是要用键盘来进行操作啊，很麻烦，不如看看<a href="http://pc.tgbus.com/xinshou_182/17365/" target="_blank" rel="external">这个手柄连接模拟器的教程吧</a>。</p><p>手柄设置补充，图一为设置手柄接入虚拟机，图二为虚拟机系统接入手柄，之后一一设置好按键对应即可：</p><p>图一：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-09-18%20%E4%B8%8B%E5%8D%886.16.38.png" alt=""></p><p>图二：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-09-18%20%E4%B8%8B%E5%8D%886.16.50.png" alt=""></p><p>这样就完成了所有的任务了，开始游戏吧～</p><h2 id="补充：手柄在wii模拟器上的按键设置。"><a href="#补充：手柄在wii模拟器上的按键设置。" class="headerlink" title="补充：手柄在wii模拟器上的按键设置。"></a>补充：手柄在wii模拟器上的按键设置。</h2><blockquote><p>可参考：</p></blockquote><ul><li><blockquote><p><a href="https://zhidao.baidu.com/question/1767290945679820540.html?qbl=relate_question_1" target="_blank" rel="external">https://zhidao.baidu.com/question/1767290945679820540.html?qbl=relate_question_1</a></p></blockquote></li><li><blockquote><p><a href="https://zhidao.baidu.com/question/1446133145568041260.html?qbl=relate_question_1" target="_blank" rel="external">https://zhidao.baidu.com/question/1446133145568041260.html?qbl=relate_question_1</a></p></blockquote></li></ul><h1 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h1><p>介绍几款小时候觉得很好玩的游戏：</p><ul><li><p><em>奥特曼进化格斗3</em>以及资源:<a href="https://tieba.baidu.com/p/3223685286?pn=13" target="_blank" rel="external">https://tieba.baidu.com/p/3223685286?pn=13</a></p></li><li><p><em>数码宝贝编年史</em>以及资源：<a href="https://tieba.baidu.com/p/1974490485" target="_blank" rel="external">https://tieba.baidu.com/p/1974490485</a></p></li></ul><p><em>龙珠电光火石3</em>教程参考：<a href="https://tieba.baidu.com/p/3069784385?red_tag=0039514238" target="_blank" rel="external">https://tieba.baidu.com/p/3069784385?red_tag=0039514238</a></p><p>上面的资源我均有备份，如果是失效了不妨可以留言补上。</p><p>以上。happy time~</p><p><strong>补充关于wii模拟器减速的问题：</strong></p><p>看下图进行适当设置即可：</p><p><img src="http://owudg3xs2.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-09-18%20%E4%B8%8B%E5%8D%886.40.13.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;昨天想在电脑上玩玩&lt;em&gt;龙珠电光火石3&lt;/em&gt;，这是一款我小时候经常喜欢玩的游戏呢，哈哈，甚是怀念～&lt;/p&gt;
&lt;p&gt;话不多说，因为手上设备是&lt;em&gt;Macbook&lt;/em&gt;，所以研究了一下，但是并不难，开始下面的教程吧。&lt;/p&gt;
    
    </summary>
    
      <category term="游戏教程" scheme="https://liujunjie11.github.io/categories/%E6%B8%B8%E6%88%8F%E6%95%99%E7%A8%8B/"/>
    
    
      <category term="游戏教程" scheme="https://liujunjie11.github.io/tags/%E6%B8%B8%E6%88%8F%E6%95%99%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>初学机器学习指南</title>
    <link href="https://liujunjie11.github.io/2018/09/16/%E5%88%9D%E5%AD%A6%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8D%97/"/>
    <id>https://liujunjie11.github.io/2018/09/16/初学机器学习指南/</id>
    <published>2018-09-16T02:06:47.000Z</published>
    <updated>2018-10-11T12:49:41.119Z</updated>
    
    <content type="html"><![CDATA[<p>老早就想写下这一篇文章了，对我来说这个意义很大。</p><p>以下是我开始真正学习机器学习的入门经历，在这个过程中我感到异常的轻松(在仅仅是了解学习机器学习知识的过程中)，为何说是“真正的”开始学习呢？因为之前有过接触但是进度很慢…我相信有许多的人在选择如何入门的时候肯定也有这样的麻烦。废话不多说，开始说说如何以我的方法尽快入门吧。希望以此来帮助需要的人。</p><a id="more"></a><ul><li><strong>入门：看书，看视频，记笔记，回顾思考。</strong></li></ul><blockquote><p>无非就是这样的套路。顺序不重要，但是在此间交叉切换的过程却很重要。你不可能在入门的过程中一直的保持看书或者是看视频，so,我的意思已经明了，明者自明，哈哈，但是学会记笔记的却是最重要的，这点我有亲身体验，相信你也是。</p></blockquote><h1 id="以kaggle为起点"><a href="#以kaggle为起点" class="headerlink" title="以kaggle为起点"></a>以kaggle为起点</h1><p>我开始学习机器学习是因为我想着入数据挖掘的坑，我对<em>kaggle</em>早已有过了解，我在掌握一点点的机器学习概念(没错，仅仅是概念)之后就奋不顾身的投入到了<em>kaggle</em>的一个入门级比赛当中去了。补充一下，在这之前我是有写过数据分析的一些小程序的…</p><p>这个实践的入门级比赛即是：<strong>Exploring Survival on the Titanic</strong>，经典的<em>泰坦尼克号预测</em>入门级比赛。</p><p>现在需要的即是查找一些文章来参考模仿并且投入实践，一切学习都是从模仿开始的，静下心来，一步步实践，遇到问题利用好搜索引擎。有相关的错误出现一般可以将错误信息复制粘贴到搜索引擎上，一般都会有答案出现(一般都是英语答案)。不要畏惧英语。</p><p>具体哪些文章可参考：</p><ul><li><p>1，R实现：<a href="https://zhuanlan.zhihu.com/p/27655949" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/27655949</a></p></li><li><p>2，python实现：<a href="https://zhuanlan.zhihu.com/p/33733586" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/33733586</a></p></li><li><p>3，python实现：<a href="http://www.jasongj.com/ml/classification/" target="_blank" rel="external">http://www.jasongj.com/ml/classification/</a></p></li><li><p>文章是参考不完的，但是还有一个重要的推荐，那就是<em>kaggle</em>本身的资源利用，即在每一个比赛都有<em>Kernel</em>资源分享，那是做过的前辈分享的经验，务必利用好。</p></li></ul><blockquote><p>在这个过程中，你可能想放弃，因为你什么都不懂..但是，你也要坚持下去，至少把流程是怎么一回事搞清楚。期间你可能会遇到编码问题，还有一些意外的错误问题，还是一句话，利用好搜索引擎。</p></blockquote><h1 id="工具选择"><a href="#工具选择" class="headerlink" title="工具选择"></a>工具选择</h1><ul><li><p><a href="https://www.anaconda.com/download/#macos" target="_blank" rel="external">Anaconda</a></p></li><li><p>Anaconda其中内嵌的notebook</p></li></ul><blockquote><p>非常不错，看起来很舒服，但是也有一些缺点，基本上可以忽略。notebook写python写R都是可以的，具体我有写过<a href="https://liujunjie11.github.io/2018/06/04/在Jupyter-Notebook中安装多种语言内核/#more">一篇文章介绍</a>。另外，出现的错误我也有相关的记录，自行根据需求查找。一句话说得好，一切发明都是根据需求产生的。</p></blockquote><h1 id="入门，机器学习理论"><a href="#入门，机器学习理论" class="headerlink" title="入门，机器学习理论"></a>入门，机器学习理论</h1><h2 id="视频"><a href="#视频" class="headerlink" title="视频"></a>视频</h2><ul><li><p>1，<a href="https://github.com/hahaahaha111/Coursera-ML-AndrewNg-Notes" target="_blank" rel="external">吴恩达机器学习</a></p></li><li><p>2，<a href="https://github.com/hahaahaha111/deeplearning_ai_books" target="_blank" rel="external">吴恩达深度学习</a></p></li></ul><blockquote><p>视频的话看这个基本上差不多做个了解，网易云课堂也可查到相关的视频。上面的链接里面有作者的笔记记录，可以看视频再来看一遍对应的笔记加深印象。记得做笔记。</p></blockquote><h2 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h2><ul><li><p>1，<a href="http://www.ai-start.com/ml2014/" target="_blank" rel="external">斯坦福大学2014机器学习教程中文笔记目录</a></p></li><li><p>2，<a href="http://www.ai-start.com/dl2017/" target="_blank" rel="external">深度学习笔记目录</a></p></li></ul><blockquote><p>以上链接为为上面说的笔记目录，再结合视频看是一个不错的选择，里面记录有每一节的核心内容，总结的不错。</p></blockquote><h2 id="书籍"><a href="#书籍" class="headerlink" title="书籍"></a>书籍</h2><ul><li><p>1，<a href="https://pan.baidu.com/s/1jmjuoAU_nCudDpD9YqeXXQ" target="_blank" rel="external">商务经济统计学</a></p></li><li><p>2，<a href="https://pan.baidu.com/s/1PZFRFbyfArmePnoNjlk7Vw" target="_blank" rel="external">周志华机器学习</a></p></li><li><p>3，<a href="https://pan.baidu.com/s/1dNLlg8uCRKl5E22D6XnlXw" target="_blank" rel="external">李航统计学习方法</a></p></li><li><p>4，<a href="https://pan.baidu.com/s/1gBqm7rnU6qjxgmevEOsirg" target="_blank" rel="external">数据挖掘概念与技术</a></p></li><li><p>5，备手数学书籍以便随时补充遗忘或者是不懂的相关的知识。</p></li></ul><blockquote><p>暂时记得这么多，届时补充。视频书籍交叉看最好，记得做笔记。现在的首要任务是搞清楚概念理论以及出现了一系列问题该如何使用选择。</p></blockquote><h1 id="项目实践"><a href="#项目实践" class="headerlink" title="项目实践"></a>项目实践</h1><p>自己找一些项目做做练手。最好是根据自身的需求，明者自明，话不多说。</p><h1 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h1><p>暂时说这么多吧，以后看时间看需要再进行补充。这是一篇简易的机器学习入门指南。</p><p><strong>补充：</strong>这个指南可能不适合你，因为我确确实实是有过一点点准备才开始的这个计划流程…</p><p>以上。共勉。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;老早就想写下这一篇文章了，对我来说这个意义很大。&lt;/p&gt;
&lt;p&gt;以下是我开始真正学习机器学习的入门经历，在这个过程中我感到异常的轻松(在仅仅是了解学习机器学习知识的过程中)，为何说是“真正的”开始学习呢？因为之前有过接触但是进度很慢…我相信有许多的人在选择如何入门的时候肯定也有这样的麻烦。废话不多说，开始说说如何以我的方法尽快入门吧。希望以此来帮助需要的人。&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>接受“大和”？</title>
    <link href="https://liujunjie11.github.io/2018/09/15/%E6%8E%A5%E5%8F%97%E2%80%9C%E5%A4%A7%E5%92%8C%E2%80%9D%EF%BC%9F/"/>
    <id>https://liujunjie11.github.io/2018/09/15/接受“大和”？/</id>
    <published>2018-09-15T02:02:29.000Z</published>
    <updated>2018-10-11T12:49:47.973Z</updated>
    
    <content type="html"><![CDATA[<p>不知不觉，自身的思想发生了一些变化，这种变化已维持好久了。</p><p>什么时候，曾经有些玩世不恭，对于什么事都“满腔热血”的我开始变得有些动摇了，开始变得接受这世界的“大同”思维了，我也因此而麻木了好许长的时间了。以“大同”思维来说服自己，让自己不再“焦虑”，这是我变化的根本啊。</p><p>今日忽地觉醒了，今日的我真的与从前的我在思维上有了很大的不同，在接受“大同”的抉择上我开始了质疑，是的，我承认因此我变得有些冷漠有些麻木了，我也因此付出了代价，变成了这世界千千万万麻木不仁者其中一员…我感到落寞。</p><a id="more"></a><p>我还记得这种思维是我在接触所谓哲学类书籍所产生的，开始以“世间普遍”来镇压着我的各种焦虑与猜疑直至今日此时此刻。由不堪变成了柔和甚至是一而再再而三的所谓的”理解“，我以为是我成长了，以为是我长大了…如今在此重新思考此类问题，我有些话想说。</p><p><strong>成长是变得越来越愿意接受这世间的“大同”，但若是把握的不好，却是会变成认同这种“大同”，这是两个完全不同的抉择。</strong>而曾经的我就陷入了后者之中。</p><p><strong>究竟是我选择认同了“大同”，还是“大同”说服了我？</strong>我想这两者均有在不同时期交叉出现过，我从此也慢慢变得落寞了…</p><p><strong>“大同”使我慢慢的愿意接受平庸！这是铁的事实，再者接受这世俗的说法，容易染上各种各样的颜色…我，终究还是太年轻了啊…</strong></p><p>有一段时间，我没有把本心守护好，这是我最大的过失，我也因此付出了巨大的代价。是“安乐”？是“平庸世俗”？说到底不过是我意志上的欠缺罢了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;不知不觉，自身的思想发生了一些变化，这种变化已维持好久了。&lt;/p&gt;
&lt;p&gt;什么时候，曾经有些玩世不恭，对于什么事都“满腔热血”的我开始变得有些动摇了，开始变得接受这世界的“大同”思维了，我也因此而麻木了好许长的时间了。以“大同”思维来说服自己，让自己不再“焦虑”，这是我变化的根本啊。&lt;/p&gt;
&lt;p&gt;今日忽地觉醒了，今日的我真的与从前的我在思维上有了很大的不同，在接受“大同”的抉择上我开始了质疑，是的，我承认因此我变得有些冷漠有些麻木了，我也因此付出了代价，变成了这世界千千万万麻木不仁者其中一员…我感到落寞。&lt;/p&gt;
    
    </summary>
    
      <category term="生活笔记" scheme="https://liujunjie11.github.io/categories/%E7%94%9F%E6%B4%BB%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="生活笔记" scheme="https://liujunjie11.github.io/tags/%E7%94%9F%E6%B4%BB%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>关于错误Error: Permission denied @ dir_s_mkdir - /usr/local/Frameworks</title>
    <link href="https://liujunjie11.github.io/2018/09/07/%E5%85%B3%E4%BA%8E%E9%94%99%E8%AF%AFError-Permission-denied-dir-s-mkdir-usr-local-Frameworks/"/>
    <id>https://liujunjie11.github.io/2018/09/07/关于错误Error-Permission-denied-dir-s-mkdir-usr-local-Frameworks/</id>
    <published>2018-09-07T00:49:53.000Z</published>
    <updated>2018-10-19T22:45:15.720Z</updated>
    
    <content type="html"><![CDATA[<p>最近在用<em>homebrew</em>下载东西遇到了如下错误：</p><blockquote><p>Error: Permission denied @ dir_s_mkdir - /usr/local/Frameworks</p></blockquote><a id="more"></a><p><strong>解决方案：</strong></p><p>依次使用命令行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo mkdir /usr/<span class="built_in">local</span>/Frameworks</div><div class="line"></div><div class="line">sudo chown $(whoami):admin /usr/<span class="built_in">local</span>/Frameworks</div></pre></td></tr></table></figure><p>这样重新使用之前的命令行即可正常行使了。</p><ul><li>参考：<a href="https://github.com/Homebrew/homebrew-core/issues/19286" target="_blank" rel="external">https://github.com/Homebrew/homebrew-core/issues/19286</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近在用&lt;em&gt;homebrew&lt;/em&gt;下载东西遇到了如下错误：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Error: Permission denied @ dir_s_mkdir - /usr/local/Frameworks&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="解决方案" scheme="https://liujunjie11.github.io/categories/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
    
    
      <category term="解决方案" scheme="https://liujunjie11.github.io/tags/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
    
  </entry>
  
</feed>
