<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>LXiHa`Notes</title>
  
  <subtitle>The House Belong to Love and Freedom.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://liujunjie11.github.io/"/>
  <updated>2018-11-15T02:25:11.765Z</updated>
  <id>https://liujunjie11.github.io/</id>
  
  <author>
    <name>刘俊</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>MySQL语句疑惑记录</title>
    <link href="https://liujunjie11.github.io/2018/11/15/MySQL%E8%AF%AD%E5%8F%A5%E7%96%91%E6%83%91%E8%AE%B0%E5%BD%95/"/>
    <id>https://liujunjie11.github.io/2018/11/15/MySQL语句疑惑记录/</id>
    <published>2018-11-15T01:53:00.000Z</published>
    <updated>2018-11-15T02:25:11.765Z</updated>
    
    <content type="html"><![CDATA[<p>主要是记录一些比较有疑惑的语句，方便以后的查找以及回忆。</p><a id="more"></a><h1 id="LIMIT子句"><a href="#LIMIT子句" class="headerlink" title="LIMIT子句"></a>LIMIT子句</h1><blockquote><p> <strong>主要参考：<a href="https://www.yiibai.com/mysql/limit.html" target="_blank" rel="external">https://www.yiibai.com/mysql/limit.html</a></strong></p></blockquote><p>LIMIT子句语法：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">SELECT </div><div class="line">    column1,column2,...</div><div class="line">FROM</div><div class="line">    table</div><div class="line">LIMIT offset , count;</div></pre></td></tr></table></figure><p>SQL我们来查看LIMIT子句参数：</p><p><code>offset</code>参数:指定要返回的第一行的偏移量。第一行的偏移量为0，而不是1。</p><p><code>count</code>:指定要返回的最大行数。</p><p>使用带有一个参数的LIMIT子句时，此参数将用于确定从结果集的开头返回的最大行数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">SELECT </div><div class="line">    column1,column2,...</div><div class="line">FROM</div><div class="line">    table</div><div class="line">LIMIT count;</div></pre></td></tr></table></figure><p>SQL上面的查询等同：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">SELECT </div><div class="line">    column1,column2,...</div><div class="line">FROM</div><div class="line">    table</div><div class="line">LIMIT 0 , count;</div></pre></td></tr></table></figure><h2 id="实例说明"><a href="#实例说明" class="headerlink" title="实例说明"></a>实例说明</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">mysql&gt; SELECT productCode, productName, buyprice</div><div class="line">FROM products</div><div class="line">ORDER BY buyprice DESC;</div><div class="line"></div><div class="line">+-------------+--------------------------------------+----------+</div><div class="line">| productCode | productName                          | buyprice |</div><div class="line">+-------------+--------------------------------------+----------+</div><div class="line">| S10_4962    | 1962 LanciaA Delta 16V               | 103.42   |</div><div class="line">| S18_2238    | 1998 Chrysler Plymouth Prowler       | 101.51   |</div><div class="line">| S10_1949    | 1952 Alpine Renault 1300             | 98.58    |</div><div class="line">| S24_3856    | 1956 Porsche 356A Coupe              | 98.3     |</div><div class="line">| S12_1108    | 2001 Ferrari Enzo                    | 95.59    |</div><div class="line">| S12_1099    | 1968 Ford Mustang                    | 95.34    |</div><div class="line">... ....</div><div class="line">+-------------+--------------------------------------+----------+</div><div class="line">110 rows in set</div></pre></td></tr></table></figure><p>默认语句为输出最前面的几行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">mysql&gt; SELECT customernumber, customername, creditlimit</div><div class="line">FROM customers</div><div class="line">ORDER BY creditlimit DESC</div><div class="line">LIMIT 5;</div><div class="line"></div><div class="line">相当于：</div><div class="line">mysql&gt; SELECT customernumber, customername, creditlimit</div><div class="line">FROM customers</div><div class="line">ORDER BY creditlimit DESC</div><div class="line">LIMIT 0, 5; #从第一个偏移量的指定开始向下输出指定行数的所有内容。</div><div class="line"></div><div class="line"></div><div class="line">+----------------+------------------------------+-------------+</div><div class="line">| customernumber | customername                 | creditlimit |</div><div class="line">+----------------+------------------------------+-------------+</div><div class="line">|            141 | Euro+ Shopping Channel       | 227600      |</div><div class="line">|            124 | Mini Gifts Distributors Ltd. | 210500      |</div><div class="line">|            298 | Vida Sport, Ltd              | 141300      |</div><div class="line">|            151 | Muscle Machine Inc           | 138500      |</div><div class="line">|            187 | AV Stores, Co.               | 136800      |</div><div class="line">+----------------+------------------------------+-------------+</div><div class="line">5 rows in set</div></pre></td></tr></table></figure><p>简要深入理解偏移量的作用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line">mysql&gt; SELECT productCode, productName, buyprice FROM  products</div><div class="line">ORDER BY buyprice DESC</div><div class="line">LIMIT 1, 1; #偏移量从0开始，所以要指定从1开始，然后取一行记录，以行数为1的指定仅输出一行对应的内容。</div><div class="line"></div><div class="line">+-------------+--------------------------------+----------+</div><div class="line">| productCode | productName                    | buyprice |</div><div class="line">+-------------+--------------------------------+----------+</div><div class="line">| S18_2238    | 1998 Chrysler Plymouth Prowler | 101.51   |</div><div class="line">+-------------+--------------------------------+----------+</div><div class="line">1 row in set</div><div class="line"></div><div class="line"></div><div class="line">#如下几个深入理解</div><div class="line">mysql&gt; SELECT productCode, productName, buyprice FROM  products</div><div class="line">ORDER BY buyprice DESC</div><div class="line">LIMIT 0, 1; #这时指定第一行(偏移量默认为第一行取0)</div><div class="line"></div><div class="line">+-------------+--------------------------------+----------+</div><div class="line">| productCode | productName                    | buyprice |</div><div class="line">+-------------+--------------------------------+----------+</div><div class="line">| S10_4962    | 1962 LanciaA Delta 16V | 103.42   |</div><div class="line">+-------------+--------------------------------+----------+</div><div class="line">1 row in set</div><div class="line"></div><div class="line"></div><div class="line">mysql&gt; SELECT productCode, productName, buyprice FROM  products</div><div class="line">ORDER BY buyprice DESC</div><div class="line">LIMIT 0, 2; #从已指定第一行偏移量开始输出以此为基础的指定行数的以下所有内容</div><div class="line"></div><div class="line">+-------------+--------------------------------------+----------+</div><div class="line">| productCode | productName                          | buyprice |</div><div class="line">+-------------+--------------------------------------+----------+</div><div class="line">| S10_4962    | 1962 LanciaA Delta 16V               | 103.42   |</div><div class="line">| S18_2238    | 1998 Chrysler Plymouth Prowler       | 101.51   |</div><div class="line">+----------------+------------------------------+-------------+</div><div class="line">2 rows in set</div></pre></td></tr></table></figure><blockquote><p>总结：<code>offset</code>就是相当于一个定位，<code>count</code>就是要返回指定的最大行数。</p></blockquote><h1 id="ORDER-BY-ASC-DESC"><a href="#ORDER-BY-ASC-DESC" class="headerlink" title="ORDER BY ASC/DESC"></a>ORDER BY ASC/DESC</h1><p><code>ASC</code>:[A~Z], [1~N]…</p><p><code>DESC</code>:[Z~A}, [N~1]…</p><blockquote><p>A，B，…Z。Z相当于最大的。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;主要是记录一些比较有疑惑的语句，方便以后的查找以及回忆。&lt;/p&gt;
    
    </summary>
    
      <category term="MySQL" scheme="https://liujunjie11.github.io/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="https://liujunjie11.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>MySQL学习资源与实践学习</title>
    <link href="https://liujunjie11.github.io/2018/11/13/MySQL%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%BA%90%E4%B8%8E%E5%AE%9E%E8%B7%B5%E5%AD%A6%E4%B9%A0/"/>
    <id>https://liujunjie11.github.io/2018/11/13/MySQL学习资源与实践学习/</id>
    <published>2018-11-13T13:12:31.000Z</published>
    <updated>2018-11-15T01:52:22.990Z</updated>
    
    <content type="html"><![CDATA[<p>最近心血来潮想写几个SQL玩玩，在此会分享学习的书籍资源以及YouTube教程使用语法的实践项目，以及会进行一系列的简单实践。这里通过在YouTube上的一个大佬的视频来进行在线的实践即可。</p><iframe width="560" height="315" src="https://www.youtube.com/embed/xYMhPZ_L3fI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><blockquote><p>就是这个视频。</p></blockquote><p>可主要参考书籍<a href="https://pan.baidu.com/s/15hIkCroy2w7RvBdVH8LRmA" target="_blank" rel="external">疯狂Java讲义(李刚)</a>来进行学习，当然还有参考其他的经典书籍以备用学习，这类书籍很多，就不在此一一说明了。</p><blockquote><p>《疯狂Java讲义》书籍的配套资源地址：<a href="https://github.com/DoingLee" target="_blank" rel="external">https://github.com/DoingLee</a></p></blockquote><a id="more"></a><h1 id="MySQL学习"><a href="#MySQL学习" class="headerlink" title="MySQL学习"></a>MySQL学习</h1><p>这一部分由于一些基础性的基本知识在上面和下面的书籍中已经是多如牛毛了，我就不重复说明了，需要的自行下载去了解吧。可结合书中直接开始语法的学习！实际上几个实用性强的语句就那么几个。</p><h2 id="书籍资源分享"><a href="#书籍资源分享" class="headerlink" title="书籍资源分享"></a>书籍资源分享</h2><ul><li><p><a href="https://pan.baidu.com/s/1rZwbEXEV_GlGsN7UVZ5Z6Q" target="_blank" rel="external">MySQL必知必会.pdf</a></p></li><li><p><a href="https://pan.baidu.com/s/1pA9V9weH33j7ZiV6fFNU1Q" target="_blank" rel="external">SQL语法查询(W3school).pdf</a></p></li><li><p><a href="https://pan.baidu.com/s/1cglHK9k4VY1SSJsg_C2mWA" target="_blank" rel="external">MySQL完全教程.pdf</a></p></li><li><p><a href="https://pan.baidu.com/s/14W7WJBoVnybd_r8pXQ6J4Q" target="_blank" rel="external">MySQL经典教程.pdf</a></p></li></ul><blockquote><p>就这么多吧，都是网上的人们分享出来的。</p></blockquote><h2 id="网页在线学习"><a href="#网页在线学习" class="headerlink" title="网页在线学习"></a>网页在线学习</h2><ul><li><a href="https://sqlbolt.com" target="_blank" rel="external">sqlbolt</a></li></ul><blockquote><p>强烈推荐！还可在线实践(结合上面的视频一起来即可)。</p></blockquote><ul><li><p><a href="http://www.runoob.com/mysql/mysql-tutorial.html" target="_blank" rel="external">MySQL教程(菜鸟教程)</a></p></li><li><p><a href="https://m.w3cschool.cn/mysql/" target="_blank" rel="external">MySQL教程(w3cschool)</a></p></li><li><p><a href="https://www.yiibai.com/mysql/" target="_blank" rel="external">MySQL教程(易百教程)</a></p></li></ul><blockquote><p>相较于上面的书籍，在线教程更加的通俗易懂，可先通过这些入门简单认识一下以及学习语法，不懂的更深的部分可查看书籍即可。</p></blockquote><h2 id="YouTube上的资源"><a href="#YouTube上的资源" class="headerlink" title="YouTube上的资源"></a>YouTube上的资源</h2><ul><li><a href="https://www.youtube.com/results?search_query=mysql" target="_blank" rel="external">https://www.youtube.com/results?search_query=mysql</a></li></ul><blockquote><p>就这么简单～</p></blockquote><h1 id="实践学习"><a href="#实践学习" class="headerlink" title="实践学习"></a>实践学习</h1><p>强烈建议先根据视频学习！根据上面的YouTube教程结合<a href="https://sqlbolt.com" target="_blank" rel="external">sqlbolt</a>网站一步步来即可～若是英文看不懂，可结合上面的书籍资源以及在线资源查询即可。实践才是掌握一门语言的最快方法！</p><blockquote><p>有时根据网速快慢加载的数据库可能有点慢，等待一下即可。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近心血来潮想写几个SQL玩玩，在此会分享学习的书籍资源以及YouTube教程使用语法的实践项目，以及会进行一系列的简单实践。这里通过在YouTube上的一个大佬的视频来进行在线的实践即可。&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/xYMhPZ_L3fI&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;blockquote&gt;
&lt;p&gt;就是这个视频。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;可主要参考书籍&lt;a href=&quot;https://pan.baidu.com/s/15hIkCroy2w7RvBdVH8LRmA&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;疯狂Java讲义(李刚)&lt;/a&gt;来进行学习，当然还有参考其他的经典书籍以备用学习，这类书籍很多，就不在此一一说明了。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;《疯狂Java讲义》书籍的配套资源地址：&lt;a href=&quot;https://github.com/DoingLee&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/DoingLee&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="MySQL" scheme="https://liujunjie11.github.io/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="https://liujunjie11.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>学习计算机组成、计算机系统资源分享</title>
    <link href="https://liujunjie11.github.io/2018/11/13/%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E3%80%81%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E8%B5%84%E6%BA%90%E5%88%86%E4%BA%AB/"/>
    <id>https://liujunjie11.github.io/2018/11/13/学习计算机组成、计算机系统资源分享/</id>
    <published>2018-11-13T08:32:42.000Z</published>
    <updated>2018-11-13T13:04:27.626Z</updated>
    
    <content type="html"><![CDATA[<p>一直想写一些关于计算机的基础知识的，但是我又看到许多的优秀书籍以及优秀文章，我从其中也学习到了非常的东西，也解开了我的许多疑惑，在此感谢那些人们的付出～</p><p>回到正题，自己一直想写，但是由于时间问题以及质量不能保证…所以我打算将一些优秀的资源拿出来分享好了，也解决了自己的那块心头肉。</p><p>以下资源是我从网上收集到的，仅用于学习使用。</p><a id="more"></a><h1 id="云盘资源分享"><a href="#云盘资源分享" class="headerlink" title="云盘资源分享"></a>云盘资源分享</h1><ul><li><a href="https://pan.baidu.com/s/1Z9BcwV3fKGqwVXlLfU8B_g" target="_blank" rel="external">深入理解计算机系统（原书第三版）.pdf</a></li></ul><blockquote><p>一本非常好的书！！</p></blockquote><ul><li><p><a href="https://pan.baidu.com/s/1JIC9vxu1CnKgqBnfgrfEAw" target="_blank" rel="external">计算机组成.pdf</a></p></li><li><p><a href="https://pan.baidu.com/s/1LI2Cc9dFgAgBro_Tn7uKUA" target="_blank" rel="external">计算机操作系统（第3版）_汤小丹.pdf</a></p></li><li><p><a href="https://pan.baidu.com/s/1li3YCywQlfEMtRCkRdS1tQ" target="_blank" rel="external">计算机是怎么跑起来的.pdf</a></p></li></ul><blockquote><p>一本科普书吧，很简单，但是够用了。</p></blockquote><ul><li><p><a href="https://pan.baidu.com/s/1uDVuroObwbvuqlZWokE3dg" target="_blank" rel="external">计算机组成.pdf</a></p></li><li><p><a href="https://pan.baidu.com/s/1ix393Of_pPVnvAQZEdZumw" target="_blank" rel="external">Linux设备驱动程序(中文版第三版).pdf</a></p></li><li><p><a href="https://pan.baidu.com/s/1N6Y7faTYkmU7gyaXUv9YqA" target="_blank" rel="external">Linux内核完全注释.pdf</a></p></li><li><p><a href="https://pan.baidu.com/s/1jvuMLTCtrmytamVYtR2G7A" target="_blank" rel="external">深入Linux内核架构.pdf</a></p></li></ul><blockquote><p>以上都是网上收集的电子书，我个人平时喜欢看书，基本上都是电子书，有收集很多技术类的电子书，都是根据需求来收集的。</p></blockquote><h1 id="最近看到的相关的优秀文章"><a href="#最近看到的相关的优秀文章" class="headerlink" title="最近看到的相关的优秀文章"></a>最近看到的相关的优秀文章</h1><ul><li><p><a href="https://juejin.im/post/5b3c34e3e51d45190e34c680" target="_blank" rel="external">印象系列-理解进程的存在</a></p></li><li><p><a href="https://juejin.im/post/59eaf70ff265da432b49f6bc" target="_blank" rel="external">印象系列-磁盘和内存的基本认识</a></p></li><li><p><a href="https://juejin.im/post/59be20e6f265da06633d1648" target="_blank" rel="external">印象系列-linux内核启动过程</a></p></li><li><p><a href="https://juejin.im/post/5b4f710be51d45195c073912" target="_blank" rel="external">从I/O到索引的那些事</a></p></li></ul><blockquote><p>以上都是一个作者写的，最近在学习<code>MySQL</code>时无意中看到的，很好的文章。</p></blockquote><p>还是要多看书学习才行。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一直想写一些关于计算机的基础知识的，但是我又看到许多的优秀书籍以及优秀文章，我从其中也学习到了非常的东西，也解开了我的许多疑惑，在此感谢那些人们的付出～&lt;/p&gt;
&lt;p&gt;回到正题，自己一直想写，但是由于时间问题以及质量不能保证…所以我打算将一些优秀的资源拿出来分享好了，也解决了自己的那块心头肉。&lt;/p&gt;
&lt;p&gt;以下资源是我从网上收集到的，仅用于学习使用。&lt;/p&gt;
    
    </summary>
    
      <category term="资源分享" scheme="https://liujunjie11.github.io/categories/%E8%B5%84%E6%BA%90%E5%88%86%E4%BA%AB/"/>
    
      <category term="计算机基础" scheme="https://liujunjie11.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="资源分享" scheme="https://liujunjie11.github.io/tags/%E8%B5%84%E6%BA%90%E5%88%86%E4%BA%AB/"/>
    
      <category term="计算机基础" scheme="https://liujunjie11.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>Hexo博客图片外链从七牛云移至腾讯云</title>
    <link href="https://liujunjie11.github.io/2018/11/11/Hexo%E5%8D%9A%E5%AE%A2%E5%9B%BE%E7%89%87%E5%A4%96%E9%93%BE%E4%BB%8E%E4%B8%83%E7%89%9B%E4%BA%91%E7%A7%BB%E8%87%B3%E8%85%BE%E8%AE%AF%E4%BA%91/"/>
    <id>https://liujunjie11.github.io/2018/11/11/Hexo博客图片外链从七牛云移至腾讯云/</id>
    <published>2018-11-11T10:30:01.000Z</published>
    <updated>2018-11-13T12:30:55.902Z</updated>
    
    <content type="html"><![CDATA[<p>最近发现博客中的一些文章图片无法正常显示了，查看了一些文章之后，发现原来是测试域名失效了…我的图片存放了这么多…全都不能用了，妈蛋啊！</p><p>我研究了一下关于它的这个恢复的方法，需要实名不说了，还要我的网站备案，不可能的绝对不可能的，我要走了，再见了，七牛云！！</p><p>我要搬去腾讯云了。以下是我的记录。</p><a id="more"></a><h1 id="将七牛云的图片下载至本地"><a href="#将七牛云的图片下载至本地" class="headerlink" title="将七牛云的图片下载至本地"></a>将七牛云的图片下载至本地</h1><h2 id="过程操作"><a href="#过程操作" class="headerlink" title="过程操作"></a>过程操作</h2><p>具体需要用到<a href="https://developer.qiniu.com/kodo/tools/1302/qshell" target="_blank" rel="external">七牛云命令行工具(qshell)</a>，将曾经上传上去的图片批量下载到本地然后使用腾讯云再次慢慢整理即可…</p><ul><li>可参考官方介绍：<a href="http://songfeifeids.qiniuts.com/spjc/avthumb/batchdelete.mov.mp4" target="_blank" rel="external">使用 qshell 进行批量删除</a></li></ul><blockquote><p>由于我在七牛云上的图片有一部分可以显示，一部分无法显示，但是这个量真的太大了，我不打算一个一个替换了，之后的图片我就直接用腾讯云来充当图床好了…唉…心累。</p></blockquote><h1 id="关于在腾讯云的图床操作"><a href="#关于在腾讯云的图床操作" class="headerlink" title="关于在腾讯云的图床操作"></a>关于在腾讯云的图床操作</h1><p>可参考：</p><ul><li><a href="https://blog.csdn.net/a201577F0546/article/details/80146350" target="_blank" rel="external">使用腾讯云对象存储作为图床</a></li></ul><h1 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h1><p>我通过一个兄弟买了一个已备案的域名，在<a href="https://developer.qiniu.com/fusion/kb/1322/how-to-configure-cname-domain-name" target="_blank" rel="external">这里</a>跟着设置了一下，就OK了，接下来我需要将以前的在文件中域名更改为现在的就行了，图片就能正常显示出来了。为了更有效率的处理可以自己写个脚本或者是利用好一些编译软件替换掉域名即可：</p><p><img src="http://smartjpa.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-11-12%20%E4%B8%8B%E5%8D%886.57.30.png" alt=""></p><blockquote><p>我用的<em>Macdown</em>编译软件，平时用这个来写博客的。</p></blockquote><p>另外可以用公用的图床(以下为推荐的参考链接)：</p><ul><li><p><a href="https://sspai.com/post/40499" target="_blank" rel="external">https://sspai.com/post/40499</a></p></li><li><p><a href="https://blog.nfz.moe/archives/collection-of-image-hosting.html" target="_blank" rel="external">https://blog.nfz.moe/archives/collection-of-image-hosting.html</a></p></li></ul><blockquote><p>不过为了稳定，我是真的不想从来一遍了…文件太多了。所以我买了个备案的域名。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近发现博客中的一些文章图片无法正常显示了，查看了一些文章之后，发现原来是测试域名失效了…我的图片存放了这么多…全都不能用了，妈蛋啊！&lt;/p&gt;
&lt;p&gt;我研究了一下关于它的这个恢复的方法，需要实名不说了，还要我的网站备案，不可能的绝对不可能的，我要走了，再见了，七牛云！！&lt;/p&gt;
&lt;p&gt;我要搬去腾讯云了。以下是我的记录。&lt;/p&gt;
    
    </summary>
    
      <category term="笔记" scheme="https://liujunjie11.github.io/categories/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="Hexo" scheme="https://liujunjie11.github.io/categories/Hexo/"/>
    
    
      <category term="教程笔记" scheme="https://liujunjie11.github.io/tags/%E6%95%99%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
      <category term="Hexo" scheme="https://liujunjie11.github.io/tags/Hexo/"/>
    
      <category term="七牛云" scheme="https://liujunjie11.github.io/tags/%E4%B8%83%E7%89%9B%E4%BA%91/"/>
    
      <category term="腾讯云" scheme="https://liujunjie11.github.io/tags/%E8%85%BE%E8%AE%AF%E4%BA%91/"/>
    
  </entry>
  
  <entry>
    <title>（Mac）Julia的下载及结合notebook使用</title>
    <link href="https://liujunjie11.github.io/2018/11/09/%EF%BC%88Mac%EF%BC%89Julia%E7%9A%84%E4%B8%8B%E8%BD%BD%E5%8F%8A%E7%BB%93%E5%90%88notebook%E4%BD%BF%E7%94%A8/"/>
    <id>https://liujunjie11.github.io/2018/11/09/（Mac）Julia的下载及结合notebook使用/</id>
    <published>2018-11-09T06:50:59.000Z</published>
    <updated>2018-11-13T12:31:07.561Z</updated>
    
    <content type="html"><![CDATA[<p>关于Julia这个语言，这是一个鲜为人知的语言，听说在处理数值分析方面还不错，最近也总是无意间看到，所以想试试看看，就在此顺便记录一下安装的过程以及如何在notebook中运行的过程。</p><a id="more"></a><h1 id="安装Julia"><a href="#安装Julia" class="headerlink" title="安装Julia"></a>安装Julia</h1><ul><li>在这里下载：<a href="https://julialang.org/downloads/" target="_blank" rel="external">https://julialang.org/downloads/</a></li></ul><p>或者是在<code>Mac</code>上可用<code>homebrew</code>命令行:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">brew cask install julia</div></pre></td></tr></table></figure><blockquote><p>可参考：<a href="https://julialang.org/downloads/platform.html#macos" target="_blank" rel="external">https://julialang.org/downloads/platform.html#macos</a></p></blockquote><p>我使用直接下载安装的方式。</p><h2 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">vi ~/.bash_profile <span class="comment">#打开配置文件</span></div><div class="line"></div><div class="line"><span class="comment">#输入对应目录</span></div><div class="line"><span class="comment">#Julia</span></div><div class="line"><span class="built_in">export</span> PATH=<span class="string">"/Applications/Julia-1.0.app/Contents/Resources/julia/bin:<span class="variable">$&#123;PATH&#125;</span>"</span></div><div class="line"></div><div class="line"><span class="built_in">source</span> ~/.bash_profile <span class="comment">#快速生效</span></div></pre></td></tr></table></figure><p>这样之后在终端直接输入<code>Julia</code>即可使用Julia了。</p><h1 id="notebook中运行"><a href="#notebook中运行" class="headerlink" title="notebook中运行"></a>notebook中运行</h1><p>下载相关的内核就OK了。</p><p>打开Julia终端进程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">using Pkg</div><div class="line">Pkg.add(<span class="string">"IJulia"</span>)</div></pre></td></tr></table></figure><blockquote><p>重启notebook，发现可以了。</p></blockquote><p>可参考：</p><ul><li><p><a href="https://github.com/JuliaLang/IJulia.jl" target="_blank" rel="external">https://github.com/JuliaLang/IJulia.jl</a></p></li><li><p><a href="https://www.youtube.com/watch?v=uRIQXJXRtqg" target="_blank" rel="external">https://www.youtube.com/watch?v=uRIQXJXRtqg</a></p></li></ul><h1 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h1><p>附上几个学习链接：</p><ul><li><a href="https://zhuanlan.zhihu.com/p/41802723" target="_blank" rel="external">一个简单的Julia教程（一）</a></li></ul><blockquote><p>这篇文章有介绍用其他运行<code>Julia</code>的方案。</p></blockquote><ul><li><p><a href="http://discourse.juliacn.com" target="_blank" rel="external">Julia中文discourse</a></p></li><li><p><a href="https://www.zhihu.com/question/284356534" target="_blank" rel="external">Julia 解决了 C++/Python/Matlab 的哪些痛点？</a></p></li><li><p><a href="https://www.zhihu.com/question/20072632" target="_blank" rel="external">怎么看待新出的 Julia 语言？它的前景怎么样？</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;关于Julia这个语言，这是一个鲜为人知的语言，听说在处理数值分析方面还不错，最近也总是无意间看到，所以想试试看看，就在此顺便记录一下安装的过程以及如何在notebook中运行的过程。&lt;/p&gt;
    
    </summary>
    
      <category term="软件使用" scheme="https://liujunjie11.github.io/categories/%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/"/>
    
      <category term="Julia" scheme="https://liujunjie11.github.io/categories/Julia/"/>
    
    
      <category term="Jupyter Notebook" scheme="https://liujunjie11.github.io/tags/Jupyter-Notebook/"/>
    
      <category term="Julia" scheme="https://liujunjie11.github.io/tags/Julia/"/>
    
  </entry>
  
  <entry>
    <title>Python结合OCR以及Opencv提取并且实时翻译图片内容</title>
    <link href="https://liujunjie11.github.io/2018/11/08/Python%E7%BB%93%E5%90%88OCR%E4%BB%A5%E5%8F%8AOpencv%E6%8F%90%E5%8F%96%E5%B9%B6%E4%B8%94%E5%AE%9E%E6%97%B6%E7%BF%BB%E8%AF%91%E5%9B%BE%E7%89%87%E5%86%85%E5%AE%B9/"/>
    <id>https://liujunjie11.github.io/2018/11/08/Python结合OCR以及Opencv提取并且实时翻译图片内容/</id>
    <published>2018-11-08T04:09:42.000Z</published>
    <updated>2018-11-13T12:31:21.205Z</updated>
    
    <content type="html"><![CDATA[<p>本文讲述基于python的一些模块进行<code>图片内容的提取</code>、<code>图片内容的翻译</code>。本文主要进行记录一些在实践中的构想以及遇到的问题，并且记录上一些实现的代码，因为技术含量实在是不怎么高的，不过若是自己玩玩，参加那种水比赛也许能获得个不错的名次，或者是应付个学生报告什么的…</p><p>由于时间关系，本文多数只是起到一个构想记录的效用。</p><a id="more"></a><h1 id="基于OCR的图片内容提取"><a href="#基于OCR的图片内容提取" class="headerlink" title="基于OCR的图片内容提取"></a>基于OCR的图片内容提取</h1><p>在python使用到的模块是<code>pytesseract</code>，关于简要的下载介绍什么的可见：<a href="https://zhuanlan.zhihu.com/p/31530755" target="_blank" rel="external">Python–文字识别–Tesseract</a>。</p><p>运行代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pytesseract</div><div class="line"><span class="keyword">import</span> cv2</div><div class="line"></div><div class="line">image = cv2.imread(<span class="string">'/Users/junjieliu/Desktop/1.png'</span>)</div><div class="line">text = pytesseract.image_to_string(image)</div><div class="line">print(text)</div></pre></td></tr></table></figure><p>在此记录一下在使用过程中的出现的问题：</p><h2 id="问题一："><a href="#问题一：" class="headerlink" title="问题一："></a>问题一：</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Error: [Errno 2] No such file or directory using pytesser</div></pre></td></tr></table></figure><blockquote><p>之后我参考了：<a href="https://stackoverflow.com/questions/35609773/oserror-errno-2-no-such-file-or-directory-using-pytesser" target="_blank" rel="external">https://stackoverflow.com/questions/35609773/oserror-errno-2-no-such-file-or-directory-using-pytesser</a></p></blockquote><p>我使用了其中的前面的几个答案的方案，结果出现了下面的错误…</p><h2 id="问题二："><a href="#问题二：" class="headerlink" title="问题二："></a>问题二：</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">PermissionError: [Errno 13] Permission denied</div></pre></td></tr></table></figure><blockquote><p>之后我参考了：<a href="https://github.com/madmaze/pytesseract/issues/62" target="_blank" rel="external">https://github.com/madmaze/pytesseract/issues/62</a></p></blockquote><p>但是依旧得不到解决。</p><h2 id="解决方案："><a href="#解决方案：" class="headerlink" title="解决方案："></a>解决方案：</h2><p>使用命令行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">which</span> tesseract</div></pre></td></tr></table></figure><p>找到了它的位置（没想到Mac自带的一个？）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/usr/<span class="built_in">local</span>/bin/tesseract</div></pre></td></tr></table></figure><p>然后虽然在替换了地址之后可以正常运行代码了(即<code>tesseract_cmd = “/usr/local/bin/tesseract”</code>)，就会变得很麻烦，因为自带的根本难以进行扩展。</p><p>将下载好的加入环境变量替换掉原装的：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vi ~/.bash_profile</div></pre></td></tr></table></figure><p>写入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#tesseract</span></div><div class="line">export PATH=<span class="string">"/usr/local/Cellar/tesseract/4.0.0/bin:$PATH"</span></div></pre></td></tr></table></figure><p>立即生效：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">source</span> ~/.bash_profile</div></pre></td></tr></table></figure><p>之后再使用命令行<code>which tesseract</code>,就会发现变了位置，更改<code>tesseract_cmd = “/usr/local/Cellar/tesseract/4.0.0/bin/tesseract”</code>，之后程序就能成功运行并且可以得到以后的更多的扩展使用了，比如语言包的选择。</p><h1 id="在线提取图片文字小工具"><a href="#在线提取图片文字小工具" class="headerlink" title="在线提取图片文字小工具"></a>在线提取图片文字小工具</h1><p>提取这一块的具体过程就不多说了，简单记录一下结合其他技术可以实现的想法：</p><blockquote><p>可结合<code>Pyqt5</code>的GUI界面化开发，输入图片的目录地址，下方即出现提取的内容。</p><p>在以上的基础上结合爬虫实现翻译。</p></blockquote><p><strong>可参考我以前写的文章：<a href="https://liujunworld.com/2018/05/07/python3爬虫与GUI-基于有道词典的词典小工具/" target="_blank" rel="external">python3爬虫与GUI-基于有道词典的词典小工具</a></strong></p><p>这样一来这个小工具就能出来了。这里就这样吧，因为时间关系加上实现的过程不是很难，所以就不多说了。</p><ul><li>关于提取的精确度可移步参考更强大的工具：<a href="https://github.com/JinpengLI/deep_ocr" target="_blank" rel="external">deep_ocr</a></li></ul><h1 id="结合OpenCV实时翻译"><a href="#结合OpenCV实时翻译" class="headerlink" title="结合OpenCV实时翻译"></a>结合OpenCV实时翻译</h1><p>这里主要是我在参考了：<a href="https://zhuanlan.zhihu.com/p/40025902" target="_blank" rel="external">用OpenCV和Python识别二维码和条形码</a>这篇文章之后结合本身的需求出现的启发。</p><p>这是我经过修改之后的代码（添加并且修改了几行代码）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> imutils.video <span class="keyword">import</span> VideoStream</div><div class="line"><span class="keyword">from</span> pyzbar <span class="keyword">import</span> pyzbar</div><div class="line"><span class="keyword">import</span> datetime</div><div class="line"><span class="keyword">import</span> imutils</div><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">import</span> cv2</div><div class="line"></div><div class="line">cap = cv2.VideoCapture(<span class="number">0</span>)</div><div class="line">vs = VideoStream(src=<span class="number">0</span>).start()</div><div class="line">time.sleep(<span class="number">2.0</span>)</div><div class="line"></div><div class="line"><span class="comment"># open the output CSV file for writing and initialize the set of</span></div><div class="line"><span class="comment"># barcodes found thus far</span></div><div class="line">csv = open(<span class="string">"barcodes.csv"</span>, <span class="string">"w"</span>)</div><div class="line">found = set()</div><div class="line"></div><div class="line"><span class="comment"># loop over the frames from the video stream</span></div><div class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">    <span class="comment"># grab the frame from the threaded video stream and resize it to</span></div><div class="line">    <span class="comment"># have a maximum width of 400 pixels</span></div><div class="line">    frame = vs.read()</div><div class="line">    frame = imutils.resize(frame, width=<span class="number">400</span>)</div><div class="line"></div><div class="line">    <span class="comment"># find the barcodes in the frame and decode each of the barcodes</span></div><div class="line">    barcodes = pyzbar.decode(frame)</div><div class="line"></div><div class="line">    <span class="comment"># loop over the detected barcodes</span></div><div class="line">    <span class="keyword">for</span> barcode <span class="keyword">in</span> barcodes:</div><div class="line">        <span class="comment"># extract the bounding box location of the barcode and draw</span></div><div class="line">        <span class="comment"># the bounding box surrounding the barcode on the image</span></div><div class="line">        (x, y, w, h) = barcode.rect</div><div class="line">        cv2.rectangle(frame, (x, y), (x + w, y + h), (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)</div><div class="line"></div><div class="line">        <span class="comment"># the barcode data is a bytes object so if we want to draw it</span></div><div class="line">        <span class="comment"># on our output image we need to convert it to a string first</span></div><div class="line">        barcodeData = barcode.data.decode(<span class="string">"utf-8"</span>)</div><div class="line">        barcodeType = barcode.type</div><div class="line"></div><div class="line">        <span class="comment"># draw the barcode data and barcode type on the image</span></div><div class="line">        text = <span class="string">"&#123;&#125; (&#123;&#125;)"</span>.format(barcodeData, barcodeType)</div><div class="line">        cv2.putText(frame, text, (x, y - <span class="number">10</span>),</div><div class="line">            cv2.FONT_HERSHEY_SIMPLEX, <span class="number">0.5</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)</div><div class="line"></div><div class="line">        <span class="comment"># if the barcode text is currently not in our CSV file, write</span></div><div class="line">        <span class="comment"># the timestamp + barcode qto disk and update the set</span></div><div class="line">        <span class="keyword">if</span> barcodeData <span class="keyword">not</span> <span class="keyword">in</span> found:</div><div class="line">            csv.write(<span class="string">"&#123;&#125;,&#123;&#125;\n"</span>.format(datetime.datetime.now(),</div><div class="line">                barcodeData))</div><div class="line">            csv.flush()</div><div class="line">            found.add(barcodeData)</div><div class="line"></div><div class="line">    <span class="comment"># show the output frame</span></div><div class="line">    cv2.imshow(<span class="string">"Barcode Scanner"</span>, frame)</div><div class="line">    key = cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span></div><div class="line"> </div><div class="line">    <span class="comment"># if the `q` key was pressed, break from the loop</span></div><div class="line">    <span class="keyword">if</span> key == ord(<span class="string">"q"</span>):</div><div class="line">        <span class="keyword">break</span></div><div class="line"></div><div class="line"><span class="comment"># close the output CSV file do a bit of cleanup</span></div><div class="line">print(<span class="string">"[INFO] cleaning up..."</span>)</div><div class="line">cap.release()  <span class="comment"># 释放摄像头</span></div><div class="line">csv.close()</div><div class="line">cv2.destroyAllWindows()</div><div class="line">vs.stop()</div></pre></td></tr></table></figure><blockquote><p>性能得到了一点的优化，少写了点代码。效果没变化。</p></blockquote><p>关于实现实时翻译的效果，这里可结合上面的有道爬虫与OpenCV来完成。基本上进行一些修改就行了，实现的过程不算太难。多参考官方文档以及他人的做法即能实现。</p><p>大概的代码样本：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># coding:utf-8</span></div><div class="line"></div><div class="line"><span class="keyword">from</span> imutils.video <span class="keyword">import</span> VideoStream</div><div class="line"><span class="keyword">import</span> datetime</div><div class="line"><span class="keyword">import</span> imutils</div><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">import</span> cv2</div><div class="line"><span class="keyword">import</span> hashlib</div><div class="line"><span class="keyword">import</span> requests</div><div class="line"><span class="keyword">import</span> json</div><div class="line"><span class="keyword">import</span> random</div><div class="line"></div><div class="line">cap = cv2.VideoCapture(<span class="number">0</span>)</div><div class="line"><span class="comment"># initialize the video stream and allow the camera sensor to warm up</span></div><div class="line">print(<span class="string">"starting video stream..."</span>)</div><div class="line"><span class="comment"># vs = VideoStream(src=0).start()</span></div><div class="line">vs = VideoStream(src=<span class="number">0</span>).start()</div><div class="line">time.sleep(<span class="number">2.0</span>)</div><div class="line"></div><div class="line">csv = open(<span class="string">"barcodes.csv"</span>, <span class="string">"w"</span>)</div><div class="line">found = set()</div><div class="line"></div><div class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">    <span class="comment"># grab the frame from the threaded video stream and resize it to</span></div><div class="line">    <span class="comment"># have a maximum width of 400 pixels</span></div><div class="line">    frame = vs.read()</div><div class="line">    frame = imutils.resize(frame, width=<span class="number">400</span>)</div><div class="line"></div><div class="line">    word = frame</div><div class="line">    <span class="keyword">for</span> words <span class="keyword">in</span> word:</div><div class="line">        r = str(int(time.time() * <span class="number">1000</span> + random.randint(<span class="number">1</span>, <span class="number">10</span>)))  <span class="comment"># 模仿JS代码的仿写</span></div><div class="line">        S = <span class="string">'fanyideskweb'</span></div><div class="line">        n = words</div><div class="line">        D = <span class="string">"ebSeFb%=XZ%T[KZ)c(sy!"</span>  <span class="comment"># 在完整的JS代码中可找到    </span></div><div class="line">        o = hashlib.md5((S + n + str(r) + D).encode(<span class="string">'utf-8'</span>)).hexdigest()</div><div class="line">        </div><div class="line">        data = &#123;</div><div class="line">            <span class="string">'i'</span>: words,</div><div class="line">            <span class="string">'from'</span>: <span class="string">'AUTO'</span>,</div><div class="line">            <span class="string">'to'</span>: <span class="string">'AUTO'</span>,</div><div class="line">            <span class="string">'smartresult'</span>: <span class="string">'dict'</span>,</div><div class="line">            <span class="string">'client'</span>: S,</div><div class="line">            <span class="string">'salt'</span>: r,</div><div class="line">            <span class="string">'sign'</span>: o,</div><div class="line">            <span class="string">'doctype'</span>: <span class="string">'json'</span>,</div><div class="line">            <span class="string">'version'</span>: <span class="string">'2.1'</span>,</div><div class="line">            <span class="string">'keyfrom'</span>: <span class="string">'fanyi.web'</span>,</div><div class="line">            <span class="string">'action'</span>: <span class="string">'FY_BY_REALTIME'</span>,</div><div class="line">            <span class="string">'typoResult'</span>: <span class="string">'false'</span></div><div class="line">        &#125;</div><div class="line">        url = <span class="string">'http://fanyi.youdao.com/translate_o?smartresult=dict&amp;smartresult=rule'</span></div><div class="line">        </div><div class="line">        <span class="comment"># 在代理中需要加入cookies信息，否则会出现代码错误信息的返回</span></div><div class="line">        header = &#123;</div><div class="line">            <span class="string">'Cookie'</span>: <span class="string">'OUTFOX_SEARCH_USER_ID=432464843@10.168.8.76; _ntes_nnid=25aff2b1480f17471ca1585f6f2f4293,1512024136653; OUTFOX_SEARCH_USER_ID_NCOO=132154936.07902834; JSESSIONID=aaa3TFIg-JJJN4xEog6mw; ___rl__test__cookies=1525691300664'</span>,</div><div class="line">            <span class="string">'Referer'</span>: <span class="string">'http://fanyi.youdao.com/'</span>,</div><div class="line">            <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36'</span></div><div class="line">        &#125;</div><div class="line">        response = requests.post(url=url, headers=header, data=data)</div><div class="line">        response.encoding = <span class="string">'utf-8'</span></div><div class="line">        </div><div class="line">        translateResult = json.loads(response.text)[<span class="string">"translateResult"</span>][<span class="number">0</span>][<span class="number">0</span>][<span class="string">'tgt'</span>]</div><div class="line">        <span class="comment">#(x, y, w, h) = words.rect</span></div><div class="line">        cv2.rectangle(frame, (<span class="number">10</span>, <span class="number">10</span>), (<span class="number">20</span>, <span class="number">20</span>), (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)</div><div class="line">        </div><div class="line">               cv2.putText(frame, translateResult, (<span class="number">10</span>, <span class="number">10</span> - <span class="number">10</span>),</div><div class="line">        cv2.FONT_HERSHEY_SIMPLEX, <span class="number">0.5</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)</div><div class="line">        </div><div class="line">        <span class="comment"># if the  text is currently not in our CSV file, write</span></div><div class="line">        <span class="comment"># the timestamp + text qto disk and update the set</span></div><div class="line">        <span class="keyword">if</span> translateResult <span class="keyword">not</span> <span class="keyword">in</span> found:</div><div class="line">            csv.write(<span class="string">"&#123;&#125;,&#123;&#125;\n"</span>.format(datetime.datetime.now(),</div><div class="line">                translateResult))</div><div class="line">            csv.flush()</div><div class="line">            found.add(translateResult)</div><div class="line"></div><div class="line">    <span class="comment"># show the output frame</span></div><div class="line">    cv2.imshow(<span class="string">"Translate Discern"</span>, frame)</div><div class="line">    key = cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span></div><div class="line"> </div><div class="line">    <span class="comment"># if the `q` key was pressed, break from the loop</span></div><div class="line">    <span class="keyword">if</span> key == ord(<span class="string">"q"</span>):</div><div class="line">        <span class="keyword">break</span></div><div class="line"></div><div class="line"><span class="comment"># close the output CSV file do a bit of cleanup</span></div><div class="line">print(<span class="string">"cleaning up..."</span>)</div><div class="line">cap.release()  <span class="comment"># 释放摄像头</span></div><div class="line">csv.close()</div><div class="line">cv2.destroyAllWindows()</div><div class="line">vs.stop()</div></pre></td></tr></table></figure><p>可参考：</p><ul><li><p><a href="https://www.jiqizhixin.com/articles/2017-09-21-3" target="_blank" rel="external">深度学习 + OpenCV，Python实现实时视频目标检测</a></p></li><li><p><a href="https://yongyuan.name/pcvwithpython/chapter10.html#sec-10-2-1" target="_blank" rel="external">OpenCV Python接口</a></p></li><li><p><a href="https://www.pyimagesearch.com/2015/04/06/zero-parameter-automatic-canny-edge-detection-with-python-and-opencv/" target="_blank" rel="external">Zero-parameter, automatic Canny edge detection with Python and OpenCV</a></p></li><li><p><a href="https://juejin.im/entry/5b5e694ee51d4535c75631e7" target="_blank" rel="external">Opencv获取身份证号码区域</a></p></li></ul><h1 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h1><p>记录一下在下载tesseract之后的提示，有一天可能会用到：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">icu4c is keg-only, which means it was not symlinked into /usr/local,</div><div class="line">because macOS provides libicucore.dylib (but nothing else).</div><div class="line"></div><div class="line">If you need to have icu4c first in your PATH run:</div><div class="line">  echo &apos;export PATH=&quot;/usr/local/opt/icu4c/bin:$PATH&quot;&apos; &gt;&gt; ~/.bash_profile</div><div class="line">  echo &apos;export PATH=&quot;/usr/local/opt/icu4c/sbin:$PATH&quot;&apos; &gt;&gt; ~/.bash_profile</div><div class="line"></div><div class="line">For compilers to find icu4c you may need to set:</div><div class="line">  export LDFLAGS=&quot;-L/usr/local/opt/icu4c/lib&quot;</div><div class="line">  export CPPFLAGS=&quot;-I/usr/local/opt/icu4c/include&quot;</div><div class="line"></div><div class="line">For pkg-config to find icu4c you may need to set:</div><div class="line">  export PKG_CONFIG_PATH=&quot;/usr/local/opt/icu4c/lib/pkgconfig&quot;</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文讲述基于python的一些模块进行&lt;code&gt;图片内容的提取&lt;/code&gt;、&lt;code&gt;图片内容的翻译&lt;/code&gt;。本文主要进行记录一些在实践中的构想以及遇到的问题，并且记录上一些实现的代码，因为技术含量实在是不怎么高的，不过若是自己玩玩，参加那种水比赛也许能获得个不错的名次，或者是应付个学生报告什么的…&lt;/p&gt;
&lt;p&gt;由于时间关系，本文多数只是起到一个构想记录的效用。&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://liujunjie11.github.io/categories/Python/"/>
    
      <category term="OCR" scheme="https://liujunjie11.github.io/categories/OCR/"/>
    
      <category term="OpenCV" scheme="https://liujunjie11.github.io/categories/OpenCV/"/>
    
    
      <category term="Python" scheme="https://liujunjie11.github.io/tags/Python/"/>
    
      <category term="OCR" scheme="https://liujunjie11.github.io/tags/OCR/"/>
    
      <category term="OpenCV" scheme="https://liujunjie11.github.io/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>Kaggle比赛：数字识别的多种算法实现</title>
    <link href="https://liujunjie11.github.io/2018/11/07/Kaggle%E6%AF%94%E8%B5%9B%EF%BC%9A%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E7%9A%84%E5%A4%9A%E7%A7%8D%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/"/>
    <id>https://liujunjie11.github.io/2018/11/07/Kaggle比赛：数字识别的多种算法实现/</id>
    <published>2018-11-07T07:09:27.000Z</published>
    <updated>2018-11-13T12:31:33.382Z</updated>
    
    <content type="html"><![CDATA[<p>关于<code>Kaggle</code>大赛就不多说了，我打算进一步了解一下入门级的比赛之后再另作参加项目/比赛的打算，在此之前需要更多的实践才行。</p><p>以下是我学习的地址(在一个<code>GitHub</code>大神分享的相关的资源)：</p><blockquote><p><a href="https://github.com/apachecn/kaggle/blob/dev/competitions/getting-started/digit-recognizer/knn算法描述.md" target="_blank" rel="external">https://github.com/apachecn/kaggle/blob/dev/competitions/getting-started/digit-recognizer/knn算法描述.md</a></p></blockquote><p>里面有多种可以实现的算法的代码以及思想，我在此进行进一步的整理，进行一个简单的代码记录，以及会进行一点修改以符合我自身的情况。</p><ul><li>需要的数据下载地址：<a href="https://www.kaggle.com/c/digit-recognizer/data" target="_blank" rel="external">https://www.kaggle.com/c/digit-recognizer/data</a></li></ul><a id="more"></a><h1 id="KNN实现"><a href="#KNN实现" class="headerlink" title="KNN实现"></a>KNN实现</h1><p><img src="http://liu-1258031152.cos.ap-beijing.myqcloud.com/1283539-1820df734cf34260.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;关于&lt;code&gt;Kaggle&lt;/code&gt;大赛就不多说了，我打算进一步了解一下入门级的比赛之后再另作参加项目/比赛的打算，在此之前需要更多的实践才行。&lt;/p&gt;
&lt;p&gt;以下是我学习的地址(在一个&lt;code&gt;GitHub&lt;/code&gt;大神分享的相关的资源)：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/apachecn/kaggle/blob/dev/competitions/getting-started/digit-recognizer/knn算法描述.md&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/apachecn/kaggle/blob/dev/competitions/getting-started/digit-recognizer/knn算法描述.md&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;里面有多种可以实现的算法的代码以及思想，我在此进行进一步的整理，进行一个简单的代码记录，以及会进行一点修改以符合我自身的情况。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;需要的数据下载地址：&lt;a href=&quot;https://www.kaggle.com/c/digit-recognizer/data&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://www.kaggle.com/c/digit-recognizer/data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Kaggle" scheme="https://liujunjie11.github.io/categories/Kaggle/"/>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/categories/Python/"/>
    
    
      <category term="Kaggle" scheme="https://liujunjie11.github.io/tags/Kaggle/"/>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>python机器学习系列：均值平移(Mean Shift)算法的实现及应用</title>
    <link href="https://liujunjie11.github.io/2018/10/30/python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%9A%E5%9D%87%E5%80%BC%E5%B9%B3%E7%A7%BB(Mean%20Shift)%E7%AE%97%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%BA%94%E7%94%A8/"/>
    <id>https://liujunjie11.github.io/2018/10/30/python机器学习系列：均值平移(Mean Shift)算法的实现及应用/</id>
    <published>2018-10-30T12:54:58.000Z</published>
    <updated>2018-11-13T12:31:42.279Z</updated>
    
    <content type="html"><![CDATA[<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/3ERPpzrDkVg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><blockquote><p>这里是对应的课程地址：<a href="https://pythonprogramming.net/hierarchical-clustering-mean-shift-machine-learning-tutorial/?completed=/k-means-from-scratch-2-machine-learning-tutorial/" target="_blank" rel="external">https://pythonprogramming.net/hierarchical-clustering-mean-shift-machine-learning-tutorial/?completed=/k-means-from-scratch-2-machine-learning-tutorial/</a></p></blockquote><p>关于这个算法更像是<code>无监督学习</code>，它相较于<code>K-Means</code>算法不用指定<code>K</code>的个数，可以自动的通过求解一个向量，使得圆心一直往数据集密度最大的方向移动。说的再简单一点，就是每次迭代的时候，都是找到圆里面点的平均位置作为新的圆心位置。</p><blockquote><p>可参考：<a href="https://blog.csdn.net/hjimce/article/details/45718593" target="_blank" rel="external">机器学习（十）Mean Shift 聚类算法</a>、<br><a href="https://zh.wikipedia.org/wiki/%E7%88%AC%E5%B1%B1%E7%AE%97%E6%B3%95" target="_blank" rel="external">爬山算法</a></p></blockquote><p>在原作者的原代码上进行一些符合当今实际情况的修改。</p><a id="more"></a><h1 id="均值平移-Mean-Shift-的实现"><a href="#均值平移-Mean-Shift-的实现" class="headerlink" title="均值平移(Mean Shift)的实现"></a>均值平移(Mean Shift)的实现</h1><p>首先通过代码来理解看看他是个什么情况：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> MeanShift</div><div class="line"><span class="keyword">from</span> sklearn.datasets.samples_generator <span class="keyword">import</span> make_blobs</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line">centers = [[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>], [<span class="number">5</span>,<span class="number">5</span>,<span class="number">5</span>], [<span class="number">3</span>,<span class="number">10</span>,<span class="number">10</span>]]</div><div class="line"></div><div class="line"><span class="comment">#样本以及聚类型</span></div><div class="line">X, label = make_blobs(n_samples=<span class="number">100</span>, centers=centers, cluster_std=<span class="number">1.5</span>) <span class="comment">#样本数量，中心点，方差设置</span></div><div class="line"></div><div class="line">ms = MeanShift()</div><div class="line">ms.fit(X)</div><div class="line">labels = ms.labels_</div><div class="line">cluster_centers = ms.cluster_centers_</div><div class="line">n_clusters = len(np.unique(labels))</div><div class="line">print(labels,cluster_centers)</div><div class="line"></div><div class="line">colors = [<span class="string">'r'</span>,<span class="string">'g'</span>,<span class="string">'k'</span>]</div><div class="line">fig = plt.figure()</div><div class="line">ax = fig.add_subplot(<span class="number">111</span>, projection = <span class="string">'3d'</span>)</div><div class="line"></div><div class="line"><span class="comment">#画出所有的样本点</span></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(X)):</div><div class="line">    ax.scatter(X[i][<span class="number">0</span>], X[i][<span class="number">1</span>], X[i][<span class="number">2</span>], c=colors[labels[i]], marker=<span class="string">'o'</span>)</div><div class="line"></div><div class="line"><span class="comment">#画出中心点</span></div><div class="line">ax.scatter(cluster_centers[:,<span class="number">0</span>], cluster_centers[:,<span class="number">1</span>], cluster_centers[:,<span class="number">2</span>],marker=<span class="string">'x'</span>, color=<span class="string">'k'</span>, s=<span class="number">150</span>, linewidths=<span class="number">5</span>, zorder=<span class="number">1</span>) <span class="comment">#zorder参数的数值越小表示越早画上去，在图表在叠加状态下时有一定的调整作用，比如不让画出来的交叉图分不清等问题</span></div><div class="line"><span class="comment"># ax.scatter(cluster_centers[0], cluster_centers[1], cluster_centers[2],marker='x', color='k', s=150, linewidths=5, zorder=10)还是跟上面的有区别的，自行检查。</span></div><div class="line">print(cluster_centers[:,<span class="number">0</span>])</div><div class="line"></div><div class="line">plt.show()</div></pre></td></tr></table></figure><p>结果展示：</p><ul><li>直接移步这里看吧：<a href="https://pythonprogramming.net/hierarchical-clustering-mean-shift-machine-learning-tutorial/" target="_blank" rel="external">https://pythonprogramming.net/hierarchical-clustering-mean-shift-machine-learning-tutorial/</a></li></ul><blockquote><p>对我来说，作者的关于<code>均值平移(Mean Shift)算法</code>的教程文章实在是看不下去了…</p></blockquote><h2 id="关于原作者的均值平移-Mean-Shift-算法的实现"><a href="#关于原作者的均值平移-Mean-Shift-算法的实现" class="headerlink" title="关于原作者的均值平移(Mean Shift)算法的实现"></a>关于原作者的均值平移(Mean Shift)算法的实现</h2><ul><li>直接移步这里吧：<a href="https://pythonprogramming.net/weighted-bandwidth-mean-shift-machine-learning-tutorial/" target="_blank" rel="external">https://pythonprogramming.net/weighted-bandwidth-mean-shift-machine-learning-tutorial/</a></li></ul><blockquote><p>原作者的代码不怎么合意，并且不能怎么真正的展现出来实现的意义，我不怎么认同，所以只贴上链接在此。</p></blockquote><h2 id="关于均值平移-Mean-Shift-算法的项目应用"><a href="#关于均值平移-Mean-Shift-算法的项目应用" class="headerlink" title="关于均值平移(Mean Shift)算法的项目应用"></a>关于均值平移(Mean Shift)算法的项目应用</h2><p>在原作者中是关于上次中的<code>titanic</code>数据集。</p><blockquote><p>数据地址：<a href="https://pythonprogramming.net/static/downloads/machine-learning-data/titanic.xls" target="_blank" rel="external">https://pythonprogramming.net/static/downloads/machine-learning-data/titanic.xls</a></p></blockquote><ul><li>这里是实现的地址：<a href="https://pythonprogramming.net/mean-shift-titanic-dataset-machine-learning-tutorial/" target="_blank" rel="external">https://pythonprogramming.net/mean-shift-titanic-dataset-machine-learning-tutorial/</a></li></ul><p>对我来说，这个算法应用到这个数据集上是有一点牵强的，没必要的…因为选择这样的数据集来进行试验品实在有点晦涩难懂不合适。</p><h2 id="铺助理解链接"><a href="#铺助理解链接" class="headerlink" title="铺助理解链接"></a>铺助理解链接</h2><ul><li><p><a href="https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.array_equal.html" target="_blank" rel="external">numpy.array_equal</a></p></li><li><p><a href="https://matplotlib.org/mpl_toolkits/mplot3d/tutorial.html" target="_blank" rel="external">mplot3d tutorial</a></p></li><li><p><a href="https://blog.csdn.net/ichuzhen/article/details/51768934" target="_blank" rel="external">sklearn 中 make_blobs模块使用</a></p></li><li><p><a href="https://blog.csdn.net/hjimce/article/details/45718593" target="_blank" rel="external">机器学习（十）Mean Shift 聚类算法</a></p></li><li><p><a href="https://www.zhihu.com/question/56091756/answer/191164507" target="_blank" rel="external">matplotlib.pyplot.plot()函数中参数zorder</a></p></li></ul><p>就这样吧，其实我也很期待写下<code>神经网络</code>的记录教程～</p>]]></content>
    
    <summary type="html">
    
      &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/3ERPpzrDkVg&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;blockquote&gt;
&lt;p&gt;这里是对应的课程地址：&lt;a href=&quot;https://pythonprogramming.net/hierarchical-clustering-mean-shift-machine-learning-tutorial/?completed=/k-means-from-scratch-2-machine-learning-tutorial/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://pythonprogramming.net/hierarchical-clustering-mean-shift-machine-learning-tutorial/?completed=/k-means-from-scratch-2-machine-learning-tutorial/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;关于这个算法更像是&lt;code&gt;无监督学习&lt;/code&gt;，它相较于&lt;code&gt;K-Means&lt;/code&gt;算法不用指定&lt;code&gt;K&lt;/code&gt;的个数，可以自动的通过求解一个向量，使得圆心一直往数据集密度最大的方向移动。说的再简单一点，就是每次迭代的时候，都是找到圆里面点的平均位置作为新的圆心位置。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;可参考：&lt;a href=&quot;https://blog.csdn.net/hjimce/article/details/45718593&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;机器学习（十）Mean Shift 聚类算法&lt;/a&gt;、&lt;br&gt;&lt;a href=&quot;https://zh.wikipedia.org/wiki/%E7%88%AC%E5%B1%B1%E7%AE%97%E6%B3%95&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;爬山算法&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在原作者的原代码上进行一些符合当今实际情况的修改。&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/categories/Python/"/>
    
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>python机器学习系列：K-均值算法(K-Means)的实现及应用</title>
    <link href="https://liujunjie11.github.io/2018/10/26/python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%9AK-%E5%9D%87%E5%80%BC%E7%AE%97%E6%B3%95(K-Means)%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%BA%94%E7%94%A8/"/>
    <id>https://liujunjie11.github.io/2018/10/26/python机器学习系列：K-均值算法(K-Means)的实现及应用/</id>
    <published>2018-10-26T13:22:11.000Z</published>
    <updated>2018-11-13T12:31:53.703Z</updated>
    
    <content type="html"><![CDATA[<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/ZueoXMgCd1c" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe><ul><li>对应的课程地址：<a href="https://pythonprogramming.net/machine-learning-clustering-introduction-machine-learning-tutorial/?completed=/support-vector-machine-parameters-machine-learning-tutorial/" target="_blank" rel="external">https://pythonprogramming.net/machine-learning-clustering-introduction-machine-learning-tutorial/?completed=/support-vector-machine-parameters-machine-learning-tutorial/</a></li></ul><p>K-均值算法(K-Means)属于无监督学习、聚类算法。即将无标签的数据集进行分类，并且无训练过程(监督学习的数据集才存在训练一说)等，又可理解为<code>自动分类器</code>。</p><p>本文对于原作者的代码进行了一点修改以符合当今情况。</p><a id="more"></a><h1 id="K-均值算法-K-Means-的实现"><a href="#K-均值算法-K-Means-的实现" class="headerlink" title="K-均值算法(K-Means)的实现"></a>K-均值算法(K-Means)的实现</h1><p>这个算法不算是很难理解，实际上很容易理解，在此就不多废话了。</p><p>简单说说等下代码实现的思想原理以及相关的需要注意的一些东西。关于这个实现的过程中，会想从前一样，使用自制的数据集样本，在其中会选择两个作为最初的中心点(亦可通过洗牌后进行选择)，然后将剩下的数据集与这两个中心点进行计算，通过得出的距离大小使得离得哪个中心点近就归属于那个中心点的分类处(非0即1的分类)，接着会从这些已经各就各位的点中得出平均点。我们会设置一个最大迭代次数以及一个固定公差数(迭代次数在此不够严谨，仅仅起到学习认知的作用)，关于这个公差数是起到一个监督的作用，若是在未得出平均点之前的数据点与中心点之间的公差数值大于固定公差数阈值，就说明优化失败了，之后这次的优化就忽略，直接进行下一次的优化过程(得出最佳平均点就是一次又一次优化的过程，最终目标就是得出最佳的平均点，最具代表性的点)。最终我们会通过数据可视化来进行图表结果的展示。</p><p>以下是实现代码。</p><h2 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"> 自制训练数据集</div><div class="line">X = np.array([[<span class="number">1</span>,<span class="number">2</span>],</div><div class="line">             [<span class="number">1.5</span>,<span class="number">1.8</span>],</div><div class="line">             [<span class="number">5</span>,<span class="number">8</span>],</div><div class="line">             [<span class="number">8</span>,<span class="number">8</span>],</div><div class="line">             [<span class="number">1</span>,<span class="number">0.6</span>],</div><div class="line">             [<span class="number">9</span>,<span class="number">11</span>],</div><div class="line">             [<span class="number">1</span>,<span class="number">3</span>],</div><div class="line">             [<span class="number">8</span>,<span class="number">9</span>],</div><div class="line">             [<span class="number">0</span>,<span class="number">3</span>],</div><div class="line">             [<span class="number">5</span>,<span class="number">4</span>],</div><div class="line">             [<span class="number">6</span>,<span class="number">4</span>]])</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">K_Means</span><span class="params">()</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, k=<span class="number">2</span>, tol=<span class="number">0.001</span>, max_iter=<span class="number">300</span>)</span>:</span></div><div class="line">        self.k = k</div><div class="line">        self.tol = tol</div><div class="line">        self.max_iter = max_iter <span class="comment">#最大迭代次数</span></div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, data)</span>:</span></div><div class="line">        </div><div class="line">        self.centroids = &#123;&#125; <span class="comment">#质点圆心</span></div><div class="line">        </div><div class="line">        <span class="comment">#取两个作为中心点</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.k):</div><div class="line">            self.centroids[i] = data[i]</div><div class="line">            </div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.max_iter):</div><div class="line">            self.classifications = &#123;&#125;</div><div class="line">            </div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(self.k):</div><div class="line">                self.classifications[i] = []</div><div class="line">            </div><div class="line">            <span class="keyword">for</span> featureset <span class="keyword">in</span> data:</div><div class="line">                <span class="comment">#计算点与点之间的距离,分配数据集进入各自合适的阵营</span></div><div class="line">                distances = [np.linalg.norm(featureset-self.centroids[centroid]) <span class="keyword">for</span> centroid <span class="keyword">in</span> self.centroids]</div><div class="line">                classification = distances.index(min(distances)) <span class="comment">#取最小的距离索引位置点</span></div><div class="line">                self.classifications[classification].append(featureset)</div><div class="line">        </div><div class="line">            prev_centroids = dict(self.centroids) <span class="comment">#保留现在的原数据，之后计算公差要用到</span></div><div class="line">            </div><div class="line">            <span class="keyword">for</span> classification <span class="keyword">in</span> self.classifications:</div><div class="line">                <span class="comment">#得出平均点</span></div><div class="line">                self.centroids[classification] = np.average(self.classifications[classification], axis=<span class="number">0</span>)</div><div class="line">            </div><div class="line">            optimized = <span class="keyword">True</span></div><div class="line">            </div><div class="line">            <span class="keyword">for</span> c <span class="keyword">in</span> self.centroids:</div><div class="line">                original_centroid = prev_centroids[c]</div><div class="line">                current_centroid = self.centroids[c]</div><div class="line">                <span class="keyword">if</span> np.sum((current_centroid - original_centroid)/original_centroid*<span class="number">100.0</span>) &gt; self.tol:</div><div class="line">                    print(np.sum((current_centroid - original_centroid)/original_centroid*<span class="number">100</span>))</div><div class="line">                    optimized = <span class="keyword">False</span></div><div class="line">                </div><div class="line">            <span class="keyword">if</span> optimized:</div><div class="line">                <span class="keyword">break</span></div><div class="line">                </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, data)</span>:</span></div><div class="line">        <span class="comment">#代入数据集与圆心点进行距离计算，并且进行分类0/1</span></div><div class="line">        distances = [np.linalg.norm(data-self.centroids[centroid]) <span class="keyword">for</span> centroid <span class="keyword">in</span> self.centroids]</div><div class="line">        classification = distances.index(min(distances)) </div><div class="line">        <span class="keyword">return</span> classification</div></pre></td></tr></table></figure><p>下面是训练过程以及图表展示相关的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line">colors = [<span class="string">'g'</span>, <span class="string">'r'</span>, <span class="string">'c'</span>, <span class="string">'b'</span>, <span class="string">'k'</span>] </div><div class="line"></div><div class="line">clf = K_Means()</div><div class="line">clf.fit(X)</div><div class="line"></div><div class="line"><span class="comment"># 可视化中心原点</span></div><div class="line"><span class="keyword">for</span> centroid <span class="keyword">in</span> clf.centroids:</div><div class="line">    plt.scatter(clf.centroids[centroid][<span class="number">0</span>], clf.centroids[centroid][<span class="number">1</span>], marker=<span class="string">'o'</span>, color=<span class="string">'k'</span>, s=<span class="number">150</span>, linewidths=<span class="number">5</span>)</div><div class="line"></div><div class="line"><span class="comment">#可视化已分类好的各就各位的点</span></div><div class="line"><span class="keyword">for</span> classification <span class="keyword">in</span> clf.classifications:</div><div class="line">    color = colors[classification]</div><div class="line">    <span class="keyword">for</span> featrueset <span class="keyword">in</span> clf.classifications[classification]:</div><div class="line">        plt.scatter(featrueset[<span class="number">0</span>], featrueset[<span class="number">1</span>], marker=<span class="string">'x'</span>, color=color, s=<span class="number">150</span>, linewidths=<span class="number">5</span>)</div><div class="line"></div><div class="line">plt.show()</div></pre></td></tr></table></figure><h2 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line"><span class="comment"># 自制训练数据集</span></div><div class="line">X = np.array([[<span class="number">1</span>,<span class="number">2</span>],</div><div class="line">             [<span class="number">1.5</span>,<span class="number">1.8</span>],</div><div class="line">             [<span class="number">5</span>,<span class="number">8</span>],</div><div class="line">             [<span class="number">8</span>,<span class="number">8</span>],</div><div class="line">             [<span class="number">1</span>,<span class="number">0.6</span>],</div><div class="line">             [<span class="number">9</span>,<span class="number">11</span>],</div><div class="line">             [<span class="number">1</span>,<span class="number">3</span>],</div><div class="line">             [<span class="number">8</span>,<span class="number">9</span>],</div><div class="line">             [<span class="number">0</span>,<span class="number">3</span>],</div><div class="line">             [<span class="number">5</span>,<span class="number">4</span>],</div><div class="line">             [<span class="number">6</span>,<span class="number">4</span>]])</div><div class="line"></div><div class="line">colors = [<span class="string">'g'</span>, <span class="string">'r'</span>, <span class="string">'c'</span>, <span class="string">'b'</span>, <span class="string">'k'</span>] </div><div class="line">print(colors)</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">K_Means</span><span class="params">()</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, k=<span class="number">2</span>, tol=<span class="number">0.001</span>, max_iter=<span class="number">300</span>)</span>:</span></div><div class="line">        self.k = k</div><div class="line">        self.tol = tol</div><div class="line">        self.max_iter = max_iter <span class="comment">#最大迭代次数</span></div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, data)</span>:</span></div><div class="line">        </div><div class="line">        self.centroids = &#123;&#125; <span class="comment">#质点圆心</span></div><div class="line">        </div><div class="line">        <span class="comment">#取两个作为中心点</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.k):</div><div class="line">            self.centroids[i] = data[i]</div><div class="line">            </div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.max_iter):</div><div class="line">            self.classifications = &#123;&#125;</div><div class="line">            </div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(self.k):</div><div class="line">                self.classifications[i] = []</div><div class="line">            </div><div class="line">            <span class="keyword">for</span> featureset <span class="keyword">in</span> data:</div><div class="line">                <span class="comment">#计算点与点之间的距离,分配数据集进入各自合适的阵营</span></div><div class="line">                distances = [np.linalg.norm(featureset-self.centroids[centroid]) <span class="keyword">for</span> centroid <span class="keyword">in</span> self.centroids]</div><div class="line">                classification = distances.index(min(distances)) <span class="comment">#取最小的距离索引位置点</span></div><div class="line">                self.classifications[classification].append(featureset)</div><div class="line">        </div><div class="line">            prev_centroids = dict(self.centroids) <span class="comment">#保留现在的原数据，之后计算公差要用到</span></div><div class="line">            </div><div class="line">            <span class="keyword">for</span> classification <span class="keyword">in</span> self.classifications:</div><div class="line">                <span class="comment">#得出平均点</span></div><div class="line">                self.centroids[classification] = np.average(self.classifications[classification], axis=<span class="number">0</span>)</div><div class="line">            </div><div class="line">            optimized = <span class="keyword">True</span></div><div class="line">            </div><div class="line">            <span class="keyword">for</span> c <span class="keyword">in</span> self.centroids:</div><div class="line">                original_centroid = prev_centroids[c]</div><div class="line">                current_centroid = self.centroids[c]</div><div class="line">                <span class="keyword">if</span> np.sum((current_centroid - original_centroid)/original_centroid*<span class="number">100.0</span>) &gt; self.tol:</div><div class="line">                    print(np.sum((current_centroid - original_centroid)/original_centroid*<span class="number">100</span>))</div><div class="line">                    optimized = <span class="keyword">False</span></div><div class="line">                </div><div class="line">            <span class="keyword">if</span> optimized:</div><div class="line">                <span class="keyword">break</span></div><div class="line">                </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, data)</span>:</span></div><div class="line">        <span class="comment">#代入数据集与圆心点进行距离计算，并且进行分类0/1</span></div><div class="line">        distances = [np.linalg.norm(data-self.centroids[centroid]) <span class="keyword">for</span> centroid <span class="keyword">in</span> self.centroids]</div><div class="line">        classification = distances.index(min(distances)) </div><div class="line">        <span class="keyword">return</span> classification</div><div class="line">            </div><div class="line"></div><div class="line">clf = K_Means()</div><div class="line">clf.fit(X)</div><div class="line"></div><div class="line"><span class="comment"># 可视化中心原点</span></div><div class="line"><span class="keyword">for</span> centroid <span class="keyword">in</span> clf.centroids:</div><div class="line">    plt.scatter(clf.centroids[centroid][<span class="number">0</span>], clf.centroids[centroid][<span class="number">1</span>], marker=<span class="string">'o'</span>, color=<span class="string">'k'</span>, s=<span class="number">150</span>, linewidths=<span class="number">5</span>)</div><div class="line"></div><div class="line"><span class="comment">#可视化已分类好的各就各位的点</span></div><div class="line"><span class="keyword">for</span> classification <span class="keyword">in</span> clf.classifications:</div><div class="line">    color = colors[classification]</div><div class="line">    <span class="keyword">for</span> featrueset <span class="keyword">in</span> clf.classifications[classification]:</div><div class="line">        plt.scatter(featrueset[<span class="number">0</span>], featrueset[<span class="number">1</span>], marker=<span class="string">'x'</span>, color=color, s=<span class="number">150</span>, linewidths=<span class="number">5</span>)</div><div class="line"></div><div class="line">plt.show()</div></pre></td></tr></table></figure><p>铺助理解链接：</p><ul><li><p><a href="https://cloud.tencent.com/developer/ask/42899" target="_blank" rel="external">np.mean()和Python NumPy中的np.average()有什么区别？</a></p></li><li><p><a href="https://blog.csdn.net/JohinieLi/article/details/78350999" target="_blank" rel="external">关于numpy mean函数的axis参数</a></p></li><li><p><a href="https://matplotlib.org/2.1.1/api/_as_gen/matplotlib.pyplot.plot.html" target="_blank" rel="external">matplotlib.pyplot.plot</a></p></li><li><p><a href="https://www.cnblogs.com/zsr0401/p/6405677.html" target="_blank" rel="external">Python-Matplotlib 9 颜色和样式</a></p></li></ul><h2 id="展示结果"><a href="#展示结果" class="headerlink" title="展示结果"></a>展示结果</h2><p><img src="http://smartjpa.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-30%20%E4%B8%8B%E5%8D%889.32.06.png" alt=""></p><blockquote><p>这样在这里就完成了实现的过程。这个算法真的不怎么难，至少相较于上次的<code>SVM</code>来说。</p></blockquote><h1 id="项目应用"><a href="#项目应用" class="headerlink" title="项目应用"></a>项目应用</h1><h2 id="sklearn的K-Means模型训练"><a href="#sklearn的K-Means模型训练" class="headerlink" title="sklearn的K-Means模型训练"></a>sklearn的K-Means模型训练</h2><p>这次用到的数据是再熟悉不过的<code>titanic</code>数据集，就是预测生死的那个<code>kaggle</code>入门级比赛的那个，哈哈。</p><blockquote><p>数据地址：<a href="https://pythonprogramming.net/static/downloads/machine-learning-data/titanic.xls" target="_blank" rel="external">https://pythonprogramming.net/static/downloads/machine-learning-data/titanic.xls</a></p></blockquote><p>在利用这个数据时，先将数据集进行简单的数据预处理，以及将非数值数据进行简单的数值转换(即将非数值型数值转换为数值型数据)，之后代入现成的<code>sklearn</code>对应的K-Means模型进行训练，最后得出预测准确性。</p><p>下面是代码实现部分：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line">df = pd.read_excel(<span class="string">'titanic.xls'</span>)</div><div class="line"></div><div class="line"><span class="comment">#简单的数据预处理</span></div><div class="line">df.drop([<span class="string">'body'</span>,<span class="string">'name'</span>], <span class="number">1</span>, inplace=<span class="keyword">True</span>)</div><div class="line">df.fillna(<span class="number">0</span>, inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line"><span class="comment">#处理非数值数据</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">handle_non_numerical_data</span><span class="params">(df)</span>:</span></div><div class="line">    columns = df.columns.values</div><div class="line">    </div><div class="line">    <span class="keyword">for</span> column <span class="keyword">in</span> columns: <span class="comment">#取出各个列名作为遍历的基调</span></div><div class="line">        text_digit_vals = &#123;&#125;</div><div class="line">        <span class="function"><span class="keyword">def</span> <span class="title">convert_to_int</span><span class="params">(val)</span>:</span></div><div class="line">            <span class="keyword">return</span> text_digit_vals[val]</div><div class="line">        </div><div class="line">        <span class="keyword">if</span> df[column].dtype != np.int64 <span class="keyword">and</span> df[column].dtype != np.float64:</div><div class="line">            column_contents = df[column].values.tolist() <span class="comment">#转换为列表类型以便下方处理</span></div><div class="line">            unique_elements = set(column_contents) <span class="comment">#去掉重复值</span></div><div class="line">            x = <span class="number">0</span></div><div class="line">            <span class="keyword">for</span> unique <span class="keyword">in</span> unique_elements:</div><div class="line">                <span class="keyword">if</span> unique <span class="keyword">not</span> <span class="keyword">in</span> text_digit_vals:</div><div class="line">                    text_digit_vals[unique] = x <span class="comment">#即在此将非数值的数据改为了数值型数据集</span></div><div class="line">                    x+=<span class="number">1</span></div><div class="line">                    </div><div class="line">            df[column] = list(map(convert_to_int, df[column])) <span class="comment">#将列名替代掉上面的unique非数值列名</span></div><div class="line">            </div><div class="line">    <span class="keyword">return</span> df</div><div class="line"></div><div class="line">df = handle_non_numerical_data(df)</div><div class="line"></div><div class="line">df.drop([<span class="string">'sex'</span>,<span class="string">'boat'</span>], <span class="number">1</span>, inplace=<span class="keyword">True</span>)</div><div class="line">X = np.array(df.drop([<span class="string">'survived'</span>], <span class="number">1</span>).astype(float))</div><div class="line">X = preprocessing.scale(X) <span class="comment">#进行缩放，标准化</span></div><div class="line">y = np.array(df[<span class="string">'survived'</span>])</div><div class="line"></div><div class="line">clf = KMeans(n_clusters=<span class="number">2</span>) <span class="comment">#得出0/1</span></div><div class="line">clf.fit(X)</div><div class="line"></div><div class="line">correct = <span class="number">0</span></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(X)):</div><div class="line">    predict_me = np.array(X[i].astype(float))</div><div class="line">    predict_me = predict_me.reshape(<span class="number">-1</span>, len(predict_me)) <span class="comment">#得出每排的数据集</span></div><div class="line">    prediction = clf.predict(predict_me)</div><div class="line">    <span class="keyword">if</span> prediction[<span class="number">0</span>] == y[i]: </div><div class="line">        correct += <span class="number">1</span></div><div class="line">        </div><div class="line">print(correct/len(X))</div></pre></td></tr></table></figure><p>铺助理解链接：</p><ul><li><p><a href="http://sklearn.apachecn.org/cn/stable/index.html" target="_blank" rel="external">sklearn中文主页</a></p></li><li><p><a href="http://www.runoob.com/python/python-func-map.html" target="_blank" rel="external">Python map() 函数</a></p></li><li><p><a href="https://blog.csdn.net/Dream_angel_Z/article/details/49406573" target="_blank" rel="external">Scikit-learn Preprocessing 预处理</a></p></li><li><p><a href="https://blog.csdn.net/nuaadot/article/details/78304642" target="_blank" rel="external">python进行数据处理——pandas的drop函数</a></p></li></ul><p>下面是得出的结果：</p><p><img src="http://smartjpa.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-30%20%E4%B8%8B%E5%8D%8810.04.28.png" alt=""></p><blockquote><p>由于数据简单的预处理了一下，所以准确性在0.3～0.7之间。</p></blockquote><h2 id="sklearn的K-Means模型自制数据集训练"><a href="#sklearn的K-Means模型自制数据集训练" class="headerlink" title="sklearn的K-Means模型自制数据集训练"></a>sklearn的K-Means模型自制数据集训练</h2><p>这是用自制的数据集进行的模型训练，最后将结果进行图表展示，可以更好的理解这个在<code>sklearn</code>模块中的现成<code>K-Means</code>模型的运作情况。</p><p>以下是相关的代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line">X = np.array([[<span class="number">1</span>,<span class="number">2</span>],</div><div class="line">             [<span class="number">1.5</span>,<span class="number">1.8</span>],</div><div class="line">             [<span class="number">5</span>,<span class="number">8</span>],</div><div class="line">             [<span class="number">8</span>,<span class="number">8</span>],</div><div class="line">             [<span class="number">1</span>,<span class="number">0.6</span>],</div><div class="line">             [<span class="number">9</span>,<span class="number">11</span>]])</div><div class="line"></div><div class="line">clf = KMeans(n_clusters=<span class="number">2</span>) <span class="comment">#聚点设置，必须小于数据集的长度</span></div><div class="line">clf.fit(X)</div><div class="line"></div><div class="line">centroids = clf.cluster_centers_ <span class="comment">#聚类中心坐标</span></div><div class="line">labels = clf.labels_ <span class="comment">#标签</span></div><div class="line"></div><div class="line">colors = [<span class="string">'g.'</span>,<span class="string">'r.'</span>,<span class="string">'c.'</span>,<span class="string">'b.'</span>] <span class="comment">#点加颜色配合</span></div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(X)):</div><div class="line">    plt.plot(X[i][<span class="number">0</span>], X[i][<span class="number">1</span>], colors[labels[i]], markersize = <span class="number">25</span>)</div><div class="line"></div><div class="line">plt.scatter(centroids[:,<span class="number">0</span>], centroids[:,<span class="number">1</span>], marker=<span class="string">'x'</span>, s=<span class="number">150</span>, linewidths=<span class="number">5</span>) </div><div class="line">plt.show()</div></pre></td></tr></table></figure><p>结果图表展示：</p><p><img src="http://smartjpa.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-30%20%E4%B8%8B%E5%8D%889.51.36.png" alt=""></p><blockquote><p>还是不错的，有助于理解学习。</p></blockquote><h2 id="用手动实现的K-Means算法训练数据集"><a href="#用手动实现的K-Means算法训练数据集" class="headerlink" title="用手动实现的K-Means算法训练数据集"></a>用手动实现的K-Means算法训练数据集</h2><p>在此将要使用上面实现的K-Means算法来训练上面的<code>titanic</code>数据集，将会输出预测准确性。</p><p>下面是实现的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">K_Means</span><span class="params">()</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, k=<span class="number">2</span>, tol=<span class="number">0.001</span>, max_iter=<span class="number">300</span>)</span>:</span></div><div class="line">        self.k = k</div><div class="line">        self.tol = tol</div><div class="line">        self.max_iter = max_iter <span class="comment">#最大迭代次数</span></div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, data)</span>:</span></div><div class="line">        </div><div class="line">        self.centroids = &#123;&#125; <span class="comment">#质点圆心</span></div><div class="line">        </div><div class="line">        <span class="comment">#取两个作为中心点</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.k):</div><div class="line">            self.centroids[i] = data[i]</div><div class="line">            </div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.max_iter):</div><div class="line">            self.classifications = &#123;&#125;</div><div class="line">            </div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(self.k):</div><div class="line">                self.classifications[i] = []</div><div class="line">            </div><div class="line">            <span class="keyword">for</span> featureset <span class="keyword">in</span> data:</div><div class="line">                <span class="comment">#计算点与点之间的距离,分配数据集进入各自合适的阵营</span></div><div class="line">                distances = [np.linalg.norm(featureset-self.centroids[centroid]) <span class="keyword">for</span> centroid <span class="keyword">in</span> self.centroids]</div><div class="line">                classification = distances.index(min(distances)) <span class="comment">#取最小的距离索引位置点</span></div><div class="line">                self.classifications[classification].append(featureset)</div><div class="line">        </div><div class="line">            prev_centroids = dict(self.centroids) <span class="comment">#保留现在的原数据，之后计算公差要用到</span></div><div class="line">            </div><div class="line">            <span class="keyword">for</span> classification <span class="keyword">in</span> self.classifications:</div><div class="line">                <span class="comment">#得出平均点</span></div><div class="line">                self.centroids[classification] = np.average(self.classifications[classification], axis=<span class="number">0</span>)</div><div class="line">            </div><div class="line">            optimized = <span class="keyword">True</span></div><div class="line">            </div><div class="line">            <span class="keyword">for</span> c <span class="keyword">in</span> self.centroids:</div><div class="line">                original_centroid = prev_centroids[c]</div><div class="line">                current_centroid = self.centroids[c]</div><div class="line">                <span class="keyword">if</span> np.sum((current_centroid - original_centroid)/original_centroid*<span class="number">100.0</span>) &gt; self.tol:</div><div class="line">                    print(np.sum((current_centroid - original_centroid)/original_centroid*<span class="number">100</span>))</div><div class="line">                    optimized = <span class="keyword">False</span></div><div class="line">                </div><div class="line">            <span class="keyword">if</span> optimized:</div><div class="line">                <span class="keyword">break</span></div><div class="line">                </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, data)</span>:</span></div><div class="line">        <span class="comment">#代入数据集与圆心点进行距离计算，并且进行分类0/1</span></div><div class="line">        distances = [np.linalg.norm(data-self.centroids[centroid]) <span class="keyword">for</span> centroid <span class="keyword">in</span> self.centroids]</div><div class="line">        classification = distances.index(min(distances)) </div><div class="line">        <span class="keyword">return</span> classification</div><div class="line"></div><div class="line">df = pd.read_excel(<span class="string">'titanic.xls'</span>)</div><div class="line"></div><div class="line"><span class="comment">#简单的数据预处理</span></div><div class="line">df.drop([<span class="string">'body'</span>,<span class="string">'name'</span>], <span class="number">1</span>, inplace=<span class="keyword">True</span>)</div><div class="line">df.fillna(<span class="number">0</span>, inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line"><span class="comment">#处理非数值数据</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">handle_non_numerical_data</span><span class="params">(df)</span>:</span></div><div class="line">    columns = df.columns.values</div><div class="line">    </div><div class="line">    <span class="keyword">for</span> column <span class="keyword">in</span> columns: <span class="comment">#取出各个列名作为遍历的基调</span></div><div class="line">        text_digit_vals = &#123;&#125;</div><div class="line">        <span class="function"><span class="keyword">def</span> <span class="title">convert_to_int</span><span class="params">(val)</span>:</span></div><div class="line">            <span class="keyword">return</span> text_digit_vals[val]</div><div class="line">        </div><div class="line">        <span class="keyword">if</span> df[column].dtype != np.int64 <span class="keyword">and</span> df[column].dtype != np.float64:</div><div class="line">            column_contents = df[column].values.tolist() <span class="comment">#转换为列表类型以便下方处理</span></div><div class="line">            unique_elements = set(column_contents) <span class="comment">#去掉重复值</span></div><div class="line">            x = <span class="number">0</span></div><div class="line">            <span class="keyword">for</span> unique <span class="keyword">in</span> unique_elements:</div><div class="line">                <span class="keyword">if</span> unique <span class="keyword">not</span> <span class="keyword">in</span> text_digit_vals:</div><div class="line">                    text_digit_vals[unique] = x <span class="comment">#即在此将非数值的数据改为了数值型数据集</span></div><div class="line">                    x+=<span class="number">1</span></div><div class="line">                    </div><div class="line">            df[column] = list(map(convert_to_int, df[column])) <span class="comment">#将列名替代掉上面的unique非数值列名</span></div><div class="line">            </div><div class="line">    <span class="keyword">return</span> df</div><div class="line"></div><div class="line">df = handle_non_numerical_data(df)</div><div class="line"></div><div class="line">df.drop([<span class="string">'sex'</span>,<span class="string">'boat'</span>], <span class="number">1</span>, inplace=<span class="keyword">True</span>)</div><div class="line">X = np.array(df.drop([<span class="string">'survived'</span>], <span class="number">1</span>).astype(float))</div><div class="line">X = preprocessing.scale(X) <span class="comment">#进行缩放，标准化</span></div><div class="line">y = np.array(df[<span class="string">'survived'</span>])</div><div class="line"></div><div class="line">clf = K_Means()</div><div class="line">clf.fit(X)</div><div class="line"></div><div class="line">correct = <span class="number">0</span></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(X)):</div><div class="line">    predic_me = np.array(X[i].astype(float))</div><div class="line">    predic_me = predic_me.reshape(<span class="number">-1</span>, len(predic_me))</div><div class="line">    prediction = clf.predict(predic_me)</div><div class="line">    <span class="keyword">if</span> prediction == y[i]:</div><div class="line">        correct += <span class="number">1</span></div><div class="line"></div><div class="line">print(correct/len(X))</div></pre></td></tr></table></figure><p>只是上面代码的连接罢了，代码本身也不难理解。</p><p>下面是输出的预测准确性：</p><p><img src="http://smartjpa.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-30%20%E4%B8%8B%E5%8D%889.31.38.png" alt=""></p><blockquote><p>额…效果不咋地…</p></blockquote><p>这样一来这篇文章可以接近尾声了…不懂的地方可以去对应的课程去看看，还有的是，多看书，利用好搜索引擎。</p>]]></content>
    
    <summary type="html">
    
      &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/ZueoXMgCd1c&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; encrypted-media&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;ul&gt;
&lt;li&gt;对应的课程地址：&lt;a href=&quot;https://pythonprogramming.net/machine-learning-clustering-introduction-machine-learning-tutorial/?completed=/support-vector-machine-parameters-machine-learning-tutorial/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://pythonprogramming.net/machine-learning-clustering-introduction-machine-learning-tutorial/?completed=/support-vector-machine-parameters-machine-learning-tutorial/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;K-均值算法(K-Means)属于无监督学习、聚类算法。即将无标签的数据集进行分类，并且无训练过程(监督学习的数据集才存在训练一说)等，又可理解为&lt;code&gt;自动分类器&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;本文对于原作者的代码进行了一点修改以符合当今情况。&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/categories/Python/"/>
    
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>关于在Mac下的python文字转语音库pyttsx3</title>
    <link href="https://liujunjie11.github.io/2018/10/23/%E5%85%B3%E4%BA%8E%E5%9C%A8Mac%E4%B8%8B%E7%9A%84python%E6%96%87%E5%AD%97%E8%BD%AC%E8%AF%AD%E9%9F%B3%E5%BA%93pyttsx3/"/>
    <id>https://liujunjie11.github.io/2018/10/23/关于在Mac下的python文字转语音库pyttsx3/</id>
    <published>2018-10-23T13:29:17.000Z</published>
    <updated>2018-11-13T12:32:08.464Z</updated>
    
    <content type="html"><![CDATA[<p>最近写python机器学习教程有点累了..就玩一些其他的东西，就包括了这个文字转语音的python3库<em>pyttsx3</em>。</p><p>其中也遇到了一些问题，在此记录一下。</p><a id="more"></a><h1 id="关于下载运行的问题"><a href="#关于下载运行的问题" class="headerlink" title="关于下载运行的问题"></a>关于下载运行的问题</h1><p>在使用命令行<code>pip install pyttsx3</code>下载之后，我在终端写下了如下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pyttsx3</div><div class="line">engine = pyttsx3.init()</div></pre></td></tr></table></figure><p>结果出现了<code>No module named &#39;Foundation&#39;</code>的错误问题。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>下载模块<code>pyobjc</code>.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install pyobjc</div></pre></td></tr></table></figure><p>估计是跟调用系统一些模块有关，毕竟这个库是跟macOS关系还是挺深的…自行了解，没想到这个库可以调用Objective-C的库来进行macOS上的应用程序开发…</p><p>以下是WiKi的解释：</p><blockquote><p>PyObjC是Python和Objective-C编程语言之间的双向桥梁，允许程序员使用Python扩展现有的Objective-C库，例如Apple的Cocoa框架。 PyObjC用于在纯Python中开发macOS应用程序。 对GNUstep的支持也很有限，GNUstep是Cocoa的开源，跨平台实现。</p></blockquote><p>下载完成这个库之后，再运行上面的代码就没有出错了。</p><ul><li>参考链接：<a href="https://blog.csdn.net/noway5456/article/details/78905275" target="_blank" rel="external">https://blog.csdn.net/noway5456/article/details/78905275</a></li></ul><h1 id="关于pyttsx3读中文字的问题"><a href="#关于pyttsx3读中文字的问题" class="headerlink" title="关于pyttsx3读中文字的问题"></a>关于pyttsx3读中文字的问题</h1><p>这个问题其实是跟系统的语音设置相关的，看下图吧。</p><p>我在系统默认的语音类型(在图中两者之间切换)：</p><p><img src="http://smartjpa.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-23%20%E4%B8%8B%E5%8D%889.24.59.png" alt=""></p><p>然后又用代码查看<em>pyttsx3</em>的对应默认声音：</p><p><img src="http://smartjpa.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-23%20%E4%B8%8B%E5%8D%889.24.30.png" alt=""></p><p>发现了其实pyttsx3的语音是根据本地语音相关的，这又一步说明为何要安装<code>pyobjc</code>这个铺助模块的意义。</p><p>在读取英文或中文时，设置一下本地的默认语音即可。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近写python机器学习教程有点累了..就玩一些其他的东西，就包括了这个文字转语音的python3库&lt;em&gt;pyttsx3&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;其中也遇到了一些问题，在此记录一下。&lt;/p&gt;
    
    </summary>
    
      <category term="笔记" scheme="https://liujunjie11.github.io/categories/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/categories/Python/"/>
    
    
      <category term="Python" scheme="https://liujunjie11.github.io/tags/Python/"/>
    
      <category term="问题记录笔记" scheme="https://liujunjie11.github.io/tags/%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95%E7%AC%94%E8%AE%B0/"/>
    
      <category term="Pyttsx3" scheme="https://liujunjie11.github.io/tags/Pyttsx3/"/>
    
  </entry>
  
  <entry>
    <title>python机器学习系列：支持向量机(SVM)的应用以及实现</title>
    <link href="https://liujunjie11.github.io/2018/10/23/python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%9A%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA-SVM-%E7%9A%84%E5%BA%94%E7%94%A8%E4%BB%A5%E5%8F%8A%E5%AE%9E%E7%8E%B0/"/>
    <id>https://liujunjie11.github.io/2018/10/23/python机器学习系列：支持向量机-SVM-的应用以及实现/</id>
    <published>2018-10-23T01:44:10.000Z</published>
    <updated>2018-11-13T12:32:18.893Z</updated>
    
    <content type="html"><![CDATA[<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/HHUqhVzctQE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe><p>我记录下的这些东西，如果是有哪些不懂得地方，我强烈建议参考我在<a href="http://liujunworld.com/2018/09/16/%E5%88%9D%E5%AD%A6%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8D%97/" target="_blank" rel="external">这里的书籍</a>。另外还有<a href="https://github.com/apachecn/AiLearning" target="_blank" rel="external">《机器学习实战》</a>，<a href="https://github.com/exacity/deeplearningbook-chinese" target="_blank" rel="external">《深度学习》</a>这本花书等，利用好搜索引擎也是一大好利器。</p><p>关于这篇文章，我还是和以前记录相关的机器学习知识之类篇章一样的风格。</p><p>不懂可进入<a href="https://pythonprogramming.net/support-vector-machine-intro-machine-learning-tutorial/?completed=/final-thoughts-knn-machine-learning-tutorial/" target="_blank" rel="external">这里的对应的教程</a>，看不懂可借助翻译插件/软件(实际上借助这些看起来轻松多了，看英文头疼的厉害，如果是对于初学者)。</p><a id="more"></a><h1 id="SVM的实现"><a href="#SVM的实现" class="headerlink" title="SVM的实现"></a>SVM的实现</h1><p>SVM算法是有一点难理解的，但是坚持看一些文章和上面说的那些书籍之后就会发现其实也就那么回事。</p><p>关于SVM的实现(仅作通俗说明，以二维为例)：由于这个算法是根据支持向量得出两个函数，而我们取的是这两条线性函数的距离的中间值，从而得到了决策边界函数，这样任务也就完成了。但是由于参数的不同，取这个决策边界是可以有多个甚至是无穷个的，那么取得最优的参数是可以利用梯度下降算法的(符合凸二次规划)。得到了最优的参数就可以得出决策边界的函数了。</p><blockquote><p>涉及到不少的数学知识…我想我大概是说对了吧，哈哈…</p></blockquote><p>为了实现这个算法，必须要提前了解这算法相关的知识，不然真的是寸步难行啊。</p><p>下面是铺助理解链接，不懂还要翻书看吴恩达老师的教程：</p><ul><li><p><a href="https://zh.wikipedia.org/wiki/二次规划" target="_blank" rel="external">二次规划</a></p></li><li><p><a href="http://www.sohu.com/a/206572358_160850" target="_blank" rel="external">干货 | 从超平面到SVM（一）</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/26514613" target="_blank" rel="external">浅谈最优化问题的KKT条件</a></p></li></ul><p>以下就是完整的实现代码了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Support_Vector_Machine</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, visualization=True)</span>:</span></div><div class="line">        self.visualization = visualization</div><div class="line">        self.colors = &#123;<span class="number">1</span>:<span class="string">'r'</span>, <span class="number">-1</span>:<span class="string">'b'</span>&#125;</div><div class="line">        <span class="keyword">if</span> self.visualization:</div><div class="line">            self.fig = plt.figure()</div><div class="line">            self.ax = self.fig.add_subplot(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>)</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, data)</span>:</span></div><div class="line">        self.data = data</div><div class="line">        opt_dict = &#123;&#125;</div><div class="line">        </div><div class="line">        transforms = [[<span class="number">1</span>,<span class="number">1</span>],</div><div class="line">                      [<span class="number">-1</span>,<span class="number">1</span>],</div><div class="line">                      [<span class="number">-1</span>,<span class="number">-1</span>],</div><div class="line">                      [<span class="number">1</span>,<span class="number">-1</span>]]</div><div class="line">        </div><div class="line">        all_data = []</div><div class="line">        <span class="keyword">for</span> yi <span class="keyword">in</span> self.data:</div><div class="line">            <span class="keyword">for</span> featureset <span class="keyword">in</span> self.data[yi]:</div><div class="line">                <span class="keyword">for</span> feature <span class="keyword">in</span> featureset:</div><div class="line">                    all_data.append(feature)</div><div class="line">        </div><div class="line">        self.max_feature_value = max(all_data)</div><div class="line">        self.min_feature_value = min(all_data)</div><div class="line">        all_data = <span class="keyword">None</span></div><div class="line">        </div><div class="line">        <span class="comment">#指定梯度下降的步子大小</span></div><div class="line">        step_sizes = [self.max_feature_value * <span class="number">0.1</span>,</div><div class="line">                      self.max_feature_value * <span class="number">0.01</span>,</div><div class="line">                      self.max_feature_value * <span class="number">0.001</span>,]</div><div class="line">        </div><div class="line">        <span class="comment">#b的假设大小，最为重要的是参数w，而不是参数b </span></div><div class="line">        b_range_multiple = <span class="number">2</span></div><div class="line">        b_multiple =<span class="number">5</span></div><div class="line">        latest_optimum = self.max_feature_value*<span class="number">10</span> <span class="comment">#最大的步子</span></div><div class="line">        </div><div class="line">        <span class="keyword">for</span> step <span class="keyword">in</span> step_sizes:</div><div class="line">            w = np.array([latest_optimum, latest_optimum])</div><div class="line">            optimized = <span class="keyword">False</span></div><div class="line">            <span class="keyword">while</span> <span class="keyword">not</span> optimized:</div><div class="line">                <span class="keyword">for</span> b <span class="keyword">in</span> np.arange(<span class="number">-1</span>*(self.max_feature_value * b_range_multiple),</div><div class="line">                                   self.max_feature_value * b_range_multiple,</div><div class="line">                                   step * b_multiple):</div><div class="line">                    <span class="keyword">for</span> transformation <span class="keyword">in</span> transforms:</div><div class="line">                        w_t = w*transformation</div><div class="line">                        found_option = <span class="keyword">True</span></div><div class="line">                        </div><div class="line">                        <span class="keyword">for</span> i <span class="keyword">in</span> self.data:</div><div class="line">                            <span class="keyword">for</span> xi <span class="keyword">in</span> self.data[i]:</div><div class="line">                                yi = i</div><div class="line">                                <span class="keyword">if</span> <span class="keyword">not</span> yi*(np.dot(w_t, xi)+b) &gt;= <span class="number">1</span>:</div><div class="line">                                    found_option = <span class="keyword">False</span></div><div class="line">                        </div><div class="line">                        <span class="comment">#如果约束优化条件成立</span></div><div class="line">                        <span class="keyword">if</span> found_option:</div><div class="line">                            opt_dict[np.linalg.norm(w_t)] = [w_t, b]</div><div class="line">                </div><div class="line">                <span class="comment">#若是值为负数则停止进一步的优化步子</span></div><div class="line">                <span class="keyword">if</span> w[<span class="number">0</span>] &lt;<span class="number">0</span>:</div><div class="line">                    optimized = <span class="keyword">True</span></div><div class="line">                    print(<span class="string">'Optimized a step.'</span>)</div><div class="line">                <span class="keyword">else</span>:</div><div class="line">                    w = w - step</div><div class="line">            norms = sorted([n <span class="keyword">for</span> n <span class="keyword">in</span> opt_dict])</div><div class="line">            </div><div class="line">            opt_choice = opt_dict[norms[<span class="number">0</span>]]</div><div class="line">            self.w = opt_choice[<span class="number">0</span>]</div><div class="line">            self.b = opt_choice[<span class="number">1</span>]</div><div class="line">            latest_optimum = opt_choice[<span class="number">0</span>][<span class="number">0</span>]+step*<span class="number">2</span></div><div class="line">            </div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> self.data:</div><div class="line">            <span class="keyword">for</span> xi <span class="keyword">in</span> self.data[i]:</div><div class="line">                yi = i</div><div class="line">                print(xi, <span class="string">':'</span>, yi*(np.dot(self.w, xi)+self.b))</div><div class="line">            </div><div class="line">    <span class="comment">#预测部分</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, features)</span>:</span></div><div class="line">        classification = np.sign(np.dot(np.array(features), self.w)+self.b)</div><div class="line">        <span class="keyword">if</span> classification != <span class="number">0</span> <span class="keyword">and</span> self.visualization:</div><div class="line">            self.ax.scatter(features[<span class="number">0</span>], features[<span class="number">1</span>], s=<span class="number">200</span>, marker=<span class="string">'*'</span>, c=self.colors[classification])</div><div class="line">        </div><div class="line">        <span class="keyword">return</span> classification</div><div class="line">    </div><div class="line">    <span class="comment">#可视化部分</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">visualize</span><span class="params">(self)</span>:</span></div><div class="line">        [[self.ax.scatter(x[<span class="number">0</span>], x[<span class="number">1</span>], s=<span class="number">100</span>, color=self.colors[i]) <span class="keyword">for</span> x <span class="keyword">in</span> data_dict[i]] <span class="keyword">for</span> i <span class="keyword">in</span> data_dict]</div><div class="line">        </div><div class="line">        <span class="function"><span class="keyword">def</span> <span class="title">hyperplane</span><span class="params">(x, w, b, v)</span>:</span></div><div class="line">            <span class="keyword">return</span> (-w[<span class="number">0</span>]*x-b+v) / w[<span class="number">1</span>]</div><div class="line">        </div><div class="line">        datarange = (self.min_feature_value*<span class="number">0.9</span>, self.max_feature_value*<span class="number">1.1</span>)</div><div class="line">        hyp_x_min = datarange[<span class="number">0</span>]</div><div class="line">        hyp_x_max = datarange[<span class="number">1</span>]</div><div class="line">        </div><div class="line">        psv1 = hyperplane(hyp_x_min, self.w, self.b, <span class="number">1</span>)</div><div class="line">        psv2 = hyperplane(hyp_x_max, self.w, self.b, <span class="number">1</span>)</div><div class="line">        self.ax.plot([hyp_x_min, hyp_x_max], [psv1,psv2], <span class="string">'k'</span>)</div><div class="line">        </div><div class="line">        nsv1 = hyperplane(hyp_x_min, self.w, self.b, <span class="number">-1</span>)</div><div class="line">        nsv2 = hyperplane(hyp_x_max, self.w, self.b, <span class="number">-1</span>)</div><div class="line">        self.ax.plot([hyp_x_min, hyp_x_max], [nsv1,nsv2], <span class="string">'k'</span>)</div><div class="line">        </div><div class="line">        db1 = hyperplane(hyp_x_min, self.w, self.b, <span class="number">0</span>)</div><div class="line">        db2 = hyperplane(hyp_x_max, self.w, self.b, <span class="number">0</span>)</div><div class="line">        self.ax.plot([hyp_x_min, hyp_x_max], [db1, db2], <span class="string">'y--'</span>)</div><div class="line">        </div><div class="line">        plt.show()</div></pre></td></tr></table></figure><p>铺助理解链接：</p><ul><li><p><a href="https://blog.csdn.net/qianwenhong/article/details/41414809" target="_blank" rel="external">Python 中的range(),arange()函数</a></p></li><li><p><a href="https://www.cnblogs.com/hezhiyao/p/8649231.html" target="_blank" rel="external">python中np.multiply（）、np.dot（）和星号（*）三种乘法运算的区别（转）</a></p></li></ul><h2 id="简要数据集预测以及结果可视化"><a href="#简要数据集预测以及结果可视化" class="headerlink" title="简要数据集预测以及结果可视化"></a>简要数据集预测以及结果可视化</h2><p>以下是完整代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Support_Vector_Machine</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, visualization=True)</span>:</span></div><div class="line">        self.visualization = visualization</div><div class="line">        self.colors = &#123;<span class="number">1</span>:<span class="string">'r'</span>, <span class="number">-1</span>:<span class="string">'b'</span>&#125;</div><div class="line">        <span class="keyword">if</span> self.visualization:</div><div class="line">            self.fig = plt.figure()</div><div class="line">            self.ax = self.fig.add_subplot(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>)</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, data)</span>:</span></div><div class="line">        self.data = data</div><div class="line">        opt_dict = &#123;&#125;</div><div class="line">        </div><div class="line">        transforms = [[<span class="number">1</span>,<span class="number">1</span>],</div><div class="line">                      [<span class="number">-1</span>,<span class="number">1</span>],</div><div class="line">                      [<span class="number">-1</span>,<span class="number">-1</span>],</div><div class="line">                      [<span class="number">1</span>,<span class="number">-1</span>]]</div><div class="line">        </div><div class="line">        all_data = []</div><div class="line">        <span class="keyword">for</span> yi <span class="keyword">in</span> self.data:</div><div class="line">            <span class="keyword">for</span> featureset <span class="keyword">in</span> self.data[yi]:</div><div class="line">                <span class="keyword">for</span> feature <span class="keyword">in</span> featureset:</div><div class="line">                    all_data.append(feature)</div><div class="line">        </div><div class="line">        self.max_feature_value = max(all_data)</div><div class="line">        self.min_feature_value = min(all_data)</div><div class="line">        all_data = <span class="keyword">None</span></div><div class="line">        </div><div class="line">        <span class="comment">#指定梯度下降的步子大小</span></div><div class="line">        step_sizes = [self.max_feature_value * <span class="number">0.1</span>,</div><div class="line">                      self.max_feature_value * <span class="number">0.01</span>,</div><div class="line">                      self.max_feature_value * <span class="number">0.001</span>,]</div><div class="line">        </div><div class="line">        <span class="comment">#b的假设大小，最为重要的是参数w，而不是参数b </span></div><div class="line">        b_range_multiple = <span class="number">2</span></div><div class="line">        b_multiple =<span class="number">5</span></div><div class="line">        latest_optimum = self.max_feature_value*<span class="number">10</span> <span class="comment">#最大的步子</span></div><div class="line">        </div><div class="line">        <span class="keyword">for</span> step <span class="keyword">in</span> step_sizes:</div><div class="line">            w = np.array([latest_optimum, latest_optimum])</div><div class="line">            optimized = <span class="keyword">False</span></div><div class="line">            <span class="keyword">while</span> <span class="keyword">not</span> optimized:</div><div class="line">                <span class="keyword">for</span> b <span class="keyword">in</span> np.arange(<span class="number">-1</span>*(self.max_feature_value * b_range_multiple),</div><div class="line">                                   self.max_feature_value * b_range_multiple,</div><div class="line">                                   step * b_multiple):</div><div class="line">                    <span class="keyword">for</span> transformation <span class="keyword">in</span> transforms:</div><div class="line">                        w_t = w*transformation</div><div class="line">                        found_option = <span class="keyword">True</span></div><div class="line">                        </div><div class="line">                        <span class="keyword">for</span> i <span class="keyword">in</span> self.data:</div><div class="line">                            <span class="keyword">for</span> xi <span class="keyword">in</span> self.data[i]:</div><div class="line">                                yi = i</div><div class="line">                                <span class="keyword">if</span> <span class="keyword">not</span> yi*(np.dot(w_t, xi)+b) &gt;= <span class="number">1</span>:</div><div class="line">                                    found_option = <span class="keyword">False</span></div><div class="line">                        </div><div class="line">                        <span class="comment">#如果约束优化条件成立</span></div><div class="line">                        <span class="keyword">if</span> found_option:</div><div class="line">                            opt_dict[np.linalg.norm(w_t)] = [w_t, b]</div><div class="line">                </div><div class="line">                <span class="comment">#若是值为负数则停止进一步的优化步子</span></div><div class="line">                <span class="keyword">if</span> w[<span class="number">0</span>] &lt;<span class="number">0</span>:</div><div class="line">                    optimized = <span class="keyword">True</span></div><div class="line">                    print(<span class="string">'Optimized a step.'</span>)</div><div class="line">                <span class="keyword">else</span>:</div><div class="line">                    w = w - step</div><div class="line">            norms = sorted([n <span class="keyword">for</span> n <span class="keyword">in</span> opt_dict])</div><div class="line">            </div><div class="line">            opt_choice = opt_dict[norms[<span class="number">0</span>]]</div><div class="line">            self.w = opt_choice[<span class="number">0</span>]</div><div class="line">            self.b = opt_choice[<span class="number">1</span>]</div><div class="line">            latest_optimum = opt_choice[<span class="number">0</span>][<span class="number">0</span>]+step*<span class="number">2</span></div><div class="line">            </div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> self.data:</div><div class="line">            <span class="keyword">for</span> xi <span class="keyword">in</span> self.data[i]:</div><div class="line">                yi = i</div><div class="line">                print(xi, <span class="string">':'</span>, yi*(np.dot(self.w, xi)+self.b))</div><div class="line">            </div><div class="line">    <span class="comment">#预测部分</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, features)</span>:</span></div><div class="line">        classification = np.sign(np.dot(np.array(features), self.w)+self.b)</div><div class="line">        <span class="keyword">if</span> classification != <span class="number">0</span> <span class="keyword">and</span> self.visualization:</div><div class="line">            self.ax.scatter(features[<span class="number">0</span>], features[<span class="number">1</span>], s=<span class="number">200</span>, marker=<span class="string">'*'</span>, c=self.colors[classification])</div><div class="line">        </div><div class="line">        <span class="keyword">return</span> classification</div><div class="line">    </div><div class="line">    <span class="comment">#可视化部分</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">visualize</span><span class="params">(self)</span>:</span></div><div class="line">        [[self.ax.scatter(x[<span class="number">0</span>], x[<span class="number">1</span>], s=<span class="number">100</span>, color=self.colors[i]) <span class="keyword">for</span> x <span class="keyword">in</span> data_dict[i]] <span class="keyword">for</span> i <span class="keyword">in</span> data_dict]</div><div class="line">        </div><div class="line">        <span class="function"><span class="keyword">def</span> <span class="title">hyperplane</span><span class="params">(x, w, b, v)</span>:</span></div><div class="line">            <span class="keyword">return</span> (-w[<span class="number">0</span>]*x-b+v) / w[<span class="number">1</span>]</div><div class="line">        </div><div class="line">        datarange = (self.min_feature_value*<span class="number">0.9</span>, self.max_feature_value*<span class="number">1.1</span>)</div><div class="line">        hyp_x_min = datarange[<span class="number">0</span>]</div><div class="line">        hyp_x_max = datarange[<span class="number">1</span>]</div><div class="line">        </div><div class="line">        psv1 = hyperplane(hyp_x_min, self.w, self.b, <span class="number">1</span>)</div><div class="line">        psv2 = hyperplane(hyp_x_max, self.w, self.b, <span class="number">1</span>)</div><div class="line">        self.ax.plot([hyp_x_min, hyp_x_max], [psv1,psv2], <span class="string">'k'</span>)</div><div class="line">        </div><div class="line">        nsv1 = hyperplane(hyp_x_min, self.w, self.b, <span class="number">-1</span>)</div><div class="line">        nsv2 = hyperplane(hyp_x_max, self.w, self.b, <span class="number">-1</span>)</div><div class="line">        self.ax.plot([hyp_x_min, hyp_x_max], [nsv1,nsv2], <span class="string">'k'</span>)</div><div class="line">        </div><div class="line">        db1 = hyperplane(hyp_x_min, self.w, self.b, <span class="number">0</span>)</div><div class="line">        db2 = hyperplane(hyp_x_max, self.w, self.b, <span class="number">0</span>)</div><div class="line">        self.ax.plot([hyp_x_min, hyp_x_max], [db1, db2], <span class="string">'y--'</span>)</div><div class="line">        </div><div class="line">        plt.show()</div><div class="line"></div><div class="line"><span class="comment">#训练数据集</span></div><div class="line">data_dict = &#123;<span class="number">-1</span>:np.array([[<span class="number">1</span>,<span class="number">7</span>],</div><div class="line">                          [<span class="number">2</span>,<span class="number">8</span>],</div><div class="line">                          [<span class="number">3</span>,<span class="number">8</span>],]),</div><div class="line">             </div><div class="line">             <span class="number">1</span>:np.array([[<span class="number">5</span>,<span class="number">1</span>],</div><div class="line">                         [<span class="number">6</span>,<span class="number">-1</span>],</div><div class="line">                         [<span class="number">7</span>,<span class="number">3</span>],])&#125;</div><div class="line"></div><div class="line">svm = Support_Vector_Machine()</div><div class="line">svm.fit(data=data_dict)</div><div class="line"></div><div class="line"><span class="comment">#预测数据集</span></div><div class="line">predict_us = [[<span class="number">0</span>,<span class="number">10</span>],</div><div class="line">              [<span class="number">1</span>,<span class="number">3</span>],</div><div class="line">              [<span class="number">3</span>,<span class="number">4</span>],</div><div class="line">              [<span class="number">3</span>,<span class="number">5</span>],</div><div class="line">              [<span class="number">5</span>,<span class="number">5</span>],</div><div class="line">              [<span class="number">5</span>,<span class="number">6</span>],</div><div class="line">              [<span class="number">6</span>,<span class="number">-5</span>],</div><div class="line">              [<span class="number">5</span>,<span class="number">8</span>]]</div><div class="line"></div><div class="line"><span class="keyword">for</span> p <span class="keyword">in</span> predict_us:</div><div class="line">    svm.predict(p)</div><div class="line"></div><div class="line">svm.visualize()</div></pre></td></tr></table></figure><p>这样一来就完成了算法的实现了，可视化的图表如下：</p><p><img src="http://smartjpa.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-26%20%E4%B8%8B%E5%8D%887.49.15.png" alt=""></p><blockquote><p>实际上这只是算法的简单实现，许多的细节并没有照顾到。而且这个算法的基础必须要牢固，不然很难理解上面的代码。</p></blockquote><h1 id="SVM进阶"><a href="#SVM进阶" class="headerlink" title="SVM进阶"></a>SVM进阶</h1><p>相关到<code>核函数</code>，<code>硬间隔最大化</code>，<code>软间隔最大化</code>等知识，其中的<code>核函数</code>，<code>软间隔最大化</code>针对于非线性数据(即线性不可分)，<code>硬间隔最大化</code>针对于线性可分数据类型，这需要自行去了解、理解。在上面说的书籍中可以找到相关的知识。</p><p>以下是关于<code>核函数</code>，<code>软间隔最大化</code>的针对于非线性数据python代码的实现，可以理解为SVM的底层实现的一部分，可以更好的理解内部实现的于原理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div><div class="line">251</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Mathieu Blondel, September 2010</span></div><div class="line"><span class="comment"># License: BSD 3 clause</span></div><div class="line"><span class="comment"># http://www.mblondel.org/journal/2010/09/19/support-vector-machines-in-python/</span></div><div class="line"></div><div class="line"><span class="comment"># visualizing what translating to another dimension does</span></div><div class="line"><span class="comment"># and bringing back to 2D:</span></div><div class="line"><span class="comment"># https://www.youtube.com/watch?v=3liCbRZPrZA</span></div><div class="line"></div><div class="line"><span class="comment"># Docs: http://cvxopt.org/userguide/coneprog.html#quadratic-programming</span></div><div class="line"><span class="comment"># Docs qp example: http://cvxopt.org/examples/tutorial/qp.html</span></div><div class="line"></div><div class="line"><span class="comment"># Nice tutorial:</span></div><div class="line"><span class="comment"># https://courses.csail.mit.edu/6.867/wiki/images/a/a7/Qp-cvxopt.pdf</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> linalg</div><div class="line"><span class="keyword">import</span> cvxopt</div><div class="line"><span class="keyword">import</span> cvxopt.solvers</div><div class="line">             </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_kernel</span><span class="params">(x1, x2)</span>:</span></div><div class="line">    <span class="keyword">return</span> np.dot(x1, x2)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">polynomial_kernel</span><span class="params">(x, y, p=<span class="number">3</span>)</span>:</span></div><div class="line">    <span class="keyword">return</span> (<span class="number">1</span> + np.dot(x, y)) ** p</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">gaussian_kernel</span><span class="params">(x, y, sigma=<span class="number">5.0</span>)</span>:</span></div><div class="line">    <span class="keyword">return</span> np.exp(-linalg.norm(x-y)**<span class="number">2</span> / (<span class="number">2</span> * (sigma ** <span class="number">2</span>)))</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">SVM</span><span class="params">(object)</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, kernel=linear_kernel, C=None)</span>:</span></div><div class="line">        self.kernel = kernel</div><div class="line">        self.C = C</div><div class="line">        <span class="keyword">if</span> self.C <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>: self.C = float(self.C)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y)</span>:</span></div><div class="line">        n_samples, n_features = X.shape</div><div class="line"></div><div class="line">        <span class="comment"># Gram matrix</span></div><div class="line">        K = np.zeros((n_samples, n_samples))</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(n_samples):</div><div class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(n_samples):</div><div class="line">                K[i,j] = self.kernel(X[i], X[j])</div><div class="line"></div><div class="line">        P = cvxopt.matrix(np.outer(y,y) * K)</div><div class="line">        q = cvxopt.matrix(np.ones(n_samples) * <span class="number">-1</span>)</div><div class="line">        A = cvxopt.matrix(y, (<span class="number">1</span>,n_samples))</div><div class="line">        b = cvxopt.matrix(<span class="number">0.0</span>)</div><div class="line"></div><div class="line">        <span class="keyword">if</span> self.C <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            G = cvxopt.matrix(np.diag(np.ones(n_samples) * <span class="number">-1</span>))</div><div class="line">            h = cvxopt.matrix(np.zeros(n_samples))</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            tmp1 = np.diag(np.ones(n_samples) * <span class="number">-1</span>)</div><div class="line">            tmp2 = np.identity(n_samples)</div><div class="line">            G = cvxopt.matrix(np.vstack((tmp1, tmp2)))</div><div class="line">            tmp1 = np.zeros(n_samples)</div><div class="line">            tmp2 = np.ones(n_samples) * self.C</div><div class="line">            h = cvxopt.matrix(np.hstack((tmp1, tmp2)))</div><div class="line"></div><div class="line">        <span class="comment"># solve QP problem</span></div><div class="line">        solution = cvxopt.solvers.qp(P, q, G, h, A, b)</div><div class="line"></div><div class="line">        <span class="comment"># Lagrange multipliers</span></div><div class="line">        a = np.ravel(solution[<span class="string">'x'</span>])</div><div class="line"></div><div class="line">        <span class="comment"># Support vectors have non zero lagrange multipliers</span></div><div class="line">        sv = a &gt; <span class="number">1e-5</span></div><div class="line">        ind = np.arange(len(a))[sv]</div><div class="line">        self.a = a[sv]</div><div class="line">        self.sv = X[sv]</div><div class="line">        self.sv_y = y[sv]</div><div class="line">        print(<span class="string">"%d support vectors out of %d points"</span> % (len(self.a), n_samples))</div><div class="line"></div><div class="line">        <span class="comment"># Intercept</span></div><div class="line">        self.b = <span class="number">0</span></div><div class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> range(len(self.a)):</div><div class="line">            self.b += self.sv_y[n]</div><div class="line">            self.b -= np.sum(self.a * self.sv_y * K[ind[n],sv])</div><div class="line">        self.b /= len(self.a)</div><div class="line"></div><div class="line">        <span class="comment"># Weight vector</span></div><div class="line">        <span class="keyword">if</span> self.kernel == linear_kernel:</div><div class="line">            self.w = np.zeros(n_features)</div><div class="line">            <span class="keyword">for</span> n <span class="keyword">in</span> range(len(self.a)):</div><div class="line">                self.w += self.a[n] * self.sv_y[n] * self.sv[n]</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            self.w = <span class="keyword">None</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">project</span><span class="params">(self, X)</span>:</span></div><div class="line">        <span class="keyword">if</span> self.w <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">            <span class="keyword">return</span> np.dot(X, self.w) + self.b</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            y_predict = np.zeros(len(X))</div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(X)):</div><div class="line">                s = <span class="number">0</span></div><div class="line">                <span class="keyword">for</span> a, sv_y, sv <span class="keyword">in</span> zip(self.a, self.sv_y, self.sv):</div><div class="line">                    s += a * sv_y * self.kernel(X[i], sv)</div><div class="line">                y_predict[i] = s</div><div class="line">            <span class="keyword">return</span> y_predict + self.b</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X)</span>:</span></div><div class="line">        <span class="keyword">return</span> np.sign(self.project(X))</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">    <span class="keyword">import</span> pylab <span class="keyword">as</span> pl</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gen_lin_separable_data</span><span class="params">()</span>:</span></div><div class="line">        <span class="comment"># generate training data in the 2-d case</span></div><div class="line">        mean1 = np.array([<span class="number">0</span>, <span class="number">2</span>])</div><div class="line">        mean2 = np.array([<span class="number">2</span>, <span class="number">0</span>])</div><div class="line">        cov = np.array([[<span class="number">0.8</span>, <span class="number">0.6</span>], [<span class="number">0.6</span>, <span class="number">0.8</span>]])</div><div class="line">        X1 = np.random.multivariate_normal(mean1, cov, <span class="number">100</span>)</div><div class="line">        y1 = np.ones(len(X1))</div><div class="line">        X2 = np.random.multivariate_normal(mean2, cov, <span class="number">100</span>)</div><div class="line">        y2 = np.ones(len(X2)) * <span class="number">-1</span></div><div class="line">        <span class="keyword">return</span> X1, y1, X2, y2</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gen_non_lin_separable_data</span><span class="params">()</span>:</span></div><div class="line">        mean1 = [<span class="number">-1</span>, <span class="number">2</span>]</div><div class="line">        mean2 = [<span class="number">1</span>, <span class="number">-1</span>]</div><div class="line">        mean3 = [<span class="number">4</span>, <span class="number">-4</span>]</div><div class="line">        mean4 = [<span class="number">-4</span>, <span class="number">4</span>]</div><div class="line">        cov = [[<span class="number">1.0</span>,<span class="number">0.8</span>], [<span class="number">0.8</span>, <span class="number">1.0</span>]]</div><div class="line">        X1 = np.random.multivariate_normal(mean1, cov, <span class="number">50</span>)</div><div class="line">        X1 = np.vstack((X1, np.random.multivariate_normal(mean3, cov, <span class="number">50</span>)))</div><div class="line">        y1 = np.ones(len(X1))</div><div class="line">        X2 = np.random.multivariate_normal(mean2, cov, <span class="number">50</span>)</div><div class="line">        X2 = np.vstack((X2, np.random.multivariate_normal(mean4, cov, <span class="number">50</span>)))</div><div class="line">        y2 = np.ones(len(X2)) * <span class="number">-1</span></div><div class="line">        <span class="keyword">return</span> X1, y1, X2, y2</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gen_lin_separable_overlap_data</span><span class="params">()</span>:</span></div><div class="line">        <span class="comment"># generate training data in the 2-d case</span></div><div class="line">        mean1 = np.array([<span class="number">0</span>, <span class="number">2</span>])</div><div class="line">        mean2 = np.array([<span class="number">2</span>, <span class="number">0</span>])</div><div class="line">        cov = np.array([[<span class="number">1.5</span>, <span class="number">1.0</span>], [<span class="number">1.0</span>, <span class="number">1.5</span>]])</div><div class="line">        X1 = np.random.multivariate_normal(mean1, cov, <span class="number">100</span>)</div><div class="line">        y1 = np.ones(len(X1))</div><div class="line">        X2 = np.random.multivariate_normal(mean2, cov, <span class="number">100</span>)</div><div class="line">        y2 = np.ones(len(X2)) * <span class="number">-1</span></div><div class="line">        <span class="keyword">return</span> X1, y1, X2, y2</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">split_train</span><span class="params">(X1, y1, X2, y2)</span>:</span></div><div class="line">        X1_train = X1[:<span class="number">90</span>]</div><div class="line">        y1_train = y1[:<span class="number">90</span>]</div><div class="line">        X2_train = X2[:<span class="number">90</span>]</div><div class="line">        y2_train = y2[:<span class="number">90</span>]</div><div class="line">        X_train = np.vstack((X1_train, X2_train))</div><div class="line">        y_train = np.hstack((y1_train, y2_train))</div><div class="line">        <span class="keyword">return</span> X_train, y_train</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">split_test</span><span class="params">(X1, y1, X2, y2)</span>:</span></div><div class="line">        X1_test = X1[<span class="number">90</span>:]</div><div class="line">        y1_test = y1[<span class="number">90</span>:]</div><div class="line">        X2_test = X2[<span class="number">90</span>:]</div><div class="line">        y2_test = y2[<span class="number">90</span>:]</div><div class="line">        X_test = np.vstack((X1_test, X2_test))</div><div class="line">        y_test = np.hstack((y1_test, y2_test))</div><div class="line">        <span class="keyword">return</span> X_test, y_test</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">plot_margin</span><span class="params">(X1_train, X2_train, clf)</span>:</span></div><div class="line">        <span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(x, w, b, c=<span class="number">0</span>)</span>:</span></div><div class="line">            <span class="comment"># given x, return y such that [x,y] in on the line</span></div><div class="line">            <span class="comment"># w.x + b = c</span></div><div class="line">            <span class="keyword">return</span> (-w[<span class="number">0</span>] * x - b + c) / w[<span class="number">1</span>]</div><div class="line"></div><div class="line">        pl.plot(X1_train[:,<span class="number">0</span>], X1_train[:,<span class="number">1</span>], <span class="string">"ro"</span>)</div><div class="line">        pl.plot(X2_train[:,<span class="number">0</span>], X2_train[:,<span class="number">1</span>], <span class="string">"bo"</span>)</div><div class="line">        pl.scatter(clf.sv[:,<span class="number">0</span>], clf.sv[:,<span class="number">1</span>], s=<span class="number">100</span>, c=<span class="string">"g"</span>)</div><div class="line"></div><div class="line">        <span class="comment"># w.x + b = 0</span></div><div class="line">        a0 = <span class="number">-4</span>; a1 = f(a0, clf.w, clf.b)</div><div class="line">        b0 = <span class="number">4</span>; b1 = f(b0, clf.w, clf.b)</div><div class="line">        pl.plot([a0,b0], [a1,b1], <span class="string">"k"</span>)</div><div class="line"></div><div class="line">        <span class="comment"># w.x + b = 1</span></div><div class="line">        a0 = <span class="number">-4</span>; a1 = f(a0, clf.w, clf.b, <span class="number">1</span>)</div><div class="line">        b0 = <span class="number">4</span>; b1 = f(b0, clf.w, clf.b, <span class="number">1</span>)</div><div class="line">        pl.plot([a0,b0], [a1,b1], <span class="string">"k--"</span>)</div><div class="line"></div><div class="line">        <span class="comment"># w.x + b = -1</span></div><div class="line">        a0 = <span class="number">-4</span>; a1 = f(a0, clf.w, clf.b, <span class="number">-1</span>)</div><div class="line">        b0 = <span class="number">4</span>; b1 = f(b0, clf.w, clf.b, <span class="number">-1</span>)</div><div class="line">        pl.plot([a0,b0], [a1,b1], <span class="string">"k--"</span>)</div><div class="line"></div><div class="line">        pl.axis(<span class="string">"tight"</span>)</div><div class="line">        pl.show()</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">plot_contour</span><span class="params">(X1_train, X2_train, clf)</span>:</span></div><div class="line">        pl.plot(X1_train[:,<span class="number">0</span>], X1_train[:,<span class="number">1</span>], <span class="string">"ro"</span>)</div><div class="line">        pl.plot(X2_train[:,<span class="number">0</span>], X2_train[:,<span class="number">1</span>], <span class="string">"bo"</span>)</div><div class="line">        pl.scatter(clf.sv[:,<span class="number">0</span>], clf.sv[:,<span class="number">1</span>], s=<span class="number">100</span>, c=<span class="string">"g"</span>)</div><div class="line"></div><div class="line">        X1, X2 = np.meshgrid(np.linspace(<span class="number">-6</span>,<span class="number">6</span>,<span class="number">50</span>), np.linspace(<span class="number">-6</span>,<span class="number">6</span>,<span class="number">50</span>))</div><div class="line">        X = np.array([[x1, x2] <span class="keyword">for</span> x1, x2 <span class="keyword">in</span> zip(np.ravel(X1), np.ravel(X2))])</div><div class="line">        Z = clf.project(X).reshape(X1.shape)</div><div class="line">        pl.contour(X1, X2, Z, [<span class="number">0.0</span>], colors=<span class="string">'k'</span>, linewidths=<span class="number">1</span>, origin=<span class="string">'lower'</span>)</div><div class="line">        pl.contour(X1, X2, Z + <span class="number">1</span>, [<span class="number">0.0</span>], colors=<span class="string">'grey'</span>, linewidths=<span class="number">1</span>, origin=<span class="string">'lower'</span>)</div><div class="line">        pl.contour(X1, X2, Z - <span class="number">1</span>, [<span class="number">0.0</span>], colors=<span class="string">'grey'</span>, linewidths=<span class="number">1</span>, origin=<span class="string">'lower'</span>)</div><div class="line"></div><div class="line">        pl.axis(<span class="string">"tight"</span>)</div><div class="line">        pl.show()</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_linear</span><span class="params">()</span>:</span></div><div class="line">        X1, y1, X2, y2 = gen_lin_separable_data()</div><div class="line">        X_train, y_train = split_train(X1, y1, X2, y2)</div><div class="line">        X_test, y_test = split_test(X1, y1, X2, y2)</div><div class="line"></div><div class="line">        clf = SVM()</div><div class="line">        clf.fit(X_train, y_train)</div><div class="line"></div><div class="line">        y_predict = clf.predict(X_test)</div><div class="line">        correct = np.sum(y_predict == y_test)</div><div class="line">        print(<span class="string">"%d out of %d predictions correct"</span> % (correct, len(y_predict)))</div><div class="line"></div><div class="line">        plot_margin(X_train[y_train==<span class="number">1</span>], X_train[y_train==<span class="number">-1</span>], clf)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_non_linear</span><span class="params">()</span>:</span></div><div class="line">        X1, y1, X2, y2 = gen_non_lin_separable_data()</div><div class="line">        X_train, y_train = split_train(X1, y1, X2, y2)</div><div class="line">        X_test, y_test = split_test(X1, y1, X2, y2)</div><div class="line"></div><div class="line">        clf = SVM(polynomial_kernel)</div><div class="line">        clf.fit(X_train, y_train)</div><div class="line"></div><div class="line">        y_predict = clf.predict(X_test)</div><div class="line">        correct = np.sum(y_predict == y_test)</div><div class="line">        print(<span class="string">"%d out of %d predictions correct"</span> % (correct, len(y_predict)))</div><div class="line"></div><div class="line">        plot_contour(X_train[y_train==<span class="number">1</span>], X_train[y_train==<span class="number">-1</span>], clf)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_soft</span><span class="params">()</span>:</span></div><div class="line">        X1, y1, X2, y2 = gen_lin_separable_overlap_data()</div><div class="line">        X_train, y_train = split_train(X1, y1, X2, y2)</div><div class="line">        X_test, y_test = split_test(X1, y1, X2, y2)</div><div class="line"></div><div class="line">        clf = SVM(C=<span class="number">1000.1</span>)</div><div class="line">        clf.fit(X_train, y_train)</div><div class="line"></div><div class="line">        y_predict = clf.predict(X_test)</div><div class="line">        correct = np.sum(y_predict == y_test)</div><div class="line">        print(<span class="string">"%d out of %d predictions correct"</span> % (correct, len(y_predict)))</div><div class="line"></div><div class="line">        plot_contour(X_train[y_train==<span class="number">1</span>], X_train[y_train==<span class="number">-1</span>], clf)</div><div class="line"></div><div class="line">        </div><div class="line">    <span class="comment">#test_linear()</span></div><div class="line">    <span class="comment">#test_non_linear()</span></div><div class="line">    test_soft()</div></pre></td></tr></table></figure><blockquote><p><strong>具体相关说明可见<a href="https://pythonprogramming.net/soft-margin-kernel-cvxopt-svm-machine-learning-tutorial/?completed=/soft-margin-svm-machine-learning-tutorial/" target="_blank" rel="external">对应的课程地址</a>。</strong></p></blockquote><p>更多的铺助链接：</p><ul><li><p><a href="https://cvxopt.org/userguide/intro.html" target="_blank" rel="external">pythonC最优化模块库：VXOPT二次编程文档</a></p></li><li><p><a href="https://courses.csail.mit.edu/6.867/wiki/images/a/a7/Qp-cvxopt.pdf" target="_blank" rel="external">CVXOPT进行二次编程的更深入的示例</a></p></li><li><p><a href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/" target="_blank" rel="external">用于支持向量机优化的库</a></p></li></ul><h1 id="SVM的应用"><a href="#SVM的应用" class="headerlink" title="SVM的应用"></a>SVM的应用</h1><p>还是利用了在上个文章<a href="http://liujunworld.com/2018/10/21/python机器学习系列：K近邻算法(KNN" target="_blank" rel="external">python机器学习系列：K近邻算法(KNN)的实现及应用</a>的实现及应用/)的实际数据集。只是将<code>sklearn</code>模块中的现成的拿来用了。</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing, neighbors, svm</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"></div><div class="line">df = pd.read_csv(<span class="string">'breast-cancer-wisconsin.data'</span>)</div><div class="line"></div><div class="line">df.replace(<span class="string">'?'</span>,<span class="number">-99999</span>,inplace=<span class="keyword">True</span>) <span class="comment">#替换异常值为-99999，inplace=True表示文件中也将进行同步更改</span></div><div class="line"></div><div class="line"><span class="comment">#去除不相关的特征列</span></div><div class="line">df.drop([<span class="string">'Id'</span>], <span class="number">1</span>, inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">X = np.array(df.drop([<span class="string">'Class'</span>], <span class="number">1</span>)) <span class="comment">#去除标签列，自制数据集</span></div><div class="line">y = np.array(df[<span class="string">'Class'</span>])</div><div class="line"></div><div class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</div><div class="line"></div><div class="line">clf = svm.SVC() <span class="comment">#分类SVM</span></div><div class="line">clf.fit(X_train, y_train)</div><div class="line"></div><div class="line">accuracy = clf.score(X_test, y_test) <span class="comment">#得出准确值</span></div><div class="line">print(accuracy)</div><div class="line"></div><div class="line"><span class="comment">#创建数据集来进行简单的预测</span></div><div class="line">example_maasurse = np.array([[<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>],[<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>]])</div><div class="line"></div><div class="line">example_maasurse = example_maasurse.reshape(len(example_maasurse),<span class="number">-1</span>) <span class="comment">#重朔,其中的-1可理解为，只想输出2行的情况下，后面的列我写上-1由numpy自行得出对应相符的数组，有点抽象...其实也就那么回事</span></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">prediction = clf.predict(example_maasurse)</div><div class="line">print(prediction)</div></pre></td></tr></table></figure><p>结果跟上篇介绍的用<code>KNN</code>的结果几乎一样，就不展示了。</p><p>关于现成算法的参数的使用可移步：</p><ul><li><a href="http://sklearn.apachecn.org/cn/stable/index.html" target="_blank" rel="external">sklearn中文主页</a></li></ul><p>这样这篇文章基本上就这样了，需要更新的话再来补充。</p>]]></content>
    
    <summary type="html">
    
      &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/HHUqhVzctQE&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; encrypted-media&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;我记录下的这些东西，如果是有哪些不懂得地方，我强烈建议参考我在&lt;a href=&quot;http://liujunworld.com/2018/09/16/%E5%88%9D%E5%AD%A6%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8D%97/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;这里的书籍&lt;/a&gt;。另外还有&lt;a href=&quot;https://github.com/apachecn/AiLearning&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;《机器学习实战》&lt;/a&gt;，&lt;a href=&quot;https://github.com/exacity/deeplearningbook-chinese&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;《深度学习》&lt;/a&gt;这本花书等，利用好搜索引擎也是一大好利器。&lt;/p&gt;
&lt;p&gt;关于这篇文章，我还是和以前记录相关的机器学习知识之类篇章一样的风格。&lt;/p&gt;
&lt;p&gt;不懂可进入&lt;a href=&quot;https://pythonprogramming.net/support-vector-machine-intro-machine-learning-tutorial/?completed=/final-thoughts-knn-machine-learning-tutorial/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;这里的对应的教程&lt;/a&gt;，看不懂可借助翻译插件/软件(实际上借助这些看起来轻松多了，看英文头疼的厉害，如果是对于初学者)。&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/categories/Python/"/>
    
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>解决eclipse中运行Django时出现错误Django not found</title>
    <link href="https://liujunjie11.github.io/2018/10/21/%E8%A7%A3%E5%86%B3eclipse%E4%B8%AD%E8%BF%90%E8%A1%8CDjango%E6%97%B6%E5%87%BA%E7%8E%B0%E9%94%99%E8%AF%AFDjango-not-found/"/>
    <id>https://liujunjie11.github.io/2018/10/21/解决eclipse中运行Django时出现错误Django-not-found/</id>
    <published>2018-10-21T12:07:13.000Z</published>
    <updated>2018-11-13T12:32:36.818Z</updated>
    
    <content type="html"><![CDATA[<p>打算在<em>eclipse</em>中运行<em>Django</em>项目，结果发现出现了错误Django not found，如下图(网上找的一张，忘记截图了..)：</p><p><img src="http://smartjpa.com/20151111171637700.png" alt=""></p><blockquote><p>图片来源：<a href="https://blog.csdn.net/wlsyn/article/details/49784263?utm_source=blogxgwz2" target="_blank" rel="external">https://blog.csdn.net/wlsyn/article/details/49784263?utm_source=blogxgwz2</a></p></blockquote><p>试了一些网上所谓的重新嵌入解释器目录的方法，还有重装<em>Django</em>的方法，都没有什么用。</p><a id="more"></a><p>但是我真的不想放弃啊，eclipse那么好用，而且在其中运行Django是那么的方便…</p><h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><h2 id="git下载GitHub上的Django"><a href="#git下载GitHub上的Django" class="headerlink" title="git下载GitHub上的Django"></a>git下载GitHub上的Django</h2><p>使用命令行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git <span class="built_in">clone</span> https://github.com/django/django.git</div></pre></td></tr></table></figure><blockquote><p>参考：<a href="https://www.djangoproject.com/download/" target="_blank" rel="external">https://www.djangoproject.com/download/</a></p></blockquote><h2 id="移动安装包"><a href="#移动安装包" class="headerlink" title="移动安装包"></a>移动安装包</h2><p>之后将下载好的移动到要用到的python版本中的<code>site-packages</code>中，如我的目录<code>/anaconda3/lib/python3.6/site-packages/</code>。</p><h2 id="eclipse配置"><a href="#eclipse配置" class="headerlink" title="eclipse配置"></a>eclipse配置</h2><p>之后打开eclipse配置界面，看图吧，一图胜千言。</p><p><img src="http://smartjpa.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-21%20%E4%B8%8B%E5%8D%888.16.27.png" alt=""></p><p>之后应用、关闭。</p><p>然后再建立Django项目时就不会再出现错误Django not found了。</p><p>测试和建立项目过程不妨可以参考以下链接：</p><blockquote><p><a href="http://www.cnblogs.com/lanxuezaipiao/p/3283932.html" target="_blank" rel="external">http://www.cnblogs.com/lanxuezaipiao/p/3283932.html</a></p></blockquote><p>我就不重复制造轮子了。</p><p>测试成功之后：</p><p><img src="http://smartjpa.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-21%20%E4%B8%8B%E5%8D%888.04.02.png" alt=""></p><p>Yes,it`s successful!</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;打算在&lt;em&gt;eclipse&lt;/em&gt;中运行&lt;em&gt;Django&lt;/em&gt;项目，结果发现出现了错误Django not found，如下图(网上找的一张，忘记截图了..)：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://smartjpa.com/20151111171637700.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;图片来源：&lt;a href=&quot;https://blog.csdn.net/wlsyn/article/details/49784263?utm_source=blogxgwz2&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://blog.csdn.net/wlsyn/article/details/49784263?utm_source=blogxgwz2&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;试了一些网上所谓的重新嵌入解释器目录的方法，还有重装&lt;em&gt;Django&lt;/em&gt;的方法，都没有什么用。&lt;/p&gt;
    
    </summary>
    
      <category term="笔记" scheme="https://liujunjie11.github.io/categories/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="软件使用" scheme="https://liujunjie11.github.io/categories/%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/"/>
    
      <category term="Eclipse" scheme="https://liujunjie11.github.io/categories/Eclipse/"/>
    
      <category term="Django" scheme="https://liujunjie11.github.io/categories/Django/"/>
    
    
      <category term="Eclipse" scheme="https://liujunjie11.github.io/tags/Eclipse/"/>
    
      <category term="问题记录笔记" scheme="https://liujunjie11.github.io/tags/%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95%E7%AC%94%E8%AE%B0/"/>
    
      <category term="Django" scheme="https://liujunjie11.github.io/tags/Django/"/>
    
  </entry>
  
  <entry>
    <title>python机器学习系列：K近邻算法(KNN)的实现及应用</title>
    <link href="https://liujunjie11.github.io/2018/10/21/python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%9AK%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95(KNN)%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%BA%94%E7%94%A8/"/>
    <id>https://liujunjie11.github.io/2018/10/21/python机器学习系列：K近邻算法(KNN)的实现及应用/</id>
    <published>2018-10-21T05:43:00.000Z</published>
    <updated>2018-11-13T12:32:47.294Z</updated>
    
    <content type="html"><![CDATA[<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/r_D5TTV9-2c" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe><p>还是老样子，这篇文章不适合纯粹的小白，仅仅注重实践，基础知识说的比较浅，基本上一笔带过。</p><p>我在作者的原代码和数据上进行了一点修改以符合当今的实际情况。</p><p>此篇文章将实现K近邻算法的基本原理，以及实现K邻近算法并且应用到实际数据集之中，之后会有一个实战项目。<br><a id="more"></a></p><h1 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h1><h2 id="欧几里得原理以及代码实现"><a href="#欧几里得原理以及代码实现" class="headerlink" title="欧几里得原理以及代码实现"></a>欧几里得原理以及代码实现</h2><p>欧几里得公式：</p><p><img src="http://smartjpa.com/euclidean-distance.png" alt=""></p><blockquote><p>实际上很简单，想想求解两点值之间的距离的问题吧…</p></blockquote><p>代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt</div><div class="line"></div><div class="line"><span class="comment">#数据自制</span></div><div class="line">feature_1 = [<span class="number">1</span>,<span class="number">3</span>]</div><div class="line">feature_2 = [<span class="number">2</span>,<span class="number">6</span>]</div><div class="line"></div><div class="line">euclidean_distance = sqrt((variable_2[<span class="number">0</span>]-variable_1[<span class="number">0</span>])**<span class="number">2</span> + (variable_2[<span class="number">1</span>]-variable_1[<span class="number">1</span>])**<span class="number">2</span>)</div><div class="line">print(euclidean_distance)</div></pre></td></tr></table></figure><blockquote><p>这里是中文相关一节的地址：<a href="https://www.yxgapp.com/video/c8426884-2b56-494f-a274-0aa3105503f1.html" target="_blank" rel="external">https://www.yxgapp.com/video/c8426884-2b56-494f-a274-0aa3105503f1.html</a></p></blockquote><h2 id="实现KNN"><a href="#实现KNN" class="headerlink" title="实现KNN"></a>实现KNN</h2><p>KNN的工作机制(来自志华哥的《机器学习》)：</p><blockquote><p>给定测试样本，基于某种距离度量找出训练集中与其最近的k个训练样本，然后基于这k个“邻居”的信息来进行预测，通常，在分类任务中可使用“投票法”(在本文当中明显就是分类问题)，即选择这k个样本中出现最多的类别标记作为预测结果；在回归任务中可使用“平均法”，即将这k个样本的实值输出标记的平均值作为预测结果；还可基于距离远近进行加权平均或加权投票，距离越近的样本权重越大。</p></blockquote><p>这样就能好理解之后写的算法了，这毕竟不是给纯粹的小白写的。</p><p>简单说说下面写的代码的原理：通过原有的数值与新的数值代入欧几里得原理得出各点与新数值的距离，然后对这些数值进行从小到大排序并且选取前面K个数值(即所谓的K近邻)作为选择值，之后选择第一个最近的(距离最小的)作为新数据的标签。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> warnings</div><div class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</div><div class="line"></div><div class="line"><span class="comment">#自制数据集</span></div><div class="line">dataset = &#123;<span class="string">'k'</span>:[[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">3</span>],[<span class="number">3</span>,<span class="number">1</span>]], <span class="string">'r'</span>:[[<span class="number">6</span>,<span class="number">5</span>],[<span class="number">7</span>,<span class="number">7</span>],[<span class="number">8</span>,<span class="number">6</span>]]&#125; <span class="comment">#这个字典的key值为何这样命名看到下面就知道了，作为color参数的输入</span></div><div class="line">new_features = [<span class="number">5</span>,<span class="number">7</span>]</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">k_nearest_neighbors</span><span class="params">(data, predict_feature, k=<span class="number">3</span>)</span>:</span> <span class="comment">#特别说明：k值在sklearn中的模型默认为5</span></div><div class="line">    <span class="keyword">if</span> len(data) &gt;= k:</div><div class="line">        warnings.warn(<span class="string">'你这样就没有意义了...笨猪！'</span>)</div><div class="line">    distances = []</div><div class="line">    <span class="keyword">for</span> group <span class="keyword">in</span> data:</div><div class="line">        <span class="keyword">for</span> features <span class="keyword">in</span> data[group]: <span class="comment">#这两段代码与for group, features in dateset.items():意义一致</span></div><div class="line">            euclidean_distance = np.linalg.norm(np.array(features)-np.array(predict_feature)) <span class="comment">#使用numpy的相关的模块会显得更加的快速以及更加的高级</span></div><div class="line">            distances.append([euclidean_distance, group])</div><div class="line">            </div><div class="line">    votes = [i[<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> sorted(distances)[:k]] <span class="comment">#从小到大的排序，选择出现在前面的K个样本作为投票得出的结果</span></div><div class="line">    vote_result = Counter(votes).most_common(<span class="number">1</span>)[<span class="number">0</span>][<span class="number">0</span>]</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> vote_result</div><div class="line"></div><div class="line">result = k_nearest_neighbors(dataset, new_features, k=<span class="number">3</span>)</div><div class="line">print(result)</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line"><span class="comment">#可通过图表展示出结果信息</span></div><div class="line">[[plt.scatter(ii[<span class="number">0</span>],ii[<span class="number">1</span>], s=<span class="number">20</span>, color=i) <span class="keyword">for</span> ii <span class="keyword">in</span> dateset[i]] <span class="keyword">for</span> i <span class="keyword">in</span> dateset] <span class="comment">#color输出为'r'，可见上面作者命名的含义</span></div><div class="line"></div><div class="line">result = k_nearest_neighbors(dataset, new_features)</div><div class="line">plt.scatter(new_features[<span class="number">0</span>], new_features[<span class="number">1</span>], s=<span class="number">20</span>, color = result) <span class="comment">#color输出为'r'，可见上面作者命名的含义</span></div><div class="line">plt.show()</div></pre></td></tr></table></figure><p>可帮助理解的链接：</p><ul><li><p><a href="http://www.pythoner.com/205.html" target="_blank" rel="external">Python标准库——collections模块的Counter类</a></p></li><li><p><a href="https://blog.csdn.net/hqh131360239/article/details/79061535" target="_blank" rel="external">np.linalg.norm(求范数)</a></p></li></ul><blockquote><p>看完并且理解了上面的代码之后，你就会发现<strong>KNN算法为何对于异常值不敏感了吧，因为异常值太大，得出的距离也很大，所以一般在投票选择排序时就被out了。</strong></p></blockquote><h2 id="展示图表以及运行结果"><a href="#展示图表以及运行结果" class="headerlink" title="展示图表以及运行结果"></a>展示图表以及运行结果</h2><p>如图：</p><p><img src="http://smartjpa.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-22%20%E4%B8%8B%E5%8D%885.55.39.png" alt=""></p><p>这样就一目了然了。</p><h1 id="项目实践"><a href="#项目实践" class="headerlink" title="项目实践"></a>项目实践</h1><ul><li>数据来源：<a href="https://archive.ics.uci.edu/ml/datasets.html" target="_blank" rel="external">https://archive.ics.uci.edu/ml/datasets.html</a>﻿</li></ul><p>这是加州大学的一个用于机器学习数据的仓库，基本上是开放数据给我们使用的。</p><ul><li><p>项目使用的数据下载页面：<a href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic" target="_blank" rel="external">https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic</a>)</p></li><li><p>项目使用的数据下载链接：<a href="https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/" target="_blank" rel="external">https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/</a></p></li></ul><p>下载其中的<code>breast-cancer-wisconsin.data</code>，查看特征系数情况查看<code>breast-cancer-wisconsin.names</code>。</p><p>因为需要对数据进行一些特征增加的修改，所以我贴上修改后的数据在下，也可查看上面的作者的YouTube教程来进行修改。</p><ul><li>修改后的数据集：<a href="https://pan.baidu.com/s/1J-G6ESB-JXFfBk8yTl8lmw" target="_blank" rel="external">https://pan.baidu.com/s/1J-G6ESB-JXFfBk8yTl8lmw</a></li></ul><blockquote><p>也就是添加了特征名而已。</p></blockquote><p>这是一个关于乳腺癌判断的数据集。从<code>breast-cancer-wisconsin.names</code>中可得知缺失的数据由<code>&#39;?&#39;</code>来表示。</p><blockquote><ol><li><p>Missing attribute values: 16</p><p>There are 16 instances in Groups 1 to 6 that contain a single missing (i.e., unavailable) attribute value, now denoted by “?”.  </p></li></ol></blockquote><p>这样一来就能开始整个项目了。</p><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>数据集中的特征意喻：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">Attribute Information: (class attribute has been moved to last column)</div><div class="line"></div><div class="line">   <span class="comment">#  Attribute                     Domain</span></div><div class="line">   -- -----------------------------------------</div><div class="line">   1. Sample code number            id number</div><div class="line">   2. Clump Thickness               1 - 10</div><div class="line">   3. Uniformity of Cell Size       1 - 10</div><div class="line">   4. Uniformity of Cell Shape      1 - 10</div><div class="line">   5. Marginal Adhesion             1 - 10</div><div class="line">   6. Single Epithelial Cell Size   1 - 10</div><div class="line">   7. Bare Nuclei                   1 - 10</div><div class="line">   8. Bland Chromatin               1 - 10</div><div class="line">   9. Normal Nucleoli               1 - 10</div><div class="line">  10. Mitoses                       1 - 10</div><div class="line">  11. Class:                        (2 <span class="keyword">for</span> benign(良性), 4 <span class="keyword">for</span> malignant(恶性))</div></pre></td></tr></table></figure><p>因为缺失的数据并不多，并且在我修改了那几个缺失值测试了好几次用于训练之后发现差距基本上可以忽略，所以这里的关于缺失值改为异常值来处理，因为基本上对于模型训练基本上没有什么影响。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"></div><div class="line">df = pd.read_csv(<span class="string">'breast-cancer-wisconsin.data'</span>)</div><div class="line"></div><div class="line">df.replace(<span class="string">'?'</span>,<span class="number">-99999</span>,inplace=<span class="keyword">True</span>) <span class="comment">#替换异常值为-99999，inplace=True表示文件中也将进行同步更改</span></div><div class="line"><span class="comment">#去除不相关的特征列</span></div><div class="line">df.drop([<span class="string">'Id'</span>], <span class="number">1</span>, inplace=<span class="keyword">True</span>)</div></pre></td></tr></table></figure><p>数据量本身也就是那么点…所以数据预处理也就这样了…<strong>KNN算法对于异常值不敏感。</strong></p><h2 id="模型训练及预测"><a href="#模型训练及预测" class="headerlink" title="模型训练及预测"></a>模型训练及预测</h2><p>分割数据集，进行训练，并且制作简易数据集来进行预测。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing,neighbors</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"></div><div class="line">X = np.array(df.drop([<span class="string">'Class'</span>], <span class="number">1</span>)) <span class="comment">#去除标签列，自制数据集</span></div><div class="line">y = np.array(df[<span class="string">'Class'</span>])</div><div class="line"></div><div class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</div><div class="line"></div><div class="line">clf = neighbors.KNeighborsClassifier()</div><div class="line">clf.fit(X_train, y_train)</div><div class="line"></div><div class="line">accuracy = clf.score(X_test, y_test) <span class="comment">#得出准确值</span></div><div class="line">print(accuracy)</div><div class="line"></div><div class="line"><span class="comment">#创建数据集来进行简单的预测</span></div><div class="line">example_maasurse = np.array([[<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>],[<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>]])</div><div class="line">example_maasurse = example_maasurse.reshape(len(example_maasurse),<span class="number">-1</span>) <span class="comment">#重朔,其中的-1可理解为，只想输出2行的情况下，后面的列我写上-1由numpy自行得出对应相符的数组，有点抽象...其实也就那么回事</span></div><div class="line"></div><div class="line"></div><div class="line">prediction = clf.predict(example_maasurse)</div><div class="line">print(prediction)</div></pre></td></tr></table></figure><p>输出如下：</p><p><img src="http://smartjpa.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-21%20%E4%B8%8B%E5%8D%884.10.36.png" alt=""></p><p>如果还是对于这条代码<code>example_maasurse.reshape(len(example_maasurse),-1)</code>中的<code>-1</code>还是不理解，可参考如下链接或者是官网：</p><ul><li><p><a href="https://www.zhihu.com/question/52684594" target="_blank" rel="external">Python中reshape函数参数-1的意思？</a></p></li><li><p><a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html#numpy-reshape" target="_blank" rel="external">numpy.reshape</a></p></li><li><p><a href="">Python Numpy中reshape函数参数-1的含义</a></p></li></ul><p>其实也就那么回事…</p><h2 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing,neighbors</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"></div><div class="line">df = pd.read_csv(<span class="string">'breast-cancer-wisconsin.data'</span>)</div><div class="line"></div><div class="line">df.replace(<span class="string">'?'</span>,<span class="number">-99999</span>,inplace=<span class="keyword">True</span>) </div><div class="line">df.drop([<span class="string">'Id'</span>], <span class="number">1</span>, inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">X = np.array(df.drop([<span class="string">'Class'</span>], <span class="number">1</span>)) </div><div class="line">y = np.array(df[<span class="string">'Class'</span>])</div><div class="line"></div><div class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</div><div class="line"></div><div class="line">clf = neighbors.KNeighborsClassifier()</div><div class="line">clf.fit(X_train, y_train)</div><div class="line"></div><div class="line">accuracy = clf.score(X_test, y_test) </div><div class="line">print(accuracy)</div><div class="line"></div><div class="line">example_maasurse = np.array([[<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>],[<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>]])</div><div class="line">example_maasurse = example_maasurse.reshape(len(example_maasurse),<span class="number">-1</span>)</div><div class="line"></div><div class="line">prediction = clf.predict(example_maasurse)</div><div class="line">print(prediction)</div></pre></td></tr></table></figure><h2 id="用手动实现的KNN训练此数据集"><a href="#用手动实现的KNN训练此数据集" class="headerlink" title="用手动实现的KNN训练此数据集"></a>用手动实现的KNN训练此数据集</h2><p>代入以上的实际数据，转换数据类型打乱整体(俗称“洗牌”)的数据集并且分割对应标签制作成可代入上面写的算法中的数据集形式，然后根据计算出的距离结合<code>K</code>的取值得出最终的测试数据集的整体预测标签(计算在训练数据集与测试数据集之间进行)，然后将预测得出的标签与实际的结果进行比较，最终即可得出整体的算法准确性(Accuracy)。</p><p>下面是实现的整体代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> warnings</div><div class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">k_nearest_neighbors</span><span class="params">(data, predict_feature, k=<span class="number">3</span>)</span>:</span> <span class="comment">#特别说明：k值在sklearn中的模型默认为5</span></div><div class="line">    <span class="keyword">if</span> len(data) &gt;= k:</div><div class="line">        warnings.warn(<span class="string">'你这样就没有意义了...笨猪！'</span>)</div><div class="line">    distances = []</div><div class="line">    <span class="keyword">for</span> group <span class="keyword">in</span> data:</div><div class="line">        <span class="keyword">for</span> features <span class="keyword">in</span> data[group]: <span class="comment">#这两段代码与for group, features in dateset.items():意义一致</span></div><div class="line">            euclidean_distance = np.linalg.norm(np.array(features)-np.array(predict_feature)) <span class="comment">#使用numpy的相关的模块会显得更加的快速以及更加的高级</span></div><div class="line">            distances.append([euclidean_distance, group])</div><div class="line">            </div><div class="line">    votes = [i[<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> sorted(distances)[:k]] <span class="comment">#从小到大的排序，选择出现在前面的K个样本作为投票得出的结果</span></div><div class="line">    vote_result = Counter(votes).most_common(<span class="number">1</span>)[<span class="number">0</span>][<span class="number">0</span>]</div><div class="line">    confidence = Counter(votes).most_common(<span class="number">1</span>)[<span class="number">0</span>][<span class="number">1</span>] / k <span class="comment">#在预测的样本中正确预测的比例，但是数据量小，一般不靠谱，所以不采用，当然可写入代码中以便学习</span></div><div class="line"></div><div class="line"></div><div class="line">    <span class="keyword">return</span> vote_result, confidence</div><div class="line"></div><div class="line">df = pd.read_csv(<span class="string">'breast-cancer-wisconsin.data'</span>)</div><div class="line">df.replace(<span class="string">'?'</span>, <span class="number">-99999</span>, inplace=<span class="keyword">True</span>)</div><div class="line">df.drop([<span class="string">'Id'</span>], <span class="number">1</span>, inplace=<span class="keyword">True</span>)</div><div class="line">full_data = df.astype(float).values.tolist() <span class="comment">#转化为float、列表类型以便下面的随机打乱</span></div><div class="line"></div><div class="line">random.shuffle(full_data) <span class="comment">#随机打乱所有数据,洗牌函数</span></div><div class="line">test_size = <span class="number">0.2</span></div><div class="line">train_set = &#123;<span class="number">2</span>:[], <span class="number">4</span>:[]&#125;</div><div class="line">test_set = &#123;<span class="number">2</span>:[], <span class="number">4</span>:[]&#125;</div><div class="line"><span class="comment">#取训练数据集比例0.8:0.2</span></div><div class="line">train_data = full_data[:-int(test_size*len(full_data))]</div><div class="line">test_data = full_data[-int(test_size*len(full_data)):]</div><div class="line"></div><div class="line"><span class="comment">#数据分割对应</span></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> train_data:</div><div class="line">    train_set[i[<span class="number">-1</span>]].append(i[:<span class="number">-1</span>]) <span class="comment">#模版套入对应数据即可</span></div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> test_data:</div><div class="line">    test_set[i[<span class="number">-1</span>]].append(i[:<span class="number">-1</span>])</div><div class="line">    </div><div class="line">correct = <span class="number">0</span></div><div class="line">total = <span class="number">0</span></div><div class="line"></div><div class="line"><span class="keyword">for</span> group <span class="keyword">in</span> test_set:</div><div class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> test_set[group]: <span class="comment">#亦可理解为for group, data in test_set.items():</span></div><div class="line">        vote, confidence = k_nearest_neighbors(train_set, data, k=<span class="number">5</span>) </div><div class="line">        <span class="keyword">if</span> group == vote:</div><div class="line">            correct += <span class="number">1</span> <span class="comment">#若是准确预测了则加1</span></div><div class="line">        total += <span class="number">1</span></div><div class="line">print(<span class="string">'Accuracy:'</span>, correct/total)</div></pre></td></tr></table></figure><blockquote><p>铺助理解：<a href="http://www.runoob.com/python3/python3-func-number-shuffle.html" target="_blank" rel="external">Python3 shuffle() 函数</a></p></blockquote><p>运行可得预测准确性：</p><p><img src="http://smartjpa.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-22%20%E4%B8%8B%E5%8D%886.51.22.png" alt=""></p><p>其中有必要说明一下：<code>Accuracy</code>与<code>confidence</code>的关系，就相当于<code>查准率(Precision)</code>(<strong>预测正确的样本数与总体使用样本数的比例</strong>)和<code>查全率(Recall)</code>(<strong>预测正确样本数与全部使用数据数量的比例</strong>)的关系。另外补充一点关于平常常用的<code>score</code>参数的计算公式：</p><p><img src="http://smartjpa.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-22%20%E4%B8%8B%E5%8D%887.27.46.png" alt=""></p><blockquote><p>这些知识都是基础知识，可在网友整理的吴恩达老师的<a href="http://www.ai-start.com/ml2014/html/week6.html#header-n168" target="_blank" rel="external">机器学习笔记</a>中找到，也可完整的学习相关的知识，吴恩达老师的必看啊。</p></blockquote><h1 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h1><p>以上的算法没有完全的实现，仅仅是实现基础的构想，还需要改进的地方有很多，比如数据量大了一点之后，需要用到的多线程等。</p><p>另外，KNN算法的优缺点值得去了解，上面我也说过一点，比如数据量大了之后它的效率会受到影响，但是它对于异常值处理的都很好，基本上不受异常值之类的影响等，自行翻书了解去吧。</p>]]></content>
    
    <summary type="html">
    
      &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/r_D5TTV9-2c&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; encrypted-media&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;还是老样子，这篇文章不适合纯粹的小白，仅仅注重实践，基础知识说的比较浅，基本上一笔带过。&lt;/p&gt;
&lt;p&gt;我在作者的原代码和数据上进行了一点修改以符合当今的实际情况。&lt;/p&gt;
&lt;p&gt;此篇文章将实现K近邻算法的基本原理，以及实现K邻近算法并且应用到实际数据集之中，之后会有一个实战项目。&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/categories/Python/"/>
    
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>python机器学习系列：线性回归算法的实现</title>
    <link href="https://liujunjie11.github.io/2018/10/19/python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%9A%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B0/"/>
    <id>https://liujunjie11.github.io/2018/10/19/python机器学习系列：线性回归算法的实现/</id>
    <published>2018-10-19T03:08:43.000Z</published>
    <updated>2018-11-13T12:33:00.528Z</updated>
    
    <content type="html"><![CDATA[<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/V59bYfIomVk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe><p>本来不想写太多关于这方面的基础知识的，但是为了加强理解，我想不妨直接写博文记录也是一个好的选择，也可以顺便帮助需要的人，何乐而不为呢？</p><p>那么开始吧。我在原课程的基础上进行那么一点点修改。</p><blockquote><p>这是我学习的相应的课程地址：<a href="https://pythonprogramming.net/how-to-program-best-fit-line-machine-learning-tutorial/?completed=/how-to-program-best-fit-line-slope-machine-learning-tutorial/" target="_blank" rel="external">https://pythonprogramming.net/how-to-program-best-fit-line-machine-learning-tutorial/?completed=/how-to-program-best-fit-line-slope-machine-learning-tutorial/</a></p></blockquote><p>这不是一个小白教程，需要自行取了解一些基础知识，基础知识我仅仅是一笔带过。</p><a id="more"></a><h1 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h1><p>众所周知，线性回归算法是以一条直线来将一些散点进行分类的算法，而这条直线通常可理解为<code>y(x)=mx+b</code>/<code>y=mx+b</code>这样的函数(这是最简单的线性回归算法实例)，其中<code>m</code>为直线的斜率，而<code>y</code>为直线的截距，而<code>x</code>为直线的自变量。</p><p>如下图，我们要将图1的散点，通过图2一条直线进行适当良好的分类开来：</p><ul><li>图1</li></ul><p><img src="http://smartjpa.com/linear-regression-tutorial.png" alt=""></p><ul><li>图2</li></ul><p><img src="http://smartjpa.com/linear-regression-python-tutorial.png" alt=""></p><h2 id="求解m"><a href="#求解m" class="headerlink" title="求解m:"></a>求解<code>m</code>:</h2><p>如图：</p><p><img src="http://smartjpa.com/best-fit-slope.png" alt=""></p><h2 id="求解b"><a href="#求解b" class="headerlink" title="求解b:"></a>求解<code>b</code>:</h2><p>如图：</p><p><img src="http://smartjpa.com/best-fit-y-intercept.png" alt=""></p><p>实际上这与所谓的<code>感知机</code>是一样的原理(相关的知识可见李航老师的书籍《统计需诶下方法》)。再者，经过python实现编写对应的公式再进行可视化验证即可完成任务了。</p><h2 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h2><p>因为仅仅是为了说明算法的实现，所以数值就随便取的来用了。</p><h3 id="数值取值："><a href="#数值取值：" class="headerlink" title="数值取值："></a>数值取值：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line">xs = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],dtype=np.float64)</div><div class="line">ys = np.array([<span class="number">5</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>],dtype=np.float64)</div></pre></td></tr></table></figure><h3 id="代码实现公式原理"><a href="#代码实现公式原理" class="headerlink" title="代码实现公式原理"></a>代码实现公式原理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> statistics <span class="keyword">import</span> mean</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">best_fit_slope_and_intercept</span><span class="params">(xs,ys)</span>:</span></div><div class="line">    </div><div class="line">    <span class="comment">#实现m参数，两种实现方法</span></div><div class="line"><span class="comment">#m = (mean(xs)*mean(ys) - mean(xs*ys)) / (mean(xs)*mean(xs) - mean(xs*xs))</span></div><div class="line">    m = (mean(xs)*mean(ys) - mean(xs*ys)) / (mean(xs)**<span class="number">2</span> - mean(xs**<span class="number">2</span>))</div><div class="line">    <span class="comment">#实现b参数</span></div><div class="line">    b = mean(ys)-m*mean(xs)</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> m,b</div></pre></td></tr></table></figure><h3 id="画图预测展示"><a href="#画图预测展示" class="headerlink" title="画图预测展示"></a>画图预测展示</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line">m,b = best_fit_slope_and_intercept(xs,ys)</div><div class="line"></div><div class="line">regression_line = [(m*x)+b <span class="keyword">for</span> x <span class="keyword">in</span> xs] <span class="comment">#y(x)的实现</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">#趋势直线点向</span></div><div class="line">predict_x = <span class="number">9</span></div><div class="line">predict_y = (m*predict_x)+b</div><div class="line"></div><div class="line"><span class="comment">#散点图</span></div><div class="line">plt.scatter(xs,ys)</div><div class="line">plt.scatter(predict_x,predict_y)</div><div class="line">plt.plot(xs,regression_line) <span class="comment">#直线描绘</span></div><div class="line">plt.show()</div></pre></td></tr></table></figure><p>如图：</p><p><img src="http://smartjpa.com/Figure_1.png" alt=""></p><p>这样就完成任务了。</p><h2 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> statistics <span class="keyword">import</span> mean</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line">xs = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],dtype=np.float64)</div><div class="line">ys = np.array([<span class="number">5</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>],dtype=np.float64)</div><div class="line"><span class="comment"># print(xs,ys)</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">best_fit_slope_and_intercept</span><span class="params">(xs,ys)</span>:</span></div><div class="line">    </div><div class="line"></div><div class="line"><span class="comment">#m = (mean(xs)*mean(ys) - mean(xs*ys)) / (mean(xs)*mean(xs) - mean(xs*xs))</span></div><div class="line">    m = (mean(xs)*mean(ys) - mean(xs*ys)) / (mean(xs)**<span class="number">2</span> - mean(xs**<span class="number">2</span>))</div><div class="line">    b = mean(ys)-m*mean(xs)</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> m,b</div><div class="line"></div><div class="line">m,b = best_fit_slope_and_intercept(xs,ys)</div><div class="line"></div><div class="line">regression_line = [(m*x)+b <span class="keyword">for</span> x <span class="keyword">in</span> xs] <span class="comment">#y(x)的实现</span></div><div class="line"></div><div class="line">predict_x = <span class="number">9</span></div><div class="line">predict_y = (m*predict_x)+b</div><div class="line"></div><div class="line"></div><div class="line">plt.scatter(xs,ys)</div><div class="line">plt.scatter(predict_x,predict_y)</div><div class="line">plt.plot(xs,regression_line) <span class="comment">#直线描绘</span></div><div class="line">plt.show()</div></pre></td></tr></table></figure><h2 id="铺助理解链接"><a href="#铺助理解链接" class="headerlink" title="铺助理解链接"></a>铺助理解链接</h2><ul><li><p><a href="http://www.runoob.com/python/python-operators.html" target="_blank" rel="external">Python 运算符</a></p></li><li><p><a href="https://pythoncaff.com/docs/pymotw/statistics-statistical-calculations/106" target="_blank" rel="external">statistics — 统计学计算</a></p></li></ul><h1 id="补充R平方理论以及检验假设"><a href="#补充R平方理论以及检验假设" class="headerlink" title="补充R平方理论以及检验假设"></a>补充R平方理论以及检验假设</h1><p>强烈建议查看书籍学习了解相关的统计知识：</p><blockquote><p>商务与经济统计：<a href="https://pan.baidu.com/s/1O9G7l4QbeqOPsPs_90lFGA" target="_blank" rel="external">https://pan.baidu.com/s/1O9G7l4QbeqOPsPs_90lFGA</a></p></blockquote><p>这是一本好书。</p><h2 id="关于R平方理论"><a href="#关于R平方理论" class="headerlink" title="关于R平方理论"></a>关于R平方理论</h2><p>又称<em>决定系数/判定系数</em>。这是检验一个线性回归中<code>y</code>变量的变差与<code>x</code>变量的变差比例的系数，比例越大说明这个线性方程的拟合效果越好(可简单的理解为，它就是衡量一个线性回归算法的拟合精确度的)。它与相关系数也是有关系的。</p><blockquote><p><a href="https://wenku.baidu.com/view/2cad65f24afe04a1b171de05.html" target="_blank" rel="external">可查看百度文库的解释</a></p></blockquote><p>就不再多说了，这篇文章不是给小白看的教程，只注重实践部分。</p><h3 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h3><p>图一：</p><p><img src="http://smartjpa.com/coefficient-of-determination-r-squared.png" alt=""></p><p>这个公式还可变换为：</p><p><img src="http://smartjpa.com/v2-254f5004fb3ceaf68a6366ec593c1a63_hd.jpg" alt=""></p><p><img src="http://smartjpa.com/v2-dd32ad2965e1bdeeefa3431c96c89357_hd.jpg" alt=""></p><p>其中<code>r^2 = SSR/SST = 1 - SSE/SST</code>亦成立，所以这里的<code>r^2 = SSR/SST = 1 - SSE/SST</code>公式即对应着图一的公式，这样就好理解下面写的代码了。</p><p>目的是检验上方的<code>ys</code>取值(即测试数据点的坐标y轴线的取值点)与训练得出的<code>y(x)</code>(即上方程序中的<code>regression_line</code>)的拟合效果如何(会有一个量化值出现)。</p><blockquote><p>可参考：</p><p><a href="https://zhuanlan.zhihu.com/p/32335608" target="_blank" rel="external">线性回归中的相关度和决定系数</a></p><p><a href="https://ww2.mathworks.cn/help/stats/coefficient-of-determination-r-squared.html" target="_blank" rel="external">Coefficient of Determination (R-Squared)</a></p></blockquote><h3 id="代码实现演示"><a href="#代码实现演示" class="headerlink" title="代码实现演示"></a>代码实现演示</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#平方误差函数</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">squared_error</span><span class="params">(ys_orig, ys_line)</span>:</span></div><div class="line">    <span class="keyword">return</span> sum((ys_line-ys_orig)**<span class="number">2</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">coefficient_of_determination</span><span class="params">(ys_orig, ys_line)</span>:</span></div><div class="line">    y_mean_line = [mean(ys_orig) <span class="keyword">for</span> y <span class="keyword">in</span> ys_orig]</div><div class="line">    squared_error_regr = squared_error(ys_orig, ys_line) <span class="comment">#SSE</span></div><div class="line">    squared_error_y_mean = squared_error(y_mean_line, ys_orig) <span class="comment">#SST</span></div><div class="line">    <span class="keyword">return</span> <span class="number">1</span> - (squared_error_regr / squared_error_y_mean)</div><div class="line">    print(y_mean_line)</div><div class="line"></div><div class="line">r_squared = coefficient_of_determination(ys, regression_line)</div><div class="line">print(r_squared)</div></pre></td></tr></table></figure><p>代入以上完整代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> statistics <span class="keyword">import</span> mean</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line">xs = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],dtype=np.float64)</div><div class="line">ys = np.array([<span class="number">5</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>],dtype=np.float64)</div><div class="line"><span class="comment"># print(xs,ys)</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">best_fit_slope_and_intercept</span><span class="params">(xs,ys)</span>:</span></div><div class="line">    </div><div class="line"></div><div class="line"><span class="comment">#m = (mean(xs)*mean(ys) - mean(xs*ys)) / (mean(xs)*mean(xs) - mean(xs*xs))</span></div><div class="line">    m = (mean(xs)*mean(ys) - mean(xs*ys)) / (mean(xs)**<span class="number">2</span> - mean(xs**<span class="number">2</span>))</div><div class="line">    b = mean(ys)-m*mean(xs)</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> m,b</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">squared_error</span><span class="params">(ys_orig, ys_line)</span>:</span></div><div class="line">    <span class="keyword">return</span> sum((ys_line-ys_orig)**<span class="number">2</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">coefficient_of_determination</span><span class="params">(ys_orig, ys_line)</span>:</span></div><div class="line">    y_mean_line = [mean(ys_orig) <span class="keyword">for</span> y <span class="keyword">in</span> ys_orig]</div><div class="line">    squared_error_regr = squared_error(ys_orig, ys_line) <span class="comment">#SSE</span></div><div class="line">    squared_error_y_mean = squared_error(y_mean_line, ys_orig) <span class="comment">#SST</span></div><div class="line">    <span class="keyword">return</span> <span class="number">1</span> - (squared_error_regr / squared_error_y_mean)</div><div class="line">    print(y_mean_line)</div><div class="line"></div><div class="line">m,b = best_fit_slope_and_intercept(xs,ys)</div><div class="line"></div><div class="line">regression_line = [(m*x)+b <span class="keyword">for</span> x <span class="keyword">in</span> xs] <span class="comment">#y(x)的实现</span></div><div class="line"></div><div class="line">r_squared = coefficient_of_determination(ys, regression_line)</div><div class="line">print(r_squared)</div><div class="line"></div><div class="line"><span class="comment">#predict_x = 9</span></div><div class="line"><span class="comment">#predict_y = (m*predict_x)+b</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">#plt.scatter(xs,ys)</span></div><div class="line"><span class="comment">#plt.scatter(predict_x,predict_y)</span></div><div class="line"><span class="comment">#plt.plot(xs,regression_line) #直线描绘</span></div><div class="line"><span class="comment">#plt.show()</span></div></pre></td></tr></table></figure><blockquote><p>将会输出一个<code>R</code>的平方值，用以衡量拟合效果如何。</p></blockquote><h2 id="关于检验假设"><a href="#关于检验假设" class="headerlink" title="关于检验假设"></a>关于检验假设</h2><p>关于检验假设，这是一个可检验数据是否符合相关算法的一个验证，也可理解为先假设，然后去验证对不对(验证假设对不对)。这可与关于R平方理论(输出效果量化值)结合，从而可得出算法对于多类不同数据的拟合效果如何。</p><p>在此之后将通过伪随机生成器(可理解只要是计算机生成的随机数都是伪随机数)来进行一段实例演示。</p><blockquote><p><a href="https://blog.csdn.net/czc1997/article/details/78167705" target="_blank" rel="external">随机数：真随机数和伪随机数</a></p></blockquote><h3 id="代码实现演示-1"><a href="#代码实现演示-1" class="headerlink" title="代码实现演示"></a>代码实现演示</h3><p>这里既是一个简单的随机数据生成器，与相关性、方差有关，为其中的参数选择。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> random</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">#数据量的多少，方差，平均每个点步骤(与相关性的取值有关)，相关性设定,默认无相关性</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dataset</span><span class="params">(hm, variance, step=<span class="number">2</span>, correlation=False)</span>:</span></div><div class="line">    val = <span class="number">1</span> <span class="comment">#初始值</span></div><div class="line">    ys = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(hm):</div><div class="line">        y = val + random.randrange(-variance,variance)</div><div class="line">        ys.append(y)</div><div class="line">        <span class="comment">#若为正相关</span></div><div class="line">        <span class="keyword">if</span> correlation <span class="keyword">and</span> correlation == <span class="string">'pos'</span>:</div><div class="line">            val += step</div><div class="line">        <span class="keyword">elif</span> correlation <span class="keyword">and</span> correlation ==<span class="string">'neg'</span>:</div><div class="line">            val -= step</div><div class="line">    xs = [i <span class="keyword">for</span> i <span class="keyword">in</span> range(len(ys))] <span class="comment">#xs为平常的顺序取值数</span></div><div class="line">    </div><div class="line">    <span class="keyword">return</span> np.array(xs, dtype=np.float64), np.array(ys, dtype=np.float64)</div><div class="line"></div><div class="line">xs, ys = create_dataset(<span class="number">40</span>, <span class="number">40</span>, <span class="number">2</span>, correlation=<span class="string">'pos'</span>)</div></pre></td></tr></table></figure><h2 id="完整代码-1"><a href="#完整代码-1" class="headerlink" title="完整代码"></a>完整代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> statistics <span class="keyword">import</span> mean</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> random</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line"><span class="comment"># xs = np.array([1,2,3,4,5,6],dtype=np.float64)</span></div><div class="line"><span class="comment"># ys = np.array([5,4,6,5,6,7],dtype=np.float64)</span></div><div class="line"></div><div class="line"><span class="comment">#数据量的多少，方差，平均每个点步骤(与相关性的取值有关)，相关性设定,默认无相关性</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dataset</span><span class="params">(hm, variance, step=<span class="number">2</span>, correlation=False)</span>:</span></div><div class="line">    val = <span class="number">1</span> <span class="comment">#初始值</span></div><div class="line">    ys = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(hm):</div><div class="line">        y = val + random.randrange(-variance,variance)</div><div class="line">        ys.append(y)</div><div class="line">        <span class="comment">#若为正相关</span></div><div class="line">        <span class="keyword">if</span> correlation <span class="keyword">and</span> correlation == <span class="string">'pos'</span>:</div><div class="line">            val += step</div><div class="line">        <span class="keyword">elif</span> correlation <span class="keyword">and</span> correlation ==<span class="string">'neg'</span>:</div><div class="line">            val -= step</div><div class="line">    xs = [i <span class="keyword">for</span> i <span class="keyword">in</span> range(len(ys))] <span class="comment">#xs为平常的顺序取值数</span></div><div class="line">    </div><div class="line">    <span class="keyword">return</span> np.array(xs, dtype=np.float64), np.array(ys, dtype=np.float64)</div><div class="line">            </div><div class="line">    </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">best_fit_slope_and_intercept</span><span class="params">(xs,ys)</span>:</span></div><div class="line">    </div><div class="line">    <span class="comment">#实现m参数</span></div><div class="line">    <span class="comment">#m = (mean(xs)*mean(ys) - mean(xs*ys)) / (mean(xs)*mean(xs) - mean(xs*xs))</span></div><div class="line">    m = (mean(xs)*mean(ys) - mean(xs*ys)) / (mean(xs)**<span class="number">2</span> - mean(xs**<span class="number">2</span>))</div><div class="line">    <span class="comment">#实现b参数</span></div><div class="line">    b = mean(ys)-m*mean(xs)</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> m,b</div><div class="line"></div><div class="line"><span class="comment">#平方误差函数</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">squared_error</span><span class="params">(ys_orig, ys_line)</span>:</span></div><div class="line">    <span class="keyword">return</span> sum((ys_line-ys_orig)**<span class="number">2</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">coefficient_of_determination</span><span class="params">(ys_orig, ys_line)</span>:</span></div><div class="line">    y_mean_line = [mean(ys_orig) <span class="keyword">for</span> y <span class="keyword">in</span> ys_orig]</div><div class="line">    squared_error_regr = squared_error(ys_orig, ys_line) <span class="comment">#SSE</span></div><div class="line">    squared_error_y_mean = squared_error(y_mean_line, ys_orig) <span class="comment">#SST</span></div><div class="line">    <span class="keyword">return</span> <span class="number">1</span> - (squared_error_regr / squared_error_y_mean)</div><div class="line">    print(y_mean_line)</div><div class="line"></div><div class="line">xs, ys = create_dataset(<span class="number">40</span>, <span class="number">40</span>, <span class="number">2</span>, correlation=<span class="string">'pos'</span>)</div><div class="line">    </div><div class="line">m,b = best_fit_slope_and_intercept(xs,ys)</div><div class="line"></div><div class="line">regression_line = [(m*x)+b <span class="keyword">for</span> x <span class="keyword">in</span> xs] <span class="comment">#y(x)的实现</span></div><div class="line"></div><div class="line">r_squared = coefficient_of_determination(ys, regression_line)</div><div class="line">print(r_squared)</div><div class="line"></div><div class="line"><span class="comment">#趋势点向</span></div><div class="line">predict_x = <span class="number">9</span></div><div class="line">predict_y = (m*predict_x)+b</div><div class="line"></div><div class="line"><span class="comment">#散点图</span></div><div class="line">plt.scatter(xs,ys)</div><div class="line">plt.scatter(predict_x,predict_y)</div><div class="line">plt.plot(xs,regression_line) <span class="comment">#直线描绘</span></div><div class="line">plt.show()</div></pre></td></tr></table></figure><blockquote><p><a href="http://www.runoob.com/python/func-number-randrange.html" target="_blank" rel="external">Python randrange() 函数</a></p></blockquote><h2 id="结果展示"><a href="#结果展示" class="headerlink" title="结果展示"></a>结果展示</h2><p>会输出一个<code>R</code>平方值和一张由于随机数据为基础的训练图表。</p><p><img src="http://smartjpa.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-20%20%E4%B8%8B%E5%8D%8810.03.18.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/V59bYfIomVk&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; encrypted-media&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;本来不想写太多关于这方面的基础知识的，但是为了加强理解，我想不妨直接写博文记录也是一个好的选择，也可以顺便帮助需要的人，何乐而不为呢？&lt;/p&gt;
&lt;p&gt;那么开始吧。我在原课程的基础上进行那么一点点修改。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这是我学习的相应的课程地址：&lt;a href=&quot;https://pythonprogramming.net/how-to-program-best-fit-line-machine-learning-tutorial/?completed=/how-to-program-best-fit-line-slope-machine-learning-tutorial/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://pythonprogramming.net/how-to-program-best-fit-line-machine-learning-tutorial/?completed=/how-to-program-best-fit-line-slope-machine-learning-tutorial/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这不是一个小白教程，需要自行取了解一些基础知识，基础知识我仅仅是一笔带过。&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/categories/Python/"/>
    
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>python机器学习系列：预测房价并且可视化</title>
    <link href="https://liujunjie11.github.io/2018/10/18/python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%9A%E9%A2%84%E6%B5%8B%E6%88%BF%E4%BB%B7%E5%B9%B6%E4%B8%94%E5%8F%AF%E8%A7%86%E5%8C%96/"/>
    <id>https://liujunjie11.github.io/2018/10/18/python机器学习系列：预测房价并且可视化/</id>
    <published>2018-10-18T10:38:51.000Z</published>
    <updated>2018-11-13T12:33:17.698Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章不是给纯粹的小白看的，需要一定的基础，需要小白补充一定的基础知识，在我的博客有<a href="http://liujunworld.com/2018/09/16/%E5%88%9D%E5%AD%A6%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8D%97/" target="_blank" rel="external">相关的资源</a>介绍。</p><p>在这里记录下这篇文章时因为很实用，并且也希望以此帮助需要的人。</p><p>这是我在<em>YouTube</em>上学习到的。</p><iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/QLVMqwpOLPk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe><ul><li>中文地址(不全)：<a href="https://www.yxgapp.com/channel/349.html" target="_blank" rel="external">https://www.yxgapp.com/channel/349.html</a></li></ul><blockquote><p>对应的网页课程地址在此：<a href="https://pythonprogramming.net/forecasting-predicting-machine-learning-tutorial/" target="_blank" rel="external">https://pythonprogramming.net/forecasting-predicting-machine-learning-tutorial/</a></p></blockquote><p>在作者的基础上进行了一点点的改动。说明一下：<strong>相关的库自行安装，就不一一废话了。</strong></p><a id="more"></a><h1 id="项目开始"><a href="#项目开始" class="headerlink" title="项目开始"></a>项目开始</h1><p><strong>项目过程：从开放的数据接口拿到数据，并且做简单的数据处理，自行做好数据标签用于算法训练，之后在利用相关的模块做好预测得到的数值与相应的时间值的对接，得出数据的图表(包括预测部分)，项目完成。</strong></p><h2 id="获取数据以及简单数据处理"><a href="#获取数据以及简单数据处理" class="headerlink" title="获取数据以及简单数据处理"></a>获取数据以及简单数据处理</h2><p>代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> quandl,math</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</div><div class="line"></div><div class="line"><span class="comment">#获取公共数据接口</span></div><div class="line">df = quandl.get(<span class="string">"WIKI/GOOGL"</span>)</div><div class="line"></div><div class="line"><span class="comment">#简单的数据特征处理、整理，目的是得出“标签”特征列（因为仅仅是做到实践的效果，所以就不多说了，看代码便知）。</span></div><div class="line">df = df[[<span class="string">'Adj. Open'</span>, <span class="string">'Adj. High'</span>, <span class="string">'Adj. Low'</span>, <span class="string">'Adj. Close'</span>, <span class="string">'Adj. Volume'</span>]]  <span class="comment">#取用时需要用大括号</span></div><div class="line">df[<span class="string">'HL_PCT'</span>] = (df[<span class="string">'Adj. High'</span>] - df[<span class="string">'Adj. Close'</span>]) / df[<span class="string">'Adj. Close'</span>] * <span class="number">100.0</span></div><div class="line">df[<span class="string">'PCT_change'</span>] = (df[<span class="string">'Adj. Close'</span>] - df[<span class="string">'Adj. Open'</span>]) /df[<span class="string">'Adj. Open'</span>] * <span class="number">100.0</span></div><div class="line"></div><div class="line">df = df[[<span class="string">'Adj. Close'</span>, <span class="string">'Adj. Volume'</span>,<span class="string">'HL_PCT'</span>,<span class="string">'PCT_change'</span>]]</div><div class="line"></div><div class="line">forecast_col = <span class="string">'Adj. Close'</span></div><div class="line">df.fillna(value=<span class="number">-99999</span>, inplace=<span class="keyword">True</span>)</div><div class="line">forecast_out = int(math.ceil(<span class="number">0.01</span> * len(df)))</div><div class="line"><span class="comment">#得出标签特征列，以便直接用于训练</span></div><div class="line">df[<span class="string">'label'</span>] = df[forecast_col].shift(-forecast_out)</div></pre></td></tr></table></figure><blockquote><p>关于<a href="https://www.quandl.com" target="_blank" rel="external">quandl</a>,是个公开的数据网站，有免费的，也有收费的，它有很好的支持python的数据接口。可用<code>pip install quandl</code>下载相关的支持模块。<strong>如果有时获取数据出错了，重新运行直到没错误出现为止。</strong></p></blockquote><h2 id="算法预测"><a href="#算法预测" class="headerlink" title="算法预测"></a>算法预测</h2><p>代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">X = np.array(df.drop([<span class="string">'label'</span>], <span class="number">1</span>))</div><div class="line">X = preprocessing.scale(X)</div><div class="line"></div><div class="line"><span class="comment">#这里是取数据的后面一小部分用于预测得出的数值使用</span></div><div class="line">X_lately = X[-forecast_out:]</div><div class="line">X = X[:-forecast_out]</div><div class="line"></div><div class="line">df.dropna(inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">y = np.array(df[<span class="string">'label'</span>])</div><div class="line"></div><div class="line"><span class="comment">#数据分割</span></div><div class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</div><div class="line">clf = LinearRegression(n_jobs=<span class="number">-1</span>)</div><div class="line">clf.fit(X_train, y_train)</div><div class="line"><span class="comment">#预测准确性</span></div><div class="line">confidence = clf.score(X_test, y_test)</div><div class="line"></div><div class="line"><span class="comment">#最后预测的数值部分</span></div><div class="line">forecast_set = clf.predict(X_lately)</div></pre></td></tr></table></figure><blockquote><p>这里是简单的预测部分了，其中有一些简单的数据处理部分。</p></blockquote><h2 id="时间与预测值的对应以及图表的描绘"><a href="#时间与预测值的对应以及图表的描绘" class="headerlink" title="时间与预测值的对应以及图表的描绘"></a>时间与预测值的对应以及图表的描绘</h2><p>代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> datetime</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line"><span class="comment">#matplotlib的美化图表风格</span></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line"><span class="comment">#预测标签</span></div><div class="line">df[<span class="string">'Forecast'</span>] = np.nan</div><div class="line"></div><div class="line"><span class="comment">#获取源数据最后一天日期</span></div><div class="line">last_date = df.iloc[<span class="number">-1</span>].name</div><div class="line">last_unix = last_date.timestamp()</div><div class="line">one_day = <span class="number">86400</span> <span class="comment">#一天的时间戳</span></div><div class="line">next_unix = last_unix + one_day</div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> forecast_set:</div><div class="line">    next_date = datetime.datetime.fromtimestamp(next_unix)</div><div class="line">    next_unix += <span class="number">86400</span></div><div class="line">    <span class="comment">#将此日期对应的前面五列不相干的均设为nan，而仅仅加上预测的数值，即仅仅有相应的时间对应相应的预测数值</span></div><div class="line">    df.loc[next_date] = [np.nan <span class="keyword">for</span> _ <span class="keyword">in</span> range(len(df.columns)<span class="number">-1</span>)]+[i] <span class="comment">#如果这里不理解的话，可以查看df的head和tail部分试试，就能一目了然了</span></div><div class="line"></div><div class="line"><span class="comment">#图表描绘</span></div><div class="line">df[<span class="string">'Adj. Close'</span>].plot()</div><div class="line">df[<span class="string">'Forecast'</span>].plot()</div><div class="line">plt.legend(loc=<span class="number">4</span>)</div><div class="line">plt.xlabel(<span class="string">'Date'</span>)</div><div class="line">plt.ylabel(<span class="string">'Price'</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><blockquote><p>这里有些难理解，但是其实很好理解，只是一些代码根本没见到过，所以导致阅读障碍。</p></blockquote><p>估计有人不理解这段<code>df.loc[next_date] = [np.nan for _ in range(len(df.columns)-1)]+[i]</code>代码，我来简单说明一下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> forecast_set:</div><div class="line">    next_date = datetime.datetime.fromtimestamp(next_unix)</div><div class="line">    next_unix += <span class="number">86400</span></div><div class="line">    df.loc[next_date] = [np.nan <span class="keyword">for</span> _ <span class="keyword">in</span> range(len(df.columns)<span class="number">-1</span>)]+[i]</div><div class="line"></div><div class="line">print(df.head())   </div><div class="line"></div><div class="line">输出：</div><div class="line"></div><div class="line">         Adj. Close  Adj. Volume   HL_PCT  PCT_change   label      Forecast</div><div class="line">Date                                                                          </div><div class="line"><span class="number">2004</span><span class="number">-08</span><span class="number">-19</span>   <span class="number">50.322842</span>   <span class="number">44659000.0</span>  <span class="number">3.712563</span>    <span class="number">0.324968</span>  <span class="number">69.078238</span>       NaN</div><div class="line"><span class="number">2004</span><span class="number">-08</span><span class="number">-20</span>   <span class="number">54.322689</span>   <span class="number">22834300.0</span>  <span class="number">0.710922</span>    <span class="number">7.227007</span>  <span class="number">67.839414</span>       NaN</div><div class="line"><span class="number">2004</span><span class="number">-08</span><span class="number">-23</span>   <span class="number">54.869377</span>   <span class="number">18256100.0</span>  <span class="number">3.729433</span>   <span class="number">-1.227880</span>  <span class="number">68.912727</span>       NaN</div><div class="line"><span class="number">2004</span><span class="number">-08</span><span class="number">-24</span>   <span class="number">52.597363</span>   <span class="number">15247300.0</span>  <span class="number">6.417469</span>   <span class="number">-5.726357</span>  <span class="number">70.668146</span>       NaN</div><div class="line"><span class="number">2004</span><span class="number">-08</span><span class="number">-25</span>   <span class="number">53.164113</span>    <span class="number">9188600.0</span>  <span class="number">1.886792</span>    <span class="number">1.183658</span>  <span class="number">71.219849</span>       NaN </div><div class="line"></div><div class="line"></div><div class="line">print(df.tail())</div><div class="line"></div><div class="line">输出：</div><div class="line"></div><div class="line">                     Adj. Close  Adj. Volume  HL_PCT  PCT_change  label  \</div><div class="line">Date                                                                      </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-08</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>         NaN          NaN     NaN         NaN    NaN   </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-09</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>         NaN          NaN     NaN         NaN    NaN   </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-10</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>         NaN          NaN     NaN         NaN    NaN   </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-11</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>         NaN          NaN     NaN         NaN    NaN   </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-12</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>         NaN          NaN     NaN         NaN    NaN   </div><div class="line"></div><div class="line">                        Forecast  </div><div class="line">Date                              </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-08</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>  <span class="number">1113.922012</span>  </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-09</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>  <span class="number">1071.104993</span>  </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-10</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>  <span class="number">1043.810593</span>  </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-11</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>  <span class="number">1073.778780</span>  </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-12</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>  <span class="number">1022.639186</span></div></pre></td></tr></table></figure><blockquote><p>就是这样，已经很明了了，就是仅仅为了让预测的时间对应预测的房价数值而已。</p></blockquote><h3 id="什么是时间戳"><a href="#什么是时间戳" class="headerlink" title="什么是时间戳?"></a>什么是时间戳?</h3><p>简单说说：时间戳是自1970年1月1日（00:00:00 UTC/GMT）以来的秒数。它也被称为Unix时间戳（Unix Timestam、Unix epoch、POSIX time、Unix timestamp）是从1970年1月1日（UTC/GMT的午夜）开始所经过的秒数，不考虑闰秒。</p><p>  UNIX时间戳的0按照ISO 8601规范为：1970-01-01T00:00:00Z</p><p>  一个小时表示为UNIX时间戳格式为：3600秒；一天表示为UNIX时间戳为86400秒，闰秒不计算。</p><blockquote><p>来自：<a href="http://www.htmer.com/article/420.htm" target="_blank" rel="external">http://www.htmer.com/article/420.htm</a></p></blockquote><h2 id="完整代码："><a href="#完整代码：" class="headerlink" title="完整代码："></a>完整代码：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> quandl,math,datetime</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing,svm</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line">df = quandl.get(<span class="string">"WIKI/GOOGL"</span>)</div><div class="line"></div><div class="line">df = df[[<span class="string">'Adj. Open'</span>, <span class="string">'Adj. High'</span>, <span class="string">'Adj. Low'</span>, <span class="string">'Adj. Close'</span>, <span class="string">'Adj. Volume'</span>]] <span class="comment">#取用时需要用大括号</span></div><div class="line">df[<span class="string">'HL_PCT'</span>] = (df[<span class="string">'Adj. High'</span>] - df[<span class="string">'Adj. Close'</span>]) / df[<span class="string">'Adj. Close'</span>] * <span class="number">100.0</span></div><div class="line">df[<span class="string">'PCT_change'</span>] = (df[<span class="string">'Adj. Close'</span>] - df[<span class="string">'Adj. Open'</span>]) /df[<span class="string">'Adj. Open'</span>] * <span class="number">100.0</span></div><div class="line"></div><div class="line">df = df[[<span class="string">'Adj. Close'</span>, <span class="string">'Adj. Volume'</span>,<span class="string">'HL_PCT'</span>,<span class="string">'PCT_change'</span>]]</div><div class="line"></div><div class="line">forecast_col = <span class="string">'Adj. Close'</span></div><div class="line"></div><div class="line">df.fillna(value=<span class="number">-99999</span>, inplace=<span class="keyword">True</span>)</div><div class="line">forecast_out = int(math.ceil(<span class="number">0.01</span> * len(df)))</div><div class="line">df[<span class="string">'label'</span>] = df[forecast_col].shift(-forecast_out)</div><div class="line"></div><div class="line">X = np.array(df.drop([<span class="string">'label'</span>], <span class="number">1</span>))</div><div class="line">X = preprocessing.scale(X)</div><div class="line">X_lately = X[-forecast_out:]</div><div class="line">X = X[:-forecast_out]</div><div class="line"></div><div class="line">df.dropna(inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">y = np.array(df[<span class="string">'label'</span>])</div><div class="line"></div><div class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</div><div class="line">clf = LinearRegression(n_jobs=<span class="number">-1</span>)</div><div class="line">clf.fit(X_train, y_train)</div><div class="line">confidence = clf.score(X_test, y_test)</div><div class="line"></div><div class="line">forecast_set = clf.predict(X_lately)</div><div class="line">df[<span class="string">'Forecast'</span>] = np.nan</div><div class="line"></div><div class="line">last_date = df.iloc[<span class="number">-1</span>].name</div><div class="line">last_unix = last_date.timestamp()</div><div class="line">one_day = <span class="number">86400</span></div><div class="line">next_unix = last_unix + one_day</div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> forecast_set:</div><div class="line">    next_date = datetime.datetime.fromtimestamp(next_unix)</div><div class="line">    next_unix += <span class="number">86400</span></div><div class="line">    df.loc[next_date] = [np.nan <span class="keyword">for</span> _ <span class="keyword">in</span> range(len(df.columns)<span class="number">-1</span>)]+[i]</div><div class="line"></div><div class="line">df[<span class="string">'Adj. Close'</span>].plot()</div><div class="line">df[<span class="string">'Forecast'</span>].plot()</div><div class="line">plt.legend(loc=<span class="number">4</span>)</div><div class="line">plt.xlabel(<span class="string">'Date'</span>)</div><div class="line">plt.ylabel(<span class="string">'Price'</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><h2 id="最终效果展示"><a href="#最终效果展示" class="headerlink" title="最终效果展示"></a>最终效果展示</h2><p><img src="http://smartjpa.com/Oct-18-2018%2020-13-50.gif" alt=""></p><blockquote><p>可以查看到预测的部分展示。</p></blockquote><h2 id="补助链接"><a href="#补助链接" class="headerlink" title="补助链接"></a>补助链接</h2><p>这里是帮助理解的链接。</p><ul><li><p><a href="https://blog.csdn.net/brucewong0516/article/details/80157639" target="_blank" rel="external">python pandas库常用函数之shift详解</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/37891729" target="_blank" rel="external">样式美化matplotlib.pyplot.style.use定制画布风格</a></p></li><li><p><a href="http://www.wklken.me/posts/2015/03/03/python-base-datetime.html#6-huo-qu-ben-zhou-ben-yue-shang-yue-zui-hou-yi-tian" target="_blank" rel="external">PYTHON-基础-时间日期处理小结</a></p></li><li><p><a href="https://morvanzhou.github.io/tutorials/data-manipulation/np-pd/3-2-pd-indexing/" target="_blank" rel="external">Pandas 选择数据</a></p></li><li><p><a href="https://morvanzhou.github.io/tutorials/data-manipulation/plt/2-5-lagend/" target="_blank" rel="external">Legend 图例</a></p></li></ul><p>值得说明一下<em>Legend 图例</em>的一些知识：</p><p>使用<code>plt.legend(loc=n)</code>中<code>n</code>的选择代表什么：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="string">'best'</span> : <span class="number">0</span>,          </div><div class="line"><span class="string">'upper right'</span>  : <span class="number">1</span>,</div><div class="line"><span class="string">'upper left'</span>   : <span class="number">2</span>,</div><div class="line"><span class="string">'lower left'</span>   : <span class="number">3</span>,</div><div class="line"><span class="string">'lower right'</span>  : <span class="number">4</span>,</div><div class="line"><span class="string">'right'</span>        : <span class="number">5</span>,</div><div class="line"><span class="string">'center left'</span>  : <span class="number">6</span>,</div><div class="line"><span class="string">'center right'</span> : <span class="number">7</span>,</div><div class="line"><span class="string">'lower center'</span> : <span class="number">8</span>,</div><div class="line"><span class="string">'upper center'</span> : <span class="number">9</span>,</div><div class="line"><span class="string">'center'</span>       : <span class="number">10</span>。</div></pre></td></tr></table></figure><h1 id="补充添加序列化保存预测模型"><a href="#补充添加序列化保存预测模型" class="headerlink" title="补充添加序列化保存预测模型"></a>补充添加序列化保存预测模型</h1><p>添加了如何将预测代码序列化的过程加相关的代码。</p><p>序列化可简单理解为：先保存了这个预测的模型(序列化的过程)，然后我们可以拿出这个模型直接进行以后的预测(反序列化的过程)。</p><p>加上代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pickle</div><div class="line"></div><div class="line"><span class="keyword">with</span> open(<span class="string">'houseforecastmodel.pickle'</span>,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</div><div class="line">   <span class="comment">#下载模型</span></div><div class="line">   pickle.dump(clf,f)</div><div class="line"></div><div class="line">pickle_in = open(<span class="string">'houseforecastmodel.pickle'</span>,<span class="string">'rb'</span>)</div><div class="line">clf = pickle.load(pickle_in) <span class="comment">#加载模型</span></div></pre></td></tr></table></figure><p>完整代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> quandl,math,datetime</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing,svm</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> pickle</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line">df = quandl.get(<span class="string">"WIKI/GOOGL"</span>)</div><div class="line"></div><div class="line">df = df[[<span class="string">'Adj. Open'</span>, <span class="string">'Adj. High'</span>, <span class="string">'Adj. Low'</span>, <span class="string">'Adj. Close'</span>, <span class="string">'Adj. Volume'</span>]] <span class="comment">#取用时需要用大括号</span></div><div class="line">df[<span class="string">'HL_PCT'</span>] = (df[<span class="string">'Adj. High'</span>] - df[<span class="string">'Adj. Close'</span>]) / df[<span class="string">'Adj. Close'</span>] * <span class="number">100.0</span></div><div class="line">df[<span class="string">'PCT_change'</span>] = (df[<span class="string">'Adj. Close'</span>] - df[<span class="string">'Adj. Open'</span>]) /df[<span class="string">'Adj. Open'</span>] * <span class="number">100.0</span></div><div class="line"></div><div class="line">df = df[[<span class="string">'Adj. Close'</span>, <span class="string">'Adj. Volume'</span>,<span class="string">'HL_PCT'</span>,<span class="string">'PCT_change'</span>]]</div><div class="line"></div><div class="line">forecast_col = <span class="string">'Adj. Close'</span></div><div class="line"></div><div class="line">df.fillna(value=<span class="number">-99999</span>, inplace=<span class="keyword">True</span>)</div><div class="line">forecast_out = int(math.ceil(<span class="number">0.01</span> * len(df)))</div><div class="line">df[<span class="string">'label'</span>] = df[forecast_col].shift(-forecast_out)</div><div class="line"></div><div class="line">X = np.array(df.drop([<span class="string">'label'</span>], <span class="number">1</span>))</div><div class="line">X = preprocessing.scale(X)</div><div class="line">X_lately = X[-forecast_out:]</div><div class="line">X = X[:-forecast_out]</div><div class="line"></div><div class="line">df.dropna(inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">y = np.array(df[<span class="string">'label'</span>])</div><div class="line"></div><div class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</div><div class="line">clf = LinearRegression(n_jobs=<span class="number">-1</span>)</div><div class="line">clf.fit(X_train, y_train)</div><div class="line"></div><div class="line"><span class="keyword">with</span> open(<span class="string">'houseforecastmodel.pickle'</span>,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</div><div class="line">   <span class="comment">#下载模型</span></div><div class="line">   pickle.dump(clf,f)</div><div class="line"></div><div class="line">pickle_in = open(<span class="string">'houseforecastmodel.pickle'</span>,<span class="string">'rb'</span>)</div><div class="line">clf = pickle.load(pickle_in) <span class="comment">#加载模型</span></div><div class="line"></div><div class="line">confidence = clf.score(X_test, y_test)</div><div class="line"></div><div class="line">forecast_set = clf.predict(X_lately)</div><div class="line">df[<span class="string">'Forecast'</span>] = np.nan</div><div class="line"></div><div class="line">last_date = df.iloc[<span class="number">-1</span>].name</div><div class="line">last_unix = last_date.timestamp()</div><div class="line">one_day = <span class="number">86400</span></div><div class="line">next_unix = last_unix + one_day</div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> forecast_set:</div><div class="line">    next_date = datetime.datetime.fromtimestamp(next_unix)</div><div class="line">    next_unix += <span class="number">86400</span></div><div class="line">    df.loc[next_date] = [np.nan <span class="keyword">for</span> _ <span class="keyword">in</span> range(len(df.columns)<span class="number">-1</span>)]+[i]</div><div class="line"></div><div class="line">df[<span class="string">'Adj. Close'</span>].plot()</div><div class="line">df[<span class="string">'Forecast'</span>].plot()</div><div class="line">plt.legend(loc=<span class="number">4</span>)</div><div class="line">plt.xlabel(<span class="string">'Date'</span>)</div><div class="line">plt.ylabel(<span class="string">'Price'</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p>在运行一遍以上的代码之后，就可以直接从保存的文件来加载模型来预测数据啦，如下可测试：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> quandl,math,datetime</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing,svm</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> pickle</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line">df = quandl.get(<span class="string">"WIKI/GOOGL"</span>)</div><div class="line"></div><div class="line">df = df[[<span class="string">'Adj. Open'</span>, <span class="string">'Adj. High'</span>, <span class="string">'Adj. Low'</span>, <span class="string">'Adj. Close'</span>, <span class="string">'Adj. Volume'</span>]] <span class="comment">#取用时需要用大括号</span></div><div class="line">df[<span class="string">'HL_PCT'</span>] = (df[<span class="string">'Adj. High'</span>] - df[<span class="string">'Adj. Close'</span>]) / df[<span class="string">'Adj. Close'</span>] * <span class="number">100.0</span></div><div class="line">df[<span class="string">'PCT_change'</span>] = (df[<span class="string">'Adj. Close'</span>] - df[<span class="string">'Adj. Open'</span>]) /df[<span class="string">'Adj. Open'</span>] * <span class="number">100.0</span></div><div class="line"></div><div class="line">df = df[[<span class="string">'Adj. Close'</span>, <span class="string">'Adj. Volume'</span>,<span class="string">'HL_PCT'</span>,<span class="string">'PCT_change'</span>]]</div><div class="line"></div><div class="line">forecast_col = <span class="string">'Adj. Close'</span></div><div class="line"></div><div class="line">df.fillna(value=<span class="number">-99999</span>, inplace=<span class="keyword">True</span>)</div><div class="line">forecast_out = int(math.ceil(<span class="number">0.01</span> * len(df)))</div><div class="line">df[<span class="string">'label'</span>] = df[forecast_col].shift(-forecast_out)</div><div class="line"></div><div class="line">X = np.array(df.drop([<span class="string">'label'</span>], <span class="number">1</span>))</div><div class="line">X = preprocessing.scale(X)</div><div class="line">X_lately = X[-forecast_out:]</div><div class="line">X = X[:-forecast_out]</div><div class="line"></div><div class="line">df.dropna(inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">y = np.array(df[<span class="string">'label'</span>])</div><div class="line"></div><div class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</div><div class="line"><span class="comment">#clf = LinearRegression(n_jobs=-1)</span></div><div class="line"><span class="comment">#clf.fit(X_train, y_train)</span></div><div class="line"></div><div class="line"><span class="comment">#with open('houseforecastmodel.pickle','wb') as f:</span></div><div class="line">   <span class="comment">#下载模型</span></div><div class="line">   <span class="comment">#pickle.dump(clf,f)</span></div><div class="line"></div><div class="line">pickle_in = open(<span class="string">'houseforecastmodel.pickle'</span>,<span class="string">'rb'</span>)</div><div class="line">clf = pickle.load(pickle_in) <span class="comment">#加载模型</span></div><div class="line"></div><div class="line">confidence = clf.score(X_test, y_test)</div><div class="line"></div><div class="line">forecast_set = clf.predict(X_lately)</div><div class="line">df[<span class="string">'Forecast'</span>] = np.nan</div><div class="line"></div><div class="line">last_date = df.iloc[<span class="number">-1</span>].name</div><div class="line">last_unix = last_date.timestamp()</div><div class="line">one_day = <span class="number">86400</span></div><div class="line">next_unix = last_unix + one_day</div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> forecast_set:</div><div class="line">    next_date = datetime.datetime.fromtimestamp(next_unix)</div><div class="line">    next_unix += <span class="number">86400</span></div><div class="line">    df.loc[next_date] = [np.nan <span class="keyword">for</span> _ <span class="keyword">in</span> range(len(df.columns)<span class="number">-1</span>)]+[i]</div><div class="line"></div><div class="line">df[<span class="string">'Adj. Close'</span>].plot()</div><div class="line">df[<span class="string">'Forecast'</span>].plot()</div><div class="line">plt.legend(loc=<span class="number">4</span>)</div><div class="line">plt.xlabel(<span class="string">'Date'</span>)</div><div class="line">plt.ylabel(<span class="string">'Price'</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><blockquote><p>得出的结果与上方展示的一致。</p></blockquote><h2 id="了解pickle"><a href="#了解pickle" class="headerlink" title="了解pickle"></a>了解pickle</h2><ul><li><p><a href="https://morvanzhou.github.io/tutorials/python-basic/basic/13-08-pickle/" target="_blank" rel="external">pickle 保存数据</a></p></li><li><p><a href="https://docs.python.org/3/library/pickle.html" target="_blank" rel="external">pickle — Python object serialization</a></p></li><li><p><a href="https://www.jianshu.com/p/113f33ab6f31" target="_blank" rel="external">scikit-learn系列之如何存储和导入机器学习模型</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇文章不是给纯粹的小白看的，需要一定的基础，需要小白补充一定的基础知识，在我的博客有&lt;a href=&quot;http://liujunworld.com/2018/09/16/%E5%88%9D%E5%AD%A6%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8D%97/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;相关的资源&lt;/a&gt;介绍。&lt;/p&gt;
&lt;p&gt;在这里记录下这篇文章时因为很实用，并且也希望以此帮助需要的人。&lt;/p&gt;
&lt;p&gt;这是我在&lt;em&gt;YouTube&lt;/em&gt;上学习到的。&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/QLVMqwpOLPk&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; encrypted-media&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;ul&gt;
&lt;li&gt;中文地址(不全)：&lt;a href=&quot;https://www.yxgapp.com/channel/349.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://www.yxgapp.com/channel/349.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;对应的网页课程地址在此：&lt;a href=&quot;https://pythonprogramming.net/forecasting-predicting-machine-learning-tutorial/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://pythonprogramming.net/forecasting-predicting-machine-learning-tutorial/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在作者的基础上进行了一点点的改动。说明一下：&lt;strong&gt;相关的库自行安装，就不一一废话了。&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/categories/Python/"/>
    
      <category term="数据分析" scheme="https://liujunjie11.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="数据挖掘" scheme="https://liujunjie11.github.io/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Mac下安装lightGBM</title>
    <link href="https://liujunjie11.github.io/2018/10/16/Mac%E4%B8%8B%E5%AE%89%E8%A3%85lightGBM/"/>
    <id>https://liujunjie11.github.io/2018/10/16/Mac下安装lightGBM/</id>
    <published>2018-10-16T05:13:23.000Z</published>
    <updated>2018-11-13T12:33:44.057Z</updated>
    
    <content type="html"><![CDATA[<p>最近需要这个算法做点东西，在此记录一下安装的过程。</p><a id="more"></a><h1 id="安装过程"><a href="#安装过程" class="headerlink" title="安装过程"></a>安装过程</h1><p>用homebrew安装相关的插件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">brew install cmake</div><div class="line">brew install gcc --without-multilib</div></pre></td></tr></table></figure><blockquote><p>在安装之后如果在使用<code>cmake ..</code>命令行出现了关于在下载的<em>cmake</em>的相关的问题时，可以考虑<code>brew uninstall cmake</code>，然后重新下载。这种问题我就遇上了…</p></blockquote><p>下载好gcc之后，我配置了一下环境问题，如图：</p><p><img src="http://smartjpa.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-16%20%E4%B8%8B%E5%8D%881.25.10.png" alt=""></p><blockquote><p>使用命令行<code>vi ~/.bash_profile</code>配置环境变量问题。</p></blockquote><p>接下来是git下载相关的GitHub资源：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git <span class="built_in">clone</span> --recursive https://github.com/Microsoft/LightGBM</div></pre></td></tr></table></figure><p>依次使用下方命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> LightGBM</div><div class="line"><span class="built_in">export</span> CXX=g++-8 CC=gcc-8</div><div class="line">mkdir build </div><div class="line"><span class="built_in">cd</span> build</div><div class="line">cmake ..</div><div class="line">make -j4</div></pre></td></tr></table></figure><blockquote><p>这样只要相关的插件下载完全了，一般就没什么问题出现了。</p></blockquote><p>之后可以使用pip命令下载了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install --no-binary :all: lightgbm</div></pre></td></tr></table></figure><blockquote><p>由于不是很懂这个命令，我又使用了<code>pip install lightgbm</code>。</p></blockquote><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>如图：</p><p><img src="http://smartjpa.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-16%20%E4%B8%8B%E5%8D%881.23.55.png" alt=""></p><blockquote><p>用的是anaconda默认的python3环境。</p></blockquote><h1 id="遇到的错误问题"><a href="#遇到的错误问题" class="headerlink" title="遇到的错误问题"></a>遇到的错误问题</h1><p>如下类似问题：</p><pre><code>OSError: dlopen(/usr/local/lib/python3.6/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/gcc/lib/gcc/7/libgomp.1.dylib  Referenced from: /usr/local/lib/python3.6/site-packages/lightgbm/lib_lightgbm.so  Reason: image not found</code></pre><blockquote><p>解决方案：<a href="https://github.com/Microsoft/LightGBM/issues/1369" target="_blank" rel="external">https://github.com/Microsoft/LightGBM/issues/1369</a></p></blockquote><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li><p><a href="http://lightgbm.apachecn.org/cn/latest/Installation-Guide.html" target="_blank" rel="external">http://lightgbm.apachecn.org/cn/latest/Installation-Guide.html</a></p></li><li><p><a href="https://blog.csdn.net/fitzgerald0/article/details/78321527?utm_source=blogxgwz4" target="_blank" rel="external">https://blog.csdn.net/fitzgerald0/article/details/78321527?utm_source=blogxgwz4</a></p></li><li><p><a href="https://github.com/Microsoft/LightGBM/issues/1369smartjpa.com" target="_blank" rel="external">https://github.com/Microsoft/LightGBM/issues/1369smartjpa.com</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近需要这个算法做点东西，在此记录一下安装的过程。&lt;/p&gt;
    
    </summary>
    
      <category term="笔记" scheme="https://liujunjie11.github.io/categories/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="Mac" scheme="https://liujunjie11.github.io/categories/Mac/"/>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="LightGBM" scheme="https://liujunjie11.github.io/categories/LightGBM/"/>
    
    
      <category term="教程笔记" scheme="https://liujunjie11.github.io/tags/%E6%95%99%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Mac" scheme="https://liujunjie11.github.io/tags/Mac/"/>
    
      <category term="LightGBM" scheme="https://liujunjie11.github.io/tags/LightGBM/"/>
    
  </entry>
  
  <entry>
    <title>Mac上下载xgboost</title>
    <link href="https://liujunjie11.github.io/2018/10/15/Mac%E4%B8%8A%E4%B8%8B%E8%BD%BDxgboost/"/>
    <id>https://liujunjie11.github.io/2018/10/15/Mac上下载xgboost/</id>
    <published>2018-10-15T14:01:48.000Z</published>
    <updated>2018-11-13T12:34:01.945Z</updated>
    
    <content type="html"><![CDATA[<p>这会有事了，感觉有必要记录一下。</p><p>最近想搞搞<em>kaggle</em>的入门级比赛，参考他人的<em>kernel</em>用到了<em>xgboost</em>，但是安装时遇到了一些坑，特别是<a href="https://xgboost.readthedocs.io/en/latest/build.html" target="_blank" rel="external">官网的安装教程</a>…真的让人吐血，根本不能解决我要安装的欲望。以下是我参考了一些文章并且成功安装的经验记录。</p><a id="more"></a><h1 id="安装过程"><a href="#安装过程" class="headerlink" title="安装过程"></a>安装过程</h1><p>先用homebrew下载相关的依赖：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">brew install gcc --without-multilib</div></pre></td></tr></table></figure><blockquote><p>加上<code>--without-multilib</code>目的是开启默认不开启支持多线程的插件。</p></blockquote><p>然后git下载在GitHub上的xgboost：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git <span class="built_in">clone</span> --recursive https://github.com/dmlc/xgboost</div></pre></td></tr></table></figure><blockquote><p>最好下载在根目录。</p></blockquote><p>下载完成之后：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> xgboost</div></pre></td></tr></table></figure><p>修改相关的配置文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vi config.mk</div></pre></td></tr></table></figure><blockquote><p>实际上这个文件有好多个，我最终都修改成一致的了…如下图</p></blockquote><p><img src="http://smartjpa.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-16%20%E4%B8%8A%E5%8D%8810.25.58.png" alt=""></p><p>修改内容为，改成用homebrew下载的gcc版本目录地址：</p><pre><code>export CC = /usr/local/Cellar/gcc/8.2.0/bin/gcc-8export CXX = /usr/local/Cellar/gcc/8.2.0/bin/g++-8export MPICXX = /usr/local/Cellar/gcc/8.2.0/bin/mpicxx</code></pre><p>如图：</p><p><img src="http://smartjpa.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-16%20%E4%B8%8A%E5%8D%8810.27.14.png" alt=""></p><p>之后使用命令行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cp make/config.mk ./config.mk</div><div class="line">make -j4</div></pre></td></tr></table></figure><blockquote><p><code>-j4</code>是开启4个线程的意思。</p></blockquote><p>之后就是编译成包的过程了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> python-package</div><div class="line">   python setup.py install</div></pre></td></tr></table></figure><blockquote><p>我用的是anaconda的python版本。</p></blockquote><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>如图：</p><p><img src="http://smartjpa.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-16%20%E4%B8%8A%E5%8D%8810.31.22.png" alt=""></p><p>这样就大功告成了。</p><h1 id="期间遇到过的问题"><a href="#期间遇到过的问题" class="headerlink" title="期间遇到过的问题"></a>期间遇到过的问题</h1><h2 id="问题一："><a href="#问题一：" class="headerlink" title="问题一："></a>问题一：</h2><pre><code>XGBoostLibraryNotFound: Cannot find XGBoost Libarary in the candidate path, did you install compilers and run build.sh in root path?List of candidates:/home/dmlc/anaconda/lib/python3.6/site-packages/xgboost-0.4-py3.6.egg/xgboost/libxgboostwrapper.so/home/dmlc/anaconda/lib/python3.6/site-packages/xgboost-0.4-py3.6.egg/xgboost/../../wrapper/libxgboostwrapper.so/home/dmlc/anaconda/lib/python3.6/site-packages/xgboost-0.4-py3.6.egg/xgboost/./wrapper/libxgboostwrapper.so</code></pre><p>此类问题，可能是<code>git clone --recursive https://github.com/dmlc/xgboost</code>下载执行未完全。</p><h2 id="问题二"><a href="#问题二" class="headerlink" title="问题二"></a>问题二</h2><p>使用命令行<code>make -j4</code>时出现：</p><pre><code>clang: error: unsupported option &apos;-fopenmp&apos;</code></pre><p>如图：</p><p><img src="http://smartjpa.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-16%20%E4%B8%8A%E5%8D%8810.47.57.png" alt=""></p><p>解决方案：</p><pre><code>export CC = /usr/local/Cellar/gcc/8.2.0/bin/gcc-8export CXX = /usr/local/Cellar/gcc/8.2.0/bin/g++-8export MPICXX = /usr/local/Cellar/gcc/8.2.0/bin/mpicxx</code></pre><blockquote><p>这只是未能识别相关插件的问题，修改文件<code>config.mk</code>相关的部分如上即可。</p><p>在此参考了：<a href="https://stackoverflow.com/questions/36211018/clang-error-errorunsupported-option-fopenmp-on-mac-osx-el-capitan-buildin" target="_blank" rel="external">https://stackoverflow.com/questions/36211018/clang-error-errorunsupported-option-fopenmp-on-mac-osx-el-capitan-buildin</a></p></blockquote><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><ul><li><p><a href="https://www.jianshu.com/p/c2b0c3067d84" target="_blank" rel="external">https://www.jianshu.com/p/c2b0c3067d84</a></p></li><li><p><a href="https://www.jianshu.com/p/76ff402a8b58" target="_blank" rel="external">https://www.jianshu.com/p/76ff402a8b58</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/23996104" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/23996104</a><br>smartjpa.com</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这会有事了，感觉有必要记录一下。&lt;/p&gt;
&lt;p&gt;最近想搞搞&lt;em&gt;kaggle&lt;/em&gt;的入门级比赛，参考他人的&lt;em&gt;kernel&lt;/em&gt;用到了&lt;em&gt;xgboost&lt;/em&gt;，但是安装时遇到了一些坑，特别是&lt;a href=&quot;https://xgboost.readthedocs.io/en/latest/build.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;官网的安装教程&lt;/a&gt;…真的让人吐血，根本不能解决我要安装的欲望。以下是我参考了一些文章并且成功安装的经验记录。&lt;/p&gt;
    
    </summary>
    
      <category term="笔记" scheme="https://liujunjie11.github.io/categories/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="Mac" scheme="https://liujunjie11.github.io/categories/Mac/"/>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Xgboost" scheme="https://liujunjie11.github.io/categories/Xgboost/"/>
    
    
      <category term="教程笔记" scheme="https://liujunjie11.github.io/tags/%E6%95%99%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Mac" scheme="https://liujunjie11.github.io/tags/Mac/"/>
    
      <category term="Xgboost" scheme="https://liujunjie11.github.io/tags/Xgboost/"/>
    
  </entry>
  
  <entry>
    <title>思考意义</title>
    <link href="https://liujunjie11.github.io/2018/10/15/%E6%80%9D%E8%80%83%E6%84%8F%E4%B9%89/"/>
    <id>https://liujunjie11.github.io/2018/10/15/思考意义/</id>
    <published>2018-10-15T12:38:30.000Z</published>
    <updated>2018-11-13T12:34:08.069Z</updated>
    
    <content type="html"><![CDATA[<p>追个不舍，活着的意义是什么，我还在寻找。</p><p>但现在我想我有些开怀了。</p><p>从来到走，不谈虚无，我想记录一些实在的心里话。</p><a id="more"></a><p>我向着“大爱”，做我能做和我想做的事，而我在平凡，苟活之间有些小的挣扎，但我依然也对什么虚荣不感冒。我矛盾，还是无法完全说服自己。我有些犹豫，这世间的种种诱惑真的有些感染到我，曾经的我，不为所动，但如今我愿意去了解更多存在于在这世间的人们，我变得有些“贪恋”人间了，如今的世界在我眼里更偏向像是个乌托邦式。</p><p>但是现在冷静下来想想，原来还是我向着“大爱”的心绪不宁了。我自相矛盾有时就会无缘无故的在我思维里像是小鹿乱撞一样，到头来也是把我自己搞得哭笑不得。</p><p>我想接下传承的接力棒，做我能做和做我想做的事。我也想尽一份力，帮助需要的所有，我愿意付出，但不会盲目。</p><p>得先是我自己，体验生而为“人”的人生生活。生而为“人”，有着各自的灵魂，做自己是生为“人”的基本原则。</p><p>我知道我的答案可能只是暂时的，但只会比现在更加积极。</p><p>即刻想想，现在心血来潮记录的这些东西也不足挂齿了，心里想说的话是永远说不完，写不完的，我再想想我执着着记录这些东西是为什么，不过是为了记录当今这个时段我内心的部分想法罢了。</p><p>看了看，又是草草了事呐～</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;追个不舍，活着的意义是什么，我还在寻找。&lt;/p&gt;
&lt;p&gt;但现在我想我有些开怀了。&lt;/p&gt;
&lt;p&gt;从来到走，不谈虚无，我想记录一些实在的心里话。&lt;/p&gt;
    
    </summary>
    
      <category term="日记" scheme="https://liujunjie11.github.io/categories/%E6%97%A5%E8%AE%B0/"/>
    
    
      <category term="日记" scheme="https://liujunjie11.github.io/tags/%E6%97%A5%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>吾道</title>
    <link href="https://liujunjie11.github.io/2018/10/13/%E5%90%BE%E9%81%93/"/>
    <id>https://liujunjie11.github.io/2018/10/13/吾道/</id>
    <published>2018-10-13T09:06:00.000Z</published>
    <updated>2018-11-13T12:34:12.149Z</updated>
    
    <content type="html"><![CDATA[<p>道非道，自成道。</p><p>吾道，非常言道，非万物道，吾道属吾道。</p><a id="more"></a><p>吾道，在吾一念之间，可从无，可从有。</p><p>吾道，吾道，还在继往开来之时。</p><p>吾道，与时无关，与实无关，可有可无。</p><p>吾道，贪恋未来，不念过往。</p><p>吾道之成，在终了之时。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;道非道，自成道。&lt;/p&gt;
&lt;p&gt;吾道，非常言道，非万物道，吾道属吾道。&lt;/p&gt;
    
    </summary>
    
      <category term="日记" scheme="https://liujunjie11.github.io/categories/%E6%97%A5%E8%AE%B0/"/>
    
    
      <category term="日记" scheme="https://liujunjie11.github.io/tags/%E6%97%A5%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Hexo博客绑定独立域名以及转移云服务器</title>
    <link href="https://liujunjie11.github.io/2018/10/12/Hexo%E5%8D%9A%E5%AE%A2%E7%BB%91%E5%AE%9A%E7%8B%AC%E7%AB%8B%E5%9F%9F%E5%90%8D%E4%BB%A5%E5%8F%8A%E8%BD%AC%E7%A7%BB%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
    <id>https://liujunjie11.github.io/2018/10/12/Hexo博客绑定独立域名以及转移云服务器/</id>
    <published>2018-10-12T06:41:54.000Z</published>
    <updated>2018-11-13T12:34:20.656Z</updated>
    
    <content type="html"><![CDATA[<p>最近对我的博客进行了一系列大换血，以前的样子太难看了，而且速度也一直不怎么满意，这次想好好的修改一下，其中包括了买了个域名，转移到了云服务器上运行。</p><p>当然在昨天开始就开始折腾了，所以把所有想要记录的都在此记录一下。</p><a id="more"></a><h1 id="大换血修改设置"><a href="#大换血修改设置" class="headerlink" title="大换血修改设置"></a>大换血修改设置</h1><p>关于这个我就贴上相关的链接好了，毕竟重复造轮子不是我的初衷。</p><p>一些对我有帮助的链接，谢谢分享的网友们：</p><ul><li><p><a href="https://asdfv1929.github.io/2018/01/21/daovoice/" target="_blank" rel="external">Hexo NexT主题内接入网页在线联系功能</a></p></li><li><p><a href="https://blog.csdn.net/qq_33699981/article/details/72716951" target="_blank" rel="external">hexo的next主题个性化教程：打造炫酷网站</a></p></li><li><p><a href="http://blog.sciencenet.cn/blog-3247241-1139774.html" target="_blank" rel="external">hexo博客解决不蒜子统计无法显示问题</a></p></li><li><p><a href="http://zouzls.github.io/2017/03/17/Next主题背景个性化DIY/" target="_blank" rel="external">Next主题背景个性化DIY</a></p></li><li><p><a href="https://www.jianshu.com/p/b20fc983005f" target="_blank" rel="external">Hexo设置主题以及Next主题个性设置</a></p></li><li><p><a href="http://leozzy.com/2017/09/08/hexo-sidebar-auto/" target="_blank" rel="external">2017版 Hexo Next主题侧边栏 Sidebar 配置自动展开教程</a></p></li><li><p><a href="https://ohmyarch.github.io/2014/12/24/Hexo主页显示摘要/" target="_blank" rel="external">Hexo主页显示摘要</a></p></li><li><p><a href="https://segmentfault.com/q/1010000004840061/a-1020000004895286" target="_blank" rel="external">hexo next主题如何在首页摘要里显示文章图片？</a></p></li><li><p><a href="https://www.ofind.cn/blog/HEXO/HEXO下的语法高亮拓展修改.html" target="_blank" rel="external">HEXO下的语法高亮拓展修改</a></p></li><li><p><a href="https://juejin.im/entry/59d4a6a651882530f31a43f4" target="_blank" rel="external">打造个性超赞博客Hexo+NexT+GithubPages的超深度优化</a></p></li><li><p><a href="http://mashirosorata.vicp.io/HEXO-NEXT主题个性化配置.html" target="_blank" rel="external">HEXO+NEXT主题个性化配置</a></p></li></ul><blockquote><p>以上就不在写明作者了，都是一些比较有帮助的文章。</p></blockquote><p>在此简单说明一下关于我在<code>next</code>主题设置头像的问题，其实在主页的<code>_config.yml</code>设置一下就可以得出头像了，如下图，我将图片发在七牛云上，将外链拿到这里存放就好了。</p><p><img src="http://smartjpa.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-12%20%E4%B8%8B%E5%8D%882.54.00.png" alt=""></p><hr><h1 id="关于hexo博客绑定域名"><a href="#关于hexo博客绑定域名" class="headerlink" title="关于hexo博客绑定域名"></a>关于hexo博客绑定域名</h1><p>关于这个事我简单说一下好了，先放有用的链接，再稍微补充一下。</p><ul><li><p><a href="http://fengdaoting.com/2017/11/12/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/%E7%BB%91%E5%AE%9AGithub%E4%B8%8A%E7%9A%84%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E5%88%B0Godaddy%E5%9F%9F%E5%90%8D/" target="_blank" rel="external">绑定Github上的个人博客到Godaddy域名</a></p></li><li><p><a href="http://hushiyu1995.com/2017/10/01/build-web-1/index.html" target="_blank" rel="external">Github Page + Hexo + Godaddy 搭建一个个性域名的博客网站</a></p></li><li><p><a href="https://www.jianshu.com/p/6a3ee5b5abfd" target="_blank" rel="external">基于github和hexo搭建博客—-绑定个人域名</a></p></li><li><p><a href="https://www.dute.me/godaddy-alipay.html" target="_blank" rel="external">GoDaddy不支持支付宝的解决办法</a></p></li><li><p><a href="https://www.dute.me/" target="_blank" rel="external">GoDaddy优惠码</a></p></li></ul><h2 id="补充说明"><a href="#补充说明" class="headerlink" title="补充说明"></a>补充说明</h2><h3 id="关于查找GitHub-pages的ip"><a href="#关于查找GitHub-pages的ip" class="headerlink" title="关于查找GitHub pages的ip"></a>关于查找GitHub pages的ip</h3><p>两种方法：</p><p>第一种：</p><blockquote><p><code>ping liujunjie11.github.io</code> ping自己的博客目录地址</p></blockquote><p>如图：</p><p><img src="http://smartjpa.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-12%20%E4%B8%8B%E5%8D%883.00.33.png" alt=""></p><p>第二种：</p><p>打开网站<a href="https://help.github.com/articles/troubleshooting-custom-domains/，拉到下面查看相关的IP，如图：" target="_blank" rel="external">https://help.github.com/articles/troubleshooting-custom-domains/，拉到下面查看相关的IP，如图：</a></p><p><img src="http://smartjpa.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-12%20%E4%B8%8B%E5%8D%883.02.32.png" alt=""></p><h3 id="建立CNAME文件的存放目录"><a href="#建立CNAME文件的存放目录" class="headerlink" title="建立CNAME文件的存放目录"></a>建立CNAME文件的存放目录</h3><p>是要放在Hexo项目的sources目录下的，我为了保险在next的sources目录下也放了一份。</p><p>补充的就这么点了。</p><h1 id="Hexo转移到云服务器"><a href="#Hexo转移到云服务器" class="headerlink" title="Hexo转移到云服务器"></a>Hexo转移到云服务器</h1><p>这地方因为不怎么懂而且自身能力也不够，所以遇到了很多的坑，唉，有些人可能自己都搞不清楚就写文章了，搞完所有流程又不对…真的是无力吐槽了，花费了那么多精力。现在还没搞好，到时候补上需要说明的。</p><p>因为GitHub允许每个仓库在1GB左右的空间，而我现在寄托在GitHub的博客大小才130M…so,我现在不打算转移到云服务器了，到时候再说吧。</p><blockquote><p>GitHub的仓库内存说明：<a href="https://help.github.com/articles/what-is-my-disk-quota/" target="_blank" rel="external">https://help.github.com/articles/what-is-my-disk-quota/</a></p></blockquote><p>贴上参考过的链接：</p><ul><li><p><a href="https://segmentfault.com/a/1190000005723321" target="_blank" rel="external">阿里云VPS搭建自己的的Hexo博客</a></p></li><li><p><a href="https://www.hellolvs.com/hexo/" target="_blank" rel="external">VPS服务器搭建Hexo博客教程</a></p></li><li><p><a href="https://www.jianshu.com/p/ad71f7a531a5" target="_blank" rel="external">利用云服务器搭架Hexo个人博客</a></p></li><li><p><a href="https://www.laoyuyu.me/2017/10/10/hexo_deploy_vps/" target="_blank" rel="external">HEXO 部署到云服务器详细指南</a></p></li></ul><blockquote><p>也就是在云服务器上建好一些需要的软件，然后就像使用命令<code>hexo g -d</code>一样上传GitHub一样，并不需要重新开始所有。    </p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近对我的博客进行了一系列大换血，以前的样子太难看了，而且速度也一直不怎么满意，这次想好好的修改一下，其中包括了买了个域名，转移到了云服务器上运行。&lt;/p&gt;
&lt;p&gt;当然在昨天开始就开始折腾了，所以把所有想要记录的都在此记录一下。&lt;/p&gt;
    
    </summary>
    
      <category term="笔记" scheme="https://liujunjie11.github.io/categories/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="Hexo" scheme="https://liujunjie11.github.io/categories/Hexo/"/>
    
    
      <category term="教程笔记" scheme="https://liujunjie11.github.io/tags/%E6%95%99%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
      <category term="Hexo" scheme="https://liujunjie11.github.io/tags/Hexo/"/>
    
  </entry>
  
</feed>
